<!doctype html>
<html lang="en" dir="ltr" class="blog-wrapper blog-tags-post-list-page plugin-blog plugin-id-default" data-has-hydrated="false">
<head>
<meta charset="UTF-8">
<meta name="generator" content="Docusaurus v3.8.1">
<title data-rh="true">2 posts tagged with &quot;workflows&quot; | CNOE</title><meta data-rh="true" name="viewport" content="width=device-width,initial-scale=1"><meta data-rh="true" name="twitter:card" content="summary_large_image"><meta data-rh="true" property="og:url" content="https://cnoe-io.github.io/blog/tags/workflows"><meta data-rh="true" property="og:locale" content="en"><meta data-rh="true" name="docusaurus_locale" content="en"><meta data-rh="true" name="docsearch:language" content="en"><meta data-rh="true" property="og:title" content="2 posts tagged with &quot;workflows&quot; | CNOE"><meta data-rh="true" name="docusaurus_tag" content="blog_tags_posts"><meta data-rh="true" name="docsearch:docusaurus_tag" content="blog_tags_posts"><link data-rh="true" rel="icon" href="/img/favicon.ico"><link data-rh="true" rel="canonical" href="https://cnoe-io.github.io/blog/tags/workflows"><link data-rh="true" rel="alternate" href="https://cnoe-io.github.io/blog/tags/workflows" hreflang="en"><link data-rh="true" rel="alternate" href="https://cnoe-io.github.io/blog/tags/workflows" hreflang="x-default"><link rel="alternate" type="application/rss+xml" href="/blog/rss.xml" title="CNOE RSS Feed">
<link rel="alternate" type="application/atom+xml" href="/blog/atom.xml" title="CNOE Atom Feed">







<link rel="stylesheet" href="https://fonts.googleapis.com/icon?family=Material+Icons"><link rel="stylesheet" href="/assets/css/styles.b79d7a1f.css">
<script src="/assets/js/runtime~main.2dd7f2c1.js" defer="defer"></script>
<script src="/assets/js/main.a92e7b36.js" defer="defer"></script>
</head>
<body class="navigation-with-keyboard">
<svg xmlns="http://www.w3.org/2000/svg" style="display: none;"><defs>
<symbol id="theme-svg-external-link" viewBox="0 0 24 24"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"/></symbol>
</defs></svg>
<script>!function(){var t="light";var e=function(){try{return new URLSearchParams(window.location.search).get("docusaurus-theme")}catch(t){}}()||function(){try{return window.localStorage.getItem("theme")}catch(t){}}();document.documentElement.setAttribute("data-theme",e||t),document.documentElement.setAttribute("data-theme-choice",e||t)}(),function(){try{const c=new URLSearchParams(window.location.search).entries();for(var[t,e]of c)if(t.startsWith("docusaurus-data-")){var a=t.replace("docusaurus-data-","data-");document.documentElement.setAttribute(a,e)}}catch(t){}}()</script><div id="__docusaurus"><link rel="preload" as="image" href="/img/logo-no-name.png"><link rel="preload" as="image" href="https://ca.slack-edge.com/T08PSQ7BQ-U03M80Q624F-f11d0924baa7-512"><link rel="preload" as="image" href="https://avatars.githubusercontent.com/u/1094878"><link rel="preload" as="image" href="https://ca.slack-edge.com/T08PSQ7BQ-UCG7862LR-ga2857bd677e-512"><link rel="preload" as="image" href="https://ca.slack-edge.com/T08PSQ7BQ-U02TMF8N4DS-95b679f8ca22-512"><link rel="preload" as="image" href="https://avatars.githubusercontent.com/u/2309880"><link rel="preload" as="image" href="https://avatars.githubusercontent.com/u/10545494"><div role="region" aria-label="Skip to main content"><a class="skipToContent_fXgn" href="#__docusaurus_skipToContent_fallback">Skip to main content</a></div><nav aria-label="Main" class="theme-layout-navbar navbar navbar--fixed-top"><div class="navbar__inner"><div class="theme-layout-navbar-left navbar__items"><button aria-label="Toggle navigation bar" aria-expanded="false" class="navbar__toggle clean-btn" type="button"><svg width="30" height="30" viewBox="0 0 30 30" aria-hidden="true"><path stroke="currentColor" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2" d="M4 7h22M4 15h22M4 23h22"></path></svg></button><a class="navbar__brand" href="/"><div class="navbar__logo"><img src="/img/logo-no-name.png" alt="CNOE Logo" class="themedComponent_mlkZ themedComponent--light_NVdE"><img src="/img/logo-no-name.png" alt="CNOE Logo" class="themedComponent_mlkZ themedComponent--dark_xIcU"></div><b class="navbar__title text--truncate"></b></a><a class="navbar__item navbar__link" href="/docs/overview/cnoe">Docs</a><a aria-current="page" class="navbar__item navbar__link navbar__link--active" href="/blog">Blog</a></div><div class="theme-layout-navbar-right navbar__items navbar__items--right"><a href="https://calendar.google.com/calendar/u/0/embed?src=064a2adfce866ccb02e61663a09f99147f22f06374e7a8994066bdc81e066986@group.calendar.google.com&amp;ctz=America/Los_Angeles" target="_blank" rel="noopener noreferrer" class="navbar__item navbar__link navbar--calendar-link" aria-label="Community Calendar"></a><a href="https://cloud-native.slack.com/archives/C05TN9WFN5S" target="_blank" rel="noopener noreferrer" class="navbar__item navbar__link navbar--slack-link" aria-label="Slack Channel"></a><a href="https://github.com/cnoe-io" target="_blank" rel="noopener noreferrer" class="navbar__item navbar__link navbar--github-link" aria-label="GitHub Repository"></a><div class="navbarSearchContainer_Bca1"><div class="navbar__search"><span aria-label="expand searchbar" role="button" class="search-icon" tabindex="0"></span><input id="search_input_react" type="search" placeholder="Loading..." aria-label="Search" class="navbar__search-input search-bar" disabled=""></div></div></div></div><div role="presentation" class="navbar-sidebar__backdrop"></div></nav><div id="__docusaurus_skipToContent_fallback" class="theme-layout-main main-wrapper mainWrapper_z2l0"><div class="container margin-vert--lg"><div class="row"><aside class="col col--3"><nav class="sidebar_re4s thin-scrollbar" aria-label="Blog recent posts navigation"><div class="sidebarItemTitle_pO2u margin-bottom--md">Recent posts</div><div role="group"><h3 class="yearGroupHeading_rMGB">2024</h3><ul class="sidebarItemList_Yudw clean-list"><li class="sidebarItem__DBe"><a class="sidebarItemLink_mo7H" href="/blog/intro-to-idpbuilder">Simplifying IDP Deployment and Local Development</a></li><li class="sidebarItem__DBe"><a class="sidebarItemLink_mo7H" href="/blog/argo-workflow-scalability">Argo Workflows Controller Scalability Testing on Amazon EKS</a></li></ul></div><div role="group"><h3 class="yearGroupHeading_rMGB">2023</h3><ul class="sidebarItemList_Yudw clean-list"><li class="sidebarItem__DBe"><a class="sidebarItemLink_mo7H" href="/blog/argo-cd-application-scalability">Argo CD Benchmarking - Pushing the Limits and Sharding Deep Dive</a></li><li class="sidebarItem__DBe"><a class="sidebarItemLink_mo7H" href="/blog/optimizing-data-quality-in-dev-portals">Optimizing for Data Quality in your Developer Portal</a></li><li class="sidebarItem__DBe"><a class="sidebarItemLink_mo7H" href="/blog/welcome">CNOE - A Joint Effort to Share Internal Developer Platform Tools and Best Practices.</a></li></ul></div></nav></aside><main class="col col--7"><header class="margin-bottom--xl"><h1>2 posts tagged with &quot;workflows&quot;</h1><a href="/blog/tags">View All Tags</a></header><article class="margin-bottom--xl"><header><h2 class="title_f1Hy"><a href="/blog/intro-to-idpbuilder">Simplifying IDP Deployment and Local Development</a></h2><div class="container_mt6G margin-vert--md"><time datetime="2024-11-11T00:00:00.000Z">November 11, 2024</time> Â· <!-- -->5 min read</div><div class="margin-top--md margin-bottom--sm row"><div class="col col--6 authorCol_Hf19"><div class="avatar margin-bottom--sm"><a href="https://github.com/blakeromano" target="_blank" rel="noopener noreferrer" class="avatar__photo-link"><img class="avatar__photo authorImage_XqGP" src="https://ca.slack-edge.com/T08PSQ7BQ-U03M80Q624F-f11d0924baa7-512" alt="Blake Romano"></a><div class="avatar__intro authorDetails_lV9A"><div class="avatar__name"><a href="https://github.com/blakeromano" target="_blank" rel="noopener noreferrer"><span class="authorName_yefp">Blake Romano</span></a></div><small class="authorTitle_nd0D" title="Software Engineer, Imagine Learning">Software Engineer, Imagine Learning</small><div class="authorSocials_rSDt"></div></div></div></div><div class="col col--6 authorCol_Hf19"><div class="avatar margin-bottom--sm"><a href="https://github.com/csantanapr" target="_blank" rel="noopener noreferrer" class="avatar__photo-link"><img class="avatar__photo authorImage_XqGP" src="https://avatars.githubusercontent.com/u/1094878" alt="Carlos Santana"></a><div class="avatar__intro authorDetails_lV9A"><div class="avatar__name"><a href="https://github.com/csantanapr" target="_blank" rel="noopener noreferrer"><span class="authorName_yefp">Carlos Santana</span></a></div><small class="authorTitle_nd0D" title="Architect, AWS">Architect, AWS</small><div class="authorSocials_rSDt"></div></div></div></div><div class="col col--6 authorCol_Hf19"><div class="avatar margin-bottom--sm"><a href="https://github.com/greghaynes" target="_blank" rel="noopener noreferrer" class="avatar__photo-link"><img class="avatar__photo authorImage_XqGP" src="https://ca.slack-edge.com/T08PSQ7BQ-UCG7862LR-ga2857bd677e-512" alt="Greg Haynes"></a><div class="avatar__intro authorDetails_lV9A"><div class="avatar__name"><a href="https://github.com/greghaynes" target="_blank" rel="noopener noreferrer"><span class="authorName_yefp">Greg Haynes</span></a></div><small class="authorTitle_nd0D" title="Architect, Autodesk">Architect, Autodesk</small><div class="authorSocials_rSDt"></div></div></div></div><div class="col col--6 authorCol_Hf19"><div class="avatar margin-bottom--sm"><a href="https://github.com/nabuskey" target="_blank" rel="noopener noreferrer" class="avatar__photo-link"><img class="avatar__photo authorImage_XqGP" src="https://ca.slack-edge.com/T08PSQ7BQ-U02TMF8N4DS-95b679f8ca22-512" alt="Manabu McCloskey"></a><div class="avatar__intro authorDetails_lV9A"><div class="avatar__name"><a href="https://github.com/nabuskey" target="_blank" rel="noopener noreferrer"><span class="authorName_yefp">Manabu McCloskey</span></a></div><small class="authorTitle_nd0D" title="Architect, AWS">Architect, AWS</small><div class="authorSocials_rSDt"></div></div></div></div></div></header><div class="markdown"><p>Creating and managing an internal developer platform (IDP) is a complex and time-consuming challenge. As outlined on our website and in the <a href="https://tag-app-delivery.cncf.io/whitepapers/platforms/" target="_blank" rel="noopener noreferrer">CNCF Platforms white paper</a>, IDPs consist of <a href="https://cnoe.io/docs/category/technology-capabilities" target="_blank" rel="noopener noreferrer">capabilities</a>. This centralized system facilitates developers in designing, building, deploying, and managing applications and services within an organization. It offers a suite of tools, APIs, and services that streamline the development process by providing essential capabilities.</p>
<p><a href="https://cnoe.io/docs/reference-implementation/idpbuilder" target="_blank" rel="noopener noreferrer">idpBuilder</a> is meant for platform engineers looking to quickly spin up a repeatable IDP environment. With just a single binary and Docker as the only dependency, idpBuilder allows you to create a fully functional IDP leveraging popular open source projects such as Kubernetes, ArgoCD, and Backstage.</p>
<p>For most use cases, you need to run one command to get started. For example, to get started with the CNOE reference implementation all you have to run is:</p>
<div class="terminal_w2Kt"><div class="terminalHeader_Kk1r"><div class="terminalControls_X6oT"><span class="terminalButton__Yhu"></span><span class="terminalButton__Yhu"></span><span class="terminalButton__Yhu"></span></div><button class="copyButton_H_xL" aria-label="Copy all commands" data-copied="false"><svg width="16" height="16" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><rect x="9" y="9" width="13" height="13" rx="2" ry="2"></rect><path d="M5 15H4a2 2 0 0 1-2-2V4a2 2 0 0 1 2-2h9a2 2 0 0 1 2 2v1"></path></svg></button></div><div class="terminalBody_tZ9P"><pre class="enhancedPre_UwTO"><div class="commandLine__eue"><div class="" style="white-space:pre-wrap"><div><span class="prompt_iIjO">$</span><span class="command_Noto"><span class="commonCommand_AyI1">idpbuilder</span> create --use-path-routing \</span></div><div><span class="command_Noto"><span style="margin-left:2ch">--package https://github.com/cnoe-io/stacks<!-- -->//<!-- -->ref-implementation</span></span></div></div></div><div class="commandLine__eue"><div class="" style="white-space:pre-wrap"><div class="text_hPwK"></div></div></div></pre></div></div>
<p><img decoding="async" loading="lazy" alt="img" src="/assets/images/idpbuilder-basic-16bfe6b7baa57701b2124233fff1e919.png" width="649" height="352" class="img_ev3q"></p>
<p>In addition to its simplicity, idpBuilder offers the following key benefits:</p>
<ol>
<li>Rapid Deployment: Create a reference implementation of an IDP with minimal setup time.</li>
<li>CI Integration: Easily incorporate idpBuilder into your continuous integration workflows for comprehensive testing.</li>
<li>Local Development: Provide IDP engineers with a consistent and easily reproducible local development environment.</li>
</ol>
<p>Let&#x27;s explore how you can use idpBuilder in your development workflow. Whether you&#x27;re looking to demonstrate an IDP reference implementation, enhance your CI pipeline, or improve your local development setup, idpBuilder offers a solution that&#x27;s both powerful and easy to use.</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="demo-your-own-idp-implementation">Demo your own IDP implementation<a href="#demo-your-own-idp-implementation" class="hash-link" aria-label="Direct link to Demo your own IDP implementation" title="Direct link to Demo your own IDP implementation">â</a></h2>
<p>idpBuilder comes with a set of technologies that enables GitOps workflows all contained within the ephemeral environment. Think of building your IDP solution in a box. It does this by provisioning a kind cluster, Gitea server, ArgoCD, and ingress-nginx. See<a href="https://cnoe.io/docs/reference-implementation/installations/idpbuilder/usage" target="_blank" rel="noopener noreferrer"> our documentation</a> site for more information.</p>
<p>in addition, idpbuilder can copy files and Kubernetes manifests checked into Git repositories to the in-cluster Gitrea repositories. Once copied to the in-cluster repositories, ArgoCD can use them to deploy your solutions in minutes. We have examples of this in the <a href="https://github.com/cnoe-io/stacks/tree/main/ref-implementation" target="_blank" rel="noopener noreferrer">Stacks repository.</a>.  You can run them in your browser using Codespaces as well.
This approach also allows you to experiment with configuration changes and code changes without changing files checked into the external repositories because everything is contained in the cluster.</p>
<p>Carlos Santana does an excellent job of show this in his video. <a href="https://www.youtube.com/watch?v=e6Fvivx4Aw8" target="_blank" rel="noopener noreferrer">https://www.youtube.com/watch?v=e6Fvivx4Aw8</a></p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="local-development-and-ci-integrations">Local Development and CI integrations<a href="#local-development-and-ci-integrations" class="hash-link" aria-label="Direct link to Local Development and CI integrations" title="Direct link to Local Development and CI integrations">â</a></h2>
<p>Due to the number of technologies involved and the complexity in integrating them, many organizations struggle with fragmented development environments. Different teams often work in silos, using disparate tools and workflows.
This fragmentation is a major barrier for organizations hoping to create cohesive internal developer platforms as it is difficult to design and develop features which span multiple capabilities. Furthermore, the lack of a reference development environment leads to significant inefficiencies including slower development cycles, especially for cross-capability functionality.
idpBuilder can set up identical environments for local development and CI pipelines. With idpBuilder, you get:</p>
<ol>
<li><strong>Reduced &quot;It Works on My Machine&quot; Syndrome</strong>: With consistent environments, discrepancies between local and CI setups become a thing of the past.</li>
<li><strong>Early Issue Detection</strong>: Integration problems are caught earlier, saving time and resources in the long run.</li>
<li><strong>Improved Collaboration</strong>: Developers can confidently work on the same project, knowing they&#x27;re all using identical environments.</li>
<li><strong>Streamlined Workflow</strong>: The seamless transition from local development to CI pipelines accelerates the development cycle.</li>
<li><strong>Local GitOps Workflow</strong>: A zero-configuration approach to GitOps: start immediately with a pre-configured local Git server, no external repositories or credentials required.</li>
</ol>
<p>During KubeCon 2024, AutoDesk touches on these topics and shares their experience using it for their platform development: <a href="https://www.youtube.com/watch?v=x_cTXvRgwdA" target="_blank" rel="noopener noreferrer">https://www.youtube.com/watch?v=x_cTXvRgwdA</a></p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="crossplane-testing">Crossplane Testing<a href="#crossplane-testing" class="hash-link" aria-label="Direct link to Crossplane Testing" title="Direct link to Crossplane Testing">â</a></h2>
<p>Another example use of idpBuilder is in development and testing with Crossplane functions. At the All Day DevOps event, Imagine Learning highlighted their use of idpBuilder:</p>
<ul>
<li><strong>Local Development</strong>: idpBuilder deploys Crossplane, a local OCI registry, composite resource definitions, compositions, and composition functions within a single local Kubernetes environment.</li>
<li><strong>Enhanced Security</strong>: This setup avoids publishing images to public registries, improving security and privacy posture.</li>
<li><strong>Local AWS Simulation</strong>: A local stack simulates an AWS environment, enabling thorough testing without external resources.</li>
</ul>
<p>More details about their implementation can be found in their <a href="https://github.com/blakeromano/control-plane-xfn" target="_blank" rel="noopener noreferrer">repository</a> and their presentation at the <a href="https://event.alldaydevops.com/hub/events/1a51349d-007d-4e3b-994e-814bc68718e9/sessions/f5df32b1-71a6-496a-9ba8-ee2573a7fae6" target="_blank" rel="noopener noreferrer">All Day DevOps event</a>.</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="conclusion">Conclusion<a href="#conclusion" class="hash-link" aria-label="Direct link to Conclusion" title="Direct link to Conclusion">â</a></h2>
<p>idpBuilder simplifies creating and testing Internal Developer Platform Capabilities, solving common development and maintenance challenges. It allows you to rapidly deploy functional solutions with minimal setup by offering consistency across development stages.</p>
<p>However, idpBuilder isn&#x27;t a one-size-fits-all solution. Organizations must assess their specific needs and existing infrastructure. While it&#x27;s excellent for testing and development, production deployments may need further adjustments.</p>
<p>Overall, idpBuilder enhances IDP management, making it worth exploring for teams aiming to improve development processes and environmental consistency.</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="take-the-next-step">Take the Next Step:<a href="#take-the-next-step" class="hash-link" aria-label="Direct link to Take the Next Step:" title="Direct link to Take the Next Step:">â</a></h3>
<ol>
<li><strong>Try idpBuilder</strong>:<a href="https://cnoe.io/docs/reference-implementation/installations/idpbuilder" target="_blank" rel="noopener noreferrer"> Download and start using idpBuilder today.</a>. Follow our quick-start guide in the documentation to set up your first IDP environment.</li>
<li><strong>Join Our Community</strong>: Have questions or want to share your experience? <a href="https://cloud-native.slack.com/archives/C05TN9WFN5S" target="_blank" rel="noopener noreferrer"> Join our community on Slack</a>. We&#x27;re here to help and learn from each other.</li>
<li><strong>Learn More</strong>: Explore our documentation and resources on our <a href="https://cnoe.io" target="_blank" rel="noopener noreferrer">website</a> to deepen your understanding of idpBuilder and its capabilities.</li>
<li><strong>Contribute</strong>: <a href="https://github.com/cnoe-io/idpbuilder" target="_blank" rel="noopener noreferrer">idpBuilder</a> is an open-source project, and we welcome contributions. Whether it&#x27;s code, documentation, or feature suggestions, your input can help shape the future of idpBuilder.</li>
</ol></div><footer class="row docusaurus-mt-lg"><div class="col"><b>Tags:</b><ul class="tags_jXut padding--none margin-left--sm"><li class="tag_QGVx"><a rel="tag" class="tag_zVej tagRegular_sFm0" href="/blog/tags/workflows">workflows</a></li><li class="tag_QGVx"><a rel="tag" class="tag_zVej tagRegular_sFm0" href="/blog/tags/benchmarking">benchmarking</a></li><li class="tag_QGVx"><a rel="tag" class="tag_zVej tagRegular_sFm0" href="/blog/tags/scalability">scalability</a></li><li class="tag_QGVx"><a rel="tag" class="tag_zVej tagRegular_sFm0" href="/blog/tags/argo">argo</a></li></ul></div></footer></article><article class="margin-bottom--xl"><header><h2 class="title_f1Hy"><a href="/blog/argo-workflow-scalability">Argo Workflows Controller Scalability Testing on Amazon EKS</a></h2><div class="container_mt6G margin-vert--md"><time datetime="2024-06-04T00:00:00.000Z">June 4, 2024</time> Â· <!-- -->18 min read</div><div class="margin-top--md margin-bottom--sm row"><div class="col col--6 authorCol_Hf19"><div class="avatar margin-bottom--sm"><a href="https://github.com/Enclavet" target="_blank" rel="noopener noreferrer" class="avatar__photo-link"><img class="avatar__photo authorImage_XqGP" src="https://avatars.githubusercontent.com/u/2309880" alt="Andrew Lee"></a><div class="avatar__intro authorDetails_lV9A"><div class="avatar__name"><a href="https://github.com/Enclavet" target="_blank" rel="noopener noreferrer"><span class="authorName_yefp">Andrew Lee</span></a></div><small class="authorTitle_nd0D" title="Architect, AWS">Architect, AWS</small><div class="authorSocials_rSDt"></div></div></div></div><div class="col col--6 authorCol_Hf19"><div class="avatar margin-bottom--sm"><a href="https://github.com/vsethi" target="_blank" rel="noopener noreferrer" class="avatar__photo-link"><img class="avatar__photo authorImage_XqGP" src="https://avatars.githubusercontent.com/u/10545494" alt="Vikram Sethi"></a><div class="avatar__intro authorDetails_lV9A"><div class="avatar__name"><a href="https://github.com/vsethi" target="_blank" rel="noopener noreferrer"><span class="authorName_yefp">Vikram Sethi</span></a></div><small class="authorTitle_nd0D" title="Principal Scientist, Adobe">Principal Scientist, Adobe</small><div class="authorSocials_rSDt"></div></div></div></div></div></header><div class="markdown"><h2 class="anchor anchorWithStickyNavbar_LWe7" id="introduction">Introduction<a href="#introduction" class="hash-link" aria-label="Direct link to Introduction" title="Direct link to Introduction">â</a></h2>
<p>In our earlier blog posts, we have discussed scalability tests for Argo CD, where in two consecutive experiments, we pushed the limits of Argo CD to deploy <a href="https://aws.amazon.com/blogs/opensource/argo-cd-application-controller-scalability-testing-on-amazon-eks/" target="_blank" rel="noopener noreferrer">10,000 applications on ~100 clusters</a> and then<a href="https://cnoe.io/blog/argo-cd-application-scalability" target="_blank" rel="noopener noreferrer"> 50,000 applications on 500 clusters</a> along with configuration and fine-tuning required to make Argo CD scale effectively. Argo CD deployments, however, do not happen in isolation, and similar to a <a href="https://cnoe.io/docs/reference-implementation" target="_blank" rel="noopener noreferrer">CNOE stack</a>, Argo CD is often deployed on a cluster along with other tooling which collectively contribute to the performance and scalability bottlenecks we see users run into.</p>
<p>Argo Workflows is one common tool we often see users deploy alongside Argo CD to enable workflow executions (e.g. building images, running tests, cutting releases, etc). Our early experiments with Argo Workflows revealed that, if not tuned properly, it can negatively impact the scalability of a given Kubernetes cluster, particularly if the Kubernetes cluster happens to be the control cluster managing developer workflows across a large group of users. A real world example of some of the scaling challenges you can encounter with Argo Workflows is explored in our recent ArgoCon talk: <a href="https://www.youtube.com/watch?v=7yVXMCX62tY" target="_blank" rel="noopener noreferrer">Key Takeaways from Scaling Adobe&#x27;s CI/CD Solution to Support 50K Argo CD Apps</a>.</p>
<p>For us to better understand the limitations and tuning requirements for Argo Workflows, in this blog post we publish details on the scalability experiments we ran for Argo Workflows executing Workflows in two different load patterns: increasing rate up to 2100 workflows/min and queued reconciliation of 5000 workflows on an Amazon EKS cluster with 50x m5.large nodes. We show the correlation between the various Argo Workflow&#x27;s knobs and controls and the processing time as well as performance improvements you can get by determining how you supply the workflows to the control plane.</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="test-parameters">Test Parameters<a href="#test-parameters" class="hash-link" aria-label="Direct link to Test Parameters" title="Direct link to Test Parameters">â</a></h2>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="test-workflow">Test Workflow<a href="#test-workflow" class="hash-link" aria-label="Direct link to Test Workflow" title="Direct link to Test Workflow">â</a></h3>
<p>The test workflow is based on the lightweight whalesay container from docker which prints out some text and ASCII art to the terminal. The reason we chose a lightweight container is that we wanted to stress the Argo Workflows controller in managing the Workflow lifecycle (pod creation, scheduling, and cleanup) and minimize the extra overhead on the Kubernetes control plane in dealing with the data plane workloads. An example of the Workflow is below:</p>
<div class="language-go codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-go codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token keyword" style="color:#00009f">var</span><span class="token plain"> helloWorldWorkflow </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> wfv1</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">Workflow</span><span class="token punctuation" style="color:#393A34">{</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    ObjectMeta</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> metav1</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">ObjectMeta</span><span class="token punctuation" style="color:#393A34">{</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        GenerateName</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> </span><span class="token string" style="color:#e3116c">&quot;hello-world-&quot;</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token punctuation" style="color:#393A34">}</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    Spec</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> wfv1</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">WorkflowSpec</span><span class="token punctuation" style="color:#393A34">{</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        Entrypoint</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> </span><span class="token string" style="color:#e3116c">&quot;whalesay&quot;</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        ServiceAccountName</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> </span><span class="token string" style="color:#e3116c">&quot;argo&quot;</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        Templates</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> </span><span class="token punctuation" style="color:#393A34">[</span><span class="token punctuation" style="color:#393A34">]</span><span class="token plain">wfv1</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">Template</span><span class="token punctuation" style="color:#393A34">{</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            </span><span class="token punctuation" style="color:#393A34">{</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">                Name</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> </span><span class="token string" style="color:#e3116c">&quot;whalesay&quot;</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">                Container</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> </span><span class="token operator" style="color:#393A34">&amp;</span><span class="token plain">corev1</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">Container</span><span class="token punctuation" style="color:#393A34">{</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">                    Image</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain">   </span><span class="token string" style="color:#e3116c">&quot;docker/whalesay:latest&quot;</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">                    Command</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> </span><span class="token punctuation" style="color:#393A34">[</span><span class="token punctuation" style="color:#393A34">]</span><span class="token builtin">string</span><span class="token punctuation" style="color:#393A34">{</span><span class="token string" style="color:#e3116c">&quot;cowsay&quot;</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> </span><span class="token string" style="color:#e3116c">&quot;hello world&quot;</span><span class="token punctuation" style="color:#393A34">}</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">                </span><span class="token punctuation" style="color:#393A34">}</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            </span><span class="token punctuation" style="color:#393A34">}</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        </span><span class="token punctuation" style="color:#393A34">}</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        PodGC</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> </span><span class="token operator" style="color:#393A34">&amp;</span><span class="token plain">wfv1</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">PodGC</span><span class="token punctuation" style="color:#393A34">{</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            Strategy</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> </span><span class="token string" style="color:#e3116c">&quot;OnPodSuccess&quot;</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        </span><span class="token punctuation" style="color:#393A34">}</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token punctuation" style="color:#393A34">}</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token punctuation" style="color:#393A34">}</span><br></span></code></pre></div></div>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="argo-workflows-settings">Argo Workflows Settings<a href="#argo-workflows-settings" class="hash-link" aria-label="Direct link to Argo Workflows Settings" title="Direct link to Argo Workflows Settings">â</a></h3>
<p>We will be detailing how each of these settings affect Argo Workflow in various experiments later in this blog post.</p>
<ul>
<li>
<p>Controller workers: Argo Workflows controller utilizes different workers for various operations in a Workflow lifecycle. We will be looking at t types of workers for our scalability testing.</p>
<ul>
<li>
<p>workflow-workers (default: 32): These workers are threads in a single Argo Workflows controller that reconcile Argo Workflow Custom Resources (CRs). When a Workflow is created, a workflow-worker will handle the end-to-end operations of the Workflow from ensuring the pod is scheduled to ensuring the pod has finished. The number of workers can be specified by passing the <code>--workflow-workers</code> flag to the controller.</p>
</li>
<li>
<p>pod-cleanup-workers (default: 4): These workers clean up finished Workflows. When a Workflow has finished executing, depending on your clean-up settings, a pod-cleanup-worker will handle cleaning up the pod from the Workflow. The number of workers can be specified by passing theÂ <code>--pod-cleanup-workers</code> flag to the controller.</p>
</li>
</ul>
</li>
<li>
<p>Client queries per second (QPS)/Burst QPS settings (default: 20/30):Â These settings control when the Argo Workflows controllerâs Kubernetes (K8s) client starts to throttle requests to the K8S API server. The client QPS setting is for limiting sustained QPS for the k8s client while burst QPS is for allowing a burst request rate in excess of the client QPS for a short period of time. The client QPS/burst QPS can be set by passing the <code>--qps</code> and <code>--burst</code> flag to the controller.</p>
</li>
<li>
<p>Sharding: Sharding with multiple Argo Workflows controllers is possible by running each controller in its own namespace. The controller would only reconcile Workflows submitted in that particular namespace. The namespace of each controller can be specified with the <code>--namespaced</code> flag.</p>
</li>
</ul>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="key-metrics">Key Metrics<a href="#key-metrics" class="hash-link" aria-label="Direct link to Key Metrics" title="Direct link to Key Metrics">â</a></h2>
<p>We chose a set of key metrics for the scalability testing because we wanted to measure how many workflows the Argo Workflows controller can reconcile and process. We will also be looking into K8s control plane metrics which might indicate your control plane cannot keep up with the Argo Workflows workload.Â </p>
<ul>
<li>
<p>Workqueue depth: The workqueue depth shows workflows which have not been reconciled. If the depth starts to increase, it indicates that the Argo Workflows controller is unable to handle the submission rate of Workflows.</p>
</li>
<li>
<p>Workqueue latency: The workqueue latency is the average time workflows spent waiting in the workqueue. A lower value indicates that the Argo Workflows controller is processing workflows faster so that they are not waiting in the workqueue.</p>
</li>
<li>
<p>K8S api server requests per second: The read and write requests per second being made to the K8S api server.</p>
</li>
</ul>
<p>We didnât include CPU/Memory as a key metric because during our testing we did not see any significant impacts to both. Most likely because of our simplistic workflows utilized for this benchmark.</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="environment">Environment<a href="#environment" class="hash-link" aria-label="Direct link to Environment" title="Direct link to Environment">â</a></h2>
<p>We ran the experiments in an AWS environment utilizing a single Amazon EKS cluster. The Kubernetes version is 1.27 and Argo Workflows version is 3.5.4. No resource quotas were utilized on the Argo Workflows controller. For the cluster, we will start by provisioning 1xÂ m5.8xlarge Amazon Elastic Compute Cloud (Amazon EC2) instances which will run the Argo Workflows controller and 50x m5.large instances for executing workflows. The number of execution instances is sufficient to run all 5000 workflows in parallel to ensure that pods are not waiting on resources to execute. Monitoring and metrics for Argo Workflows were provided by Prometheus/Grafana.Â </p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="methodology">Methodology<a href="#methodology" class="hash-link" aria-label="Direct link to Methodology" title="Direct link to Methodology">â</a></h2>
<p>There will be two types of load patterns evaluated:</p>
<p><strong>Increasing Rate Test:</strong> Workflows will be submitted at an increasing rate (workflows/min) until the Argo Workflows controller cannot keep up. The state at which the controller cannot keep up is when there are &gt;0 workflows in the workflow queue or there is increasing queue latency. That rate of Workflow submissions will be noted as the maximum rate at which the Argo Workflows can be processed with the current settings.</p>
<p>**Queued Reconciliation Test:Â **5000 workflows are submitted in less than minute. Metrics will be monitored from when the Argo Workflows controller starts processing workflows to when it has reconciled all 5000 workflows. The number of nodes is sufficient for running all the workflows simultaneously.</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="experiments">Experiments<a href="#experiments" class="hash-link" aria-label="Direct link to Experiments" title="Direct link to Experiments">â</a></h2>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="experiment-1-baseline">Experiment 1: Baseline<a href="#experiment-1-baseline" class="hash-link" aria-label="Direct link to Experiment 1: Baseline" title="Direct link to Experiment 1: Baseline">â</a></h3>
<p>In our baseline experiment, we are running in a single Argo Workflows shard (namespace) with default settings.</p>
<p><strong>Increasing Rate Test:</strong></p>
<p>As you can see below, the Argo Workflows controller can process up to 270 workflows/min. The average workqueue latency and workqueue depth are nearly zero.  At 300 workflows/min, workqueue latency and workqueue depth starts to increase.</p>
<p><img decoding="async" loading="lazy" alt="Enter image alt description" src="/assets/images/1-d6f2f88df7f56060c4c8a765a82dcbfb.png" width="974" height="753" class="img_ev3q"></p>
<p><strong>Queued Reconciliation Test:</strong></p>
<p>It takes around 17 mins to reconcile 5000 workflows and peak avg workqueue latency was 5.38 minutes.</p>
<p><img decoding="async" loading="lazy" alt="Enter image alt description" src="/assets/images/2-211e5d9c30190ab7a797043dcdc689e4.png" width="972" height="459" class="img_ev3q"></p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="experiment-2-workflow-workers">Experiment 2: Workflow Workers<a href="#experiment-2-workflow-workers" class="hash-link" aria-label="Direct link to Experiment 2: Workflow Workers" title="Direct link to Experiment 2: Workflow Workers">â</a></h3>
<p>For this experiment, we increase the number of workflow workers from the default of 32 to 128 where the workers use the maximum QPS and burst settings available to them. We also had to increase the number of pod-cleanup-workers to 32 as the Argo Workflows controller was experiencing some instability, where the controller pod was consistently crashing with the default value of 4.</p>
<p><strong>Increasing Rate Test:</strong></p>
<p>For the increasing workflow rate test, we can see exactly when the number of workflow workers is not sufficient to process the load. Both workqueue latency and depth start to increase indicating that workflows are waiting to be reconciled. When we increase the number of workers, the controller is able to reconcile the current load until an additional load is placed on it. For 32 workers, that limit is 300 workflows/min. When we increase the number of workers to 64, it is able to process that load until load is increased to 330 workflows/min. Then we increase the number of workers to 96 and it can process the additional load again. When we increase to 360 workflows/min, we need to bump the number of workers to 128.</p>
<table><thead><tr><th>Workers</th><th>Max workflows/minute</th></tr></thead><tbody><tr><td>32</td><td>270</td></tr><tr><td>64</td><td>300</td></tr><tr><td>96</td><td>330</td></tr><tr><td>128</td><td>360</td></tr></tbody></table>
<p><img decoding="async" loading="lazy" alt="Enter image alt description" src="/assets/images/3-116cb38fa45fd79d00154959c7823fe9.png" width="971" height="760" class="img_ev3q"></p>
<p>For the K8S api server, we see sustained 180 writes/sec and 70 reads/sec during the increasing rate tests.</p>
<p><img decoding="async" loading="lazy" alt="Enter image alt description" src="/assets/images/AYf_Image_1-a76b61333fac9118e74c3538c6bb6ef6.png" width="937" height="787" class="img_ev3q"></p>
<p><strong>Queued Reconciliation Test:</strong></p>
<p>For the queued reconciliation test, the time it took to reconcile all the workflows did not change significantly. With 32 workers it took 17 mins to reconcile while with 96 workers it took 16 mins. The peak workqueue latency did decrease from 5.38 mins with 32 workers to 3.19 mins with 96 workers. With 128 workers, the Argo Workflows controller kept crashing.</p>
<table><thead><tr><th>Workers</th><th>Peak avg latency (mins)</th><th>Reconcile time (mins)</th></tr></thead><tbody><tr><td>32</td><td>5.38</td><td>17</td></tr><tr><td>64</td><td>5.06</td><td>18</td></tr><tr><td>96</td><td>3.19</td><td>16</td></tr><tr><td>128</td><td>N/A</td><td>N/A</td></tr></tbody></table>
<p><img decoding="async" loading="lazy" alt="Enter image alt description" src="/assets/images/4-c8a05383e3dd19b4f35f4ddf168e9fbb.png" width="971" height="487" class="img_ev3q"></p>
<p>For the K8S api server, we see peaks of up to 260 writes/sec and 90 reads/sec during the queued reconciliation tests. You notice for the last test that there is no K8S api server activity as the Argo Workflows controller was misbehaving due to client-side throttling.</p>
<p><img decoding="async" loading="lazy" alt="Enter image alt description" src="/assets/images/ZlY_Image_2-5b7ab12762820f727e0a8b792c505da2.png" width="942" height="795" class="img_ev3q"></p>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="observations-from-experiment-2"><strong>Observations from Experiment 2:</strong><a href="#observations-from-experiment-2" class="hash-link" aria-label="Direct link to observations-from-experiment-2" title="Direct link to observations-from-experiment-2">â</a></h4>
<p>Workers play a big part in how fast the Argo Workflows controller is able to reconcile the rate of workflows being submitted. If you are observing workflow latency and backing up the workqueue depth, changing the number of workers is a potential way to improve performance. There are a few observations that we want to call out. One is that if we compare the two different patterns, one where we submit workflows at a constant rate and one in which we load up the workqueue all at once, we can see variations in calculated throughput. We can actually calculate the time it takes to reconcile 5000 apps utilizing the increasing rate test results and compare them to the queued reconciliation test.</p>
<table><thead><tr><th>Workers</th><th>Increasing rate test time to reconciling 5000 workflows (mins)</th><th>Reconcile time of 5000 workflows queued all at once (mins)</th></tr></thead><tbody><tr><td>32</td><td>18.5</td><td>17</td></tr><tr><td>64</td><td>16.6</td><td>18</td></tr><tr><td>96</td><td>15.1</td><td>16</td></tr><tr><td>128</td><td>13.8</td><td>N/A</td></tr></tbody></table>
<p>We do get some conflicting results when we make this comparison. With 32 and 64 workers, the increasing rate test is actually slower than the queued reconciliation test. But if we increase to 96 workers, we can see that the increasing rate test results are faster. We were unable to compare with 128 workers as the Argo Workflows controller crashed when trying to run the queued reconciliation test. When investigating the cause of the crash, the logs have several messages like the following:</p>
<div class="language-log codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-log codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">Waited for 6.185558715s due to client-side throttling, not priority and fairness, request: DELETE:https://10.100.0.1:443/api/v1/namespaces/argoworkflows1/pods/hello-world-57cfda8a-dc8b-4854-83a0-05785fb25e4b-3gwthk</span><br></span></code></pre></div></div>
<p>These messages indicate that we should increase the Client QPS settings which we will evaluate in the next experiment.</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="experiment-3-client-qps-settings">Experiment 3: Client QPS Settings<a href="#experiment-3-client-qps-settings" class="hash-link" aria-label="Direct link to Experiment 3: Client QPS Settings" title="Direct link to Experiment 3: Client QPS Settings">â</a></h3>
<p>For this experiment, we set the number of workflow workers back to the default of 32. We will then increase the QPS/Burst by increments of 10/10, from 20/30 to 50/60. We chose to only increase by 10/10 because any large increase past 50/60 did not yield any performance improvements. We believe that this is partly because we kept the workers at 32.</p>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="initial-testing"><strong>Initial Testing</strong><a href="#initial-testing" class="hash-link" aria-label="Direct link to initial-testing" title="Direct link to initial-testing">â</a></h4>
<p><strong>Increasing Rate Test:</strong></p>
<p>The QPS/Burst settings had a significant impact on the increasing rate test. By increasing the QPS/Burst from 20/30 to 30/40, we see ~50% improvement in max workflows/min from 270 to 420. When we increase the QPS/Burst from 30/40 to 40/50, we see another 28% improvement in max workflows/min from 420 to 540. When increasing from 40/50 to 50/60 there was only an additional 5% improvement. For 32 workers, increasing past 50/60 did not yield any significant improvements to the max workflows/min.</p>
<table><thead><tr><th>QPS/Burst</th><th>Max workflows/minute</th></tr></thead><tbody><tr><td>20/30</td><td>270</td></tr><tr><td>30/40</td><td>420</td></tr><tr><td>40/50</td><td>540</td></tr><tr><td>50/60</td><td>570</td></tr></tbody></table>
<p><img decoding="async" loading="lazy" alt="Enter image alt description" src="/assets/images/ZgU_Image_3-9ca2e433fea080701af4ce97b19c38b2.png" width="1379" height="1049" class="img_ev3q"></p>
<p>When changing QPS/Burst, we need to also monitor the K8S API server. Looking at the K8S API server req/s, we see sustained 390 writes/sec and 85 read/sec.</p>
<p><img decoding="async" loading="lazy" alt="Enter image alt description" src="/assets/images/DNV_Image_4-182669a9a3fd061ba0b23f7f7c0cf017.png" width="939" height="786" class="img_ev3q"></p>
<p><strong>Queued Reconciliation Test:</strong></p>
<p>Again, the QPS/Burst settings make a big difference in the queued reconciliation test when compared to just changing the workflow workers. Starting from the default settings of 20/30, we see decreasing reconcile times from 19 mins to 12 mins to 8 mins and finally to 6 mins when setting the QPS/Burst to 50/60. The peak average latency also decreased from 4.79 mins to 1.94 mins. We did note that there was a higher peak avg latency with 30/40 vs 20/30 but if you examine the graph you can see a steeper drop in latency accounting for the shorter reconcile time. Similar to the increasing rate test, increasing the QPS/Burst further did not yield any improvements.</p>
<table><thead><tr><th>QPS/Burst</th><th>Peak avg latency (mins)</th><th>Reconcile time (mins)</th></tr></thead><tbody><tr><td>20/30</td><td>4.79</td><td>19</td></tr><tr><td>30/40</td><td>5.66</td><td>12</td></tr><tr><td>40/50</td><td>2.98</td><td>8</td></tr><tr><td>50/60</td><td>1.94</td><td>6</td></tr></tbody></table>
<p><img decoding="async" loading="lazy" alt="Enter image alt description" src="/assets/images/lGk_Image_5-7155dee2d602ff28c6ba4957a700c26a.png" width="1376" height="656" class="img_ev3q"></p>
<p>When looking at the K8S API server, we see peaks of up to 700 writes/sec and 200 reads/sec during the tests.</p>
<p><img decoding="async" loading="lazy" alt="Enter image alt description" src="/assets/images/Bpv_Image_6-c62a64840de7c331ae4a926dbe3232c8.png" width="947" height="791" class="img_ev3q"></p>
<p>When compared to the workflow workers testing, you can see increasing the QPS/Burst is able to push the K8S API server and improve Argo Workflows overall performance. We do see some diminishing returns when increasing QPS/Burst past 50/60 even though it appears that the K8S API server has plenty of capacity for additional load. For the next test, we will increase both the workflow workers with the QPS/burst to see how far we can push Argo Workflows and the K8s API server.</p>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="max-load-test"><strong>Max Load Test</strong><a href="#max-load-test" class="hash-link" aria-label="Direct link to max-load-test" title="Direct link to max-load-test">â</a></h4>
<p><strong>Increasing Rate Test:</strong></p>
<p>We increased the number of workers to 128 and QPS/burst to 60/70 and observed peak average latency of 54 secs and a reconciliation time of 5 mins. Increasing either the workers or QPS/Burst did not improve these numbers.</p>
<p><img decoding="async" loading="lazy" alt="Enter image alt description" src="/assets/images/czp_Image_7-c58e659986c95fa3f0542fc70c6c0bbd.png" width="1520" height="708" class="img_ev3q"></p>
<p>Looking at the K8s API server, we saw peaks of 800 writes/sec and 190 reads/sec.</p>
<p><img decoding="async" loading="lazy" alt="Enter image alt description" src="/assets/images/o0Z_Image_8-de223d0852717da7581e45b5b4a3ee6b.png" width="944" height="793" class="img_ev3q"></p>
<p><strong>Queued Reconciliation Test:</strong></p>
<p>Starting with 128 workers and QPS/Burst of 60/70, we were able to push Argo Workflows to 810 workflows/min. But past that point, there were no improvements with more workers or increased QPS/Burst limits.</p>
<p><img decoding="async" loading="lazy" alt="Enter image alt description" src="/assets/images/S1V_Image_9-8517f8a643c7bfaf787f916c9478746e.png" width="1532" height="1052" class="img_ev3q"></p>
<p>We can see increased K8s API server activity with sustained 700 writes/sec and 160 reads/sec.</p>
<p><img decoding="async" loading="lazy" alt="Enter image alt description" src="/assets/images/NRO_Image_10-84aacbe750ca5f604e939f2f628bcd8e.png" width="945" height="790" class="img_ev3q"></p>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="observations-from-experiment-3"><strong>Observations from Experiment 3</strong><a href="#observations-from-experiment-3" class="hash-link" aria-label="Direct link to observations-from-experiment-3" title="Direct link to observations-from-experiment-3">â</a></h4>
<p>One observation we made in the previous experiment with workflow workers is that the two different patterns of submitting workflows can be compared. We made that comparison again with the QPS/Burst tests and saw the following results:</p>
<table><thead><tr><th>QPS/Burst</th><th>Workers</th><th>Increasing rate test time to reconcile 5000 workflows (mins)</th><th>Reconcile time of 5000 workflows queued all at once (mins)</th></tr></thead><tbody><tr><td>20/30</td><td>32</td><td>18.5</td><td>19</td></tr><tr><td>30/40</td><td>32</td><td>11.9</td><td>12</td></tr><tr><td>50/60</td><td>32</td><td>9.2</td><td>8</td></tr><tr><td>60/70</td><td>32</td><td>8.7</td><td>6</td></tr><tr><td>70/80</td><td>128</td><td>6.1</td><td>5</td></tr></tbody></table>
<p>When we take the data about the comparison in experiment 1 with the data above, we can see a slight improvement in submitting all workflows together vs staggering them. We are not sure why this is the case and more experiments are required to understand this behavior.</p>
<p>It seems that we have hit a wall with 128 workers and a QPS/burst of 60/70 for a single Argo Workflows Controller. We will now evaluate Sharding and see if we can improve our performance from this point.</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="experiment-4-sharding">Experiment 4: Sharding<a href="#experiment-4-sharding" class="hash-link" aria-label="Direct link to Experiment 4: Sharding" title="Direct link to Experiment 4: Sharding">â</a></h3>
<p>For this experiment, we will evaluate 1 shard, 2 shards, and 5 shards of the Argo Workflows controller with the default settings. We will then try for a maximum load test utilizing workflow workers, QPS/burst, and sharding to see the maximum performance on our current infrastructure.</p>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="initial-testing-1"><strong>Initial Testing</strong><a href="#initial-testing-1" class="hash-link" aria-label="Direct link to initial-testing-1" title="Direct link to initial-testing-1">â</a></h4>
<p><strong>Increasing Rate Test:</strong></p>
<p>Sharding the Argo Workflows controller has a linear impact on performance with the increasing rate test. By increasing the number of shards from 1 to 2, we see a 100% improvement in max workflows/min from 270 to 540. When we increase the shards from 2 to 5, we see an additional 150% improvement in max workflows/min from 540 to 1350.</p>
<table><thead><tr><th>Shards</th><th>Max workflows/min</th></tr></thead><tbody><tr><td>1</td><td>270</td></tr><tr><td>2</td><td>540</td></tr><tr><td>5</td><td>1350</td></tr></tbody></table>
<p>One thing to note is that each shard is increased by 30 workflows/min when increasing the rate. This means that the difference between two rates with 2 shards * 30 = 60 workflows/min and the difference between two rates with 5 shards * 30 = 150 workflows/min. That is why for 2 shards when the max load was determined at 600 workflows/min, we go down 1 rate which is 600 - 60 = 540 workflows/min.</p>
<p><img decoding="async" loading="lazy" alt="Enter image alt description" src="/assets/images/WP9_Image_11-d8f7b5848f2adde883ab39b81f4d2cd0.png" width="1532" height="1038" class="img_ev3q"></p>
<p>You can see a significant impact on the K8s API server with sustained 1400 writes/sec and 300 reads/sec.</p>
<p><img decoding="async" loading="lazy" alt="Enter image alt description" src="/assets/images/3gj_Image_12-506b3b1f517fda7c68995a3a6eda6c33.png" width="940" height="789" class="img_ev3q"></p>
<p><strong>Queued Reconciliation Test:</strong></p>
<p>As shown in the Increasing Rate Test, sharding has a huge impact on performance for the queued reconciliation test. With 1 shard it takes 18 mins to reconcile 5000 workflows, while with 2 shards it takes 9 mins. With 5 shards the reconcile time is further reduced to 4 mins.</p>
<table><thead><tr><th>Shards</th><th>Peak avg latency (mins)</th><th>Reconcile time (mins)</th></tr></thead><tbody><tr><td>1</td><td>5.43</td><td>18</td></tr><tr><td>2</td><td>3.81</td><td>9</td></tr><tr><td>5</td><td>1.42</td><td>4</td></tr></tbody></table>
<p><img decoding="async" loading="lazy" alt="Enter image alt description" src="/assets/images/6Bi_Image_13-9f8b7d60ba060017942a0bd9fd4e6d57.png" width="1535" height="699" class="img_ev3q"></p>
<p>The impact on the K8s API server was not as significant when compared to previous experiments.</p>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="max-load-test-1"><strong>Max Load Test</strong><a href="#max-load-test-1" class="hash-link" aria-label="Direct link to max-load-test-1" title="Direct link to max-load-test-1">â</a></h4>
<p><strong>Increasing Rate Test:</strong></p>
<p>When increasing the workflow workers to 128, QPS/burst to 60/70 and shards to 5, the Argo Workflows controller is able to process up to 2100 workflows/min. Any higher than this seems to run into K8s API Priority and Fairness (APF) limits.</p>
<p><img decoding="async" loading="lazy" alt="Enter image alt description" src="/assets/images/ko7_Image_14-ef2863d49d1ec7088930b86125bf90e3.png" width="1524" height="700" class="img_ev3q"></p>
<p>When looking at the K8s API server, we are seeing significant impact with peaks of 1500 writes/sec and 350 reads/sec.</p>
<p><img decoding="async" loading="lazy" alt="Enter image alt description" src="/assets/images/HH7_Image_15-df838398f527e52ea9f83e49c25f7fa3.png" width="936" height="792" class="img_ev3q"></p>
<p>When investigating why we are unable to push higher on the K8s API server, we see that APF limits are coming into effect by looking at the apiserver_flowcontrol_current_inqueue_requests. This metric shows the number of requests waiting in the APF flowcontrol queue.</p>
<p><img decoding="async" loading="lazy" alt="Enter image alt description" src="/assets/images/7RZ_Image_16-d969ed38ee1615d676c3dad927c4d2a0.png" width="773" height="329" class="img_ev3q"></p>
<p><strong>Queued Reconciliation Test:</strong></p>
<p>With the max load settings, we observed that the peak workqueue latency is only 20 seconds and the reconcile time is 2 minutes.</p>
<p><img decoding="async" loading="lazy" alt="Enter image alt description" src="/assets/images/F2t_Image_17-b05c04273726be912e3ba7e4685dd3b2.png" width="1513" height="699" class="img_ev3q"></p>
<p>The impact on K8s API server is actually less than the previous max load queued reconciliation tests.</p>
<p><img decoding="async" loading="lazy" alt="Enter image alt description" src="/assets/images/05K_Image_18-2d3c1d9b1066c403190c38cd54b423df.png" width="943" height="795" class="img_ev3q"></p>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="observations-from-experiment-4"><strong>Observations from Experiment 4</strong><a href="#observations-from-experiment-4" class="hash-link" aria-label="Direct link to observations-from-experiment-4" title="Direct link to observations-from-experiment-4">â</a></h4>
<p>As we did in previous experiments, we again make the comparison between the two different load patterns:</p>
<table><thead><tr><th>Shards</th><th>Increasing rate test time to reconcile 5000 workflows (mins)</th><th>Reconcile time of 5000 workflows queued all at once (mins)</th></tr></thead><tbody><tr><td>1</td><td>18.5</td><td>18</td></tr><tr><td>2</td><td>9.2</td><td>9</td></tr><tr><td>5</td><td>3.7</td><td>4</td></tr><tr><td>Max load (5 shards)</td><td>2.3</td><td>2</td></tr></tbody></table>
<p>In general, it appears that submitting all workflows at once performs slightly better than submitting workflows at a steady rate. More experiments will need to be done to further investigate this behavior.</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="conclusion">Conclusion<a href="#conclusion" class="hash-link" aria-label="Direct link to Conclusion" title="Direct link to Conclusion">â</a></h2>
<p>In this blog post we discussed our initial efforts in documenting and understanding the scaling characteristics of the Argo Workflows controller. Our findings show that the existing mechanisms for increasing workflow workers, increasing client and burst QPS settings and sharding the controller can help Argo Workflows scale better. Another interesting observation is that we saw differences in performance with how you submit your workflows.  For the next set of experiments, we plan to evaluate more environmental variables and different types of workflows: multi-step and/or long running. Stay tuned for the report on our next round of experiments and reach out on the CNCF <a href="https://cloud-native.slack.com/archives/C04SURUPDL2" target="_blank" rel="noopener noreferrer">#argo-sig-scalability</a> Slack channel to get help optimizing for your use-cases and scenarios.</p></div><footer class="row docusaurus-mt-lg"><div class="col"><b>Tags:</b><ul class="tags_jXut padding--none margin-left--sm"><li class="tag_QGVx"><a rel="tag" class="tag_zVej tagRegular_sFm0" href="/blog/tags/workflows">workflows</a></li><li class="tag_QGVx"><a rel="tag" class="tag_zVej tagRegular_sFm0" href="/blog/tags/benchmarking">benchmarking</a></li><li class="tag_QGVx"><a rel="tag" class="tag_zVej tagRegular_sFm0" href="/blog/tags/scalability">scalability</a></li><li class="tag_QGVx"><a rel="tag" class="tag_zVej tagRegular_sFm0" href="/blog/tags/argo">argo</a></li></ul></div></footer></article><nav class="pagination-nav" aria-label="Blog list page navigation"></nav></main></div></div></div><footer class="theme-layout-footer footer footer--dark"><div class="container container-fluid"><div class="row footer__links"><div class="theme-layout-footer-column col footer__col"><div class="footer__title">DOCS</div><ul class="footer__items clean-list"><li class="footer__item"><a class="footer__link-item" href="/docs/overview/cnoe">Introduction</a></li><li class="footer__item"><a class="footer__link-item" href="/docs/contributing/aws-ref-impl-CONTRIBUTING">Contribute</a></li></ul></div><div class="theme-layout-footer-column col footer__col"><div class="footer__title">SOCIAL</div><ul class="footer__items clean-list"><li class="footer__item"><a href="https://cloud-native.slack.com/archives/C05TN9WFN5S" target="_blank" rel="noopener noreferrer" class="footer__link-item">Slack<svg width="13.5" height="13.5" aria-hidden="true" class="iconExternalLink_nPIU"><use href="#theme-svg-external-link"></use></svg></a></li><li class="footer__item"><a href="https://calendar.google.com/calendar/u/0/embed?src=064a2adfce866ccb02e61663a09f99147f22f06374e7a8994066bdc81e066986@group.calendar.google.com&amp;ctz=America/Los_Angeles" target="_blank" rel="noopener noreferrer" class="footer__link-item">Community Meeting Calendar<svg width="13.5" height="13.5" aria-hidden="true" class="iconExternalLink_nPIU"><use href="#theme-svg-external-link"></use></svg></a></li></ul></div><div class="theme-layout-footer-column col footer__col"><div class="footer__title">MORE</div><ul class="footer__items clean-list"><li class="footer__item"><a class="footer__link-item" href="/blog">Blog</a></li><li class="footer__item"><a href="https://github.com/cnoe-io" target="_blank" rel="noopener noreferrer" class="footer__link-item">GitHub<svg width="13.5" height="13.5" aria-hidden="true" class="iconExternalLink_nPIU"><use href="#theme-svg-external-link"></use></svg></a></li></ul></div></div><div class="footer__bottom text--center"><div class="footer__copyright">Copyright Â© 2025 CNOE</div></div></div></footer></div>
</body>
</html>