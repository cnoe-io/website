{"searchDocs":[{"title":"Argo CD Benchmarking - Pushing the Limits and Sharding Deep Dive","type":0,"sectionRef":"#","url":"/blog/argo-cd-application-scalability","content":"","keywords":"","version":null},{"title":"Introduction​","type":1,"pageTitle":"Argo CD Benchmarking - Pushing the Limits and Sharding Deep Dive","url":"/blog/argo-cd-application-scalability#introduction","content":" In Part 1 of our Argo CD benchmarking blog post, we analyzed the impacts of various Argo CD configuration parameters on the performance of Argo CD. In particular we measured the impact of status and operation processes, client QPS, burst QPS, and sharding algorithms on the overall synchronization and reconciliation behavior in Argo CD. We showed that using the right configuration and sharding strategy, particularly by properly setting client and burst QPS, as well as by splitting the workload across multiple workload clusters using Argo CD sharding, overall sync time can be improved by a factor of 4.  Here, and in Part 2 of our scalability work, we push our scalability experiments for Argo CD further. In particular, among other tests, we run our scalability metrics against a maximum of 500 workload clusters, deploying 50,000 Argo applications. This, to the best of our knowledge, sets the largest scalability testing ever done for Argo CD. We also report on a much deeper set of sharding experiments, utilizing different sharding algorithms for distribution of load across 100 workload clusters. While we report on running our experiments against a legacy sharding algorithm and a round robin algorithm that already exist in Argo CD 2.8, we also discuss results of workload distribution using 3 new sharding algorithms we developed in collaboration with RedHat, namely: a greedy minimum algorithm, a weighted ring hash algorithm, and a consistent hash with bounded loads algorithm. We show that, depending on the optimization goals one has in mind, choosing from the new sharding algorithms can improve CPU utilization by a factor of 3 and reduce application-to-shard rebalancing by a factor of 5, significantly improving the performance of a highly distributed and massively scaled Argo CD deployment.  ","version":null,"tagName":"h2"},{"title":"Experiment 1: How Client QPS/Burst QPS affects the Kubernetes API Server​","type":1,"pageTitle":"Argo CD Benchmarking - Pushing the Limits and Sharding Deep Dive","url":"/blog/argo-cd-application-scalability#experiment-1-how-client-qpsburst-qps-affects-the-kubernetes-api-server","content":" Objective:  The objective of the first experiment is to understand the impact of QPS &amp; Burst Rate parameters on 1/Kubernetes control plane for both the Argo CD cluster and the remote application clusters, and 2/ overall sync duration for Argo CD applications. To understand the impact on Kubernetes API server, we observed following control plane metrics:  Latency (apiserver_request_duration_seconds_bucket)Throughput (apiserver_request_total)Error Rate (apiserver_request_total{code=~&quot;[45]..&quot;}) for any request returning an error code 4xx or 5xx.  To analyze impact on application synchronization, we observed Sync Duration and No. of Goroutines Argo CD server metrics.  Test Infrastructure:  In terms of test infrastructure and workload configuration, we had one central Amazon EKS cluster with Argo CD Server running on it. This central cluster connected with three remote Amazon EKS clusters with each one of them hosting 5000 Argo CD applications. Each application is a Configmap (2KB) provisioned in a dedicated namespace. All of the four clusters, one central and three remote, had a dedicated monitoring stack composed of Prometheus and Grafana installed on them.  Observations:  Observation 1 - Impact on Argo CD application synchronization  The table and graphs below highlight the impact of QPS &amp; Burst Rate on “Sync Duration” as well as the average and maximum no. of goroutines active during the test run.  QPS\tBurst Rate\tSync Duration\tNo. of GoRoutines (Avg)\tNo. of GoRoutines (Max) 50\t100\t61.5 mins\t1760\t1810 100\t200\t29.5 mins\t2120\t2310 150\t300\t19.0 mins\t2520\t2760 200\t400\t18.0 mins\t2620\t2780 250\t500\t17.5 mins\t2590\t2760 300\t600\t18.0 mins\t2540\t2760    To summarize, during the test, we immediately observed ~52% reduction (from 61.5 mins to 29.5 mins) as we increased QPS &amp; Burst Rate from default values to 100 &amp; 200 respectively. This also correlated with corresponding increase in no. of Goroutines processing application synchronization requests. The benefit from increasing values of these parameters started providing diminishing returns with subsequent runs. Beyond QPS &amp; Burst rate of 150 &amp; 300 respectively, there wasn’t measurable improvement observed. This again correlated with number of Goroutines actively processing sync requests.  Observation 2 - Impact on central Amazon EKS cluster control plane hosting Argo CD Server  The table and graphs below highlights the impact of QPS &amp; Burst Rate on throughput and latency from Amazon EKS control plane hosting Argo CD Server. We can observe an increase in request rate per second to the Kubernetes control plane which is in line with previous observations related to increase in no. of goroutines processing the sync requests. The increased activity related to sync operations translates into increased requests to Amazon EKS control plane tapering off at QPS of 150 and Burst Rate of 300. Additional increase in QPS and Burst Rate parameters doesn’t noticeably impact request rate per second.  QPS\tBurst Rate\tRequest Rate (Max)\tLatency p50 (Max)\tLatency p90 (Max) 50\t100\t27.2 rps\t13.0 ms\t22.6 ms 100\t200\t31.9 rps\t13.3 ms\t23.1 ms 150\t300\t39.8 rps\t14.3 ms\t24.0 ms 200\t400\t41.4 rps\t14.9 ms\t24.4 ms 250\t500\t39.0 rps\t15.1 ms\t24.4 ms 300\t600\t40.7 rps\t16.4 ms\t34.5 ms  From a latency perspective, overall during the course of testing, average (p50) duration remained within range of 13 to 16.5 ms and p90 latency within 22 ms to 34 ms. The error rate remained consistently around ~0.22% with a brief spike to ~0.25% (increase of ~0.03%).  The relatively low latency numbers and low error rate (&lt;0.25%) indicates that Amazon EKS control plane was able to handle the load comfortably. Increasing QPS and Burst rate only would stretch the control plane to a limited extent indicating it still has resources to process additional requests as long as Argo CD server can generate request traffic.    Observation 3 - Impact on remote Amazon EKS cluster control plane hosting applications  We had similar observations regarding latency, throughput and error rate for Amazon EKS control plane of remote application clusters. These are the clusters hosting ~5000 Argo CD applications each and connected to Argo CD Server on the central Amazon EKS cluster. The throughput peaked at ~35 requests per second with QPS and burst rate of 150 &amp; 300 respectively. From an average latency perspective, it remained consistently within single digit millisecond hovering around ~5ms.    ","version":null,"tagName":"h2"},{"title":"Experiment 2: Revisiting Status/Operation Processors​","type":1,"pageTitle":"Argo CD Benchmarking - Pushing the Limits and Sharding Deep Dive","url":"/blog/argo-cd-application-scalability#experiment-2-revisiting-statusoperation-processors","content":" Objective:  The objective of the second experiment is to explore why status/operation processors did not have an effect on sync times of our previous experiments. It is possible that the simple nature of ConfigMap applications which takes &lt;1s to deploy is causing this behavior. Most real world applications would consist of tens to hundreds of resources taking longer to be deployed. During this experiment, we will simulate a more complex application which takes longer to deploy than the original ConfigMap application.  Test Infrastructure:  Central Argo CD cluster running on a single m5.2xlarge managing 100 application clusters. In order to simulate larger applications, each application will execute a PreSync job which waits 10 seconds before deploying the original ConfigMap application.  Example of the PreSync Job:  apiVersion: batch/v1 kind: Job metadata: name: before annotations: argocd.argoproj.io/hook: PreSync argocd.argoproj.io/hook-delete-policy: HookSucceeded spec: template: spec: containers: - name: sleep image: alpine:latest command: [&quot;sleep&quot;, &quot;10&quot;] restartPolicy: Never backoffLimit: 0   Observations:   Observation 1 - Syncing never finishes and require a restart of the application controller to continue syncing  The screenshot below shows that from the start of the sync test at 17:02 till around 17:41, the sync process was deadlocked. We observed no changes to synced apps and the app_operation_processing_queue was pinned at 10k operations.    Looking at the Argo CD console for a single application we see that the PreSync job finished 17 mins ago, but the application stayed in the Syncing phase.    Observation 2: There is a link between client QPS/burst QPS and operation/status processor settings  In order to fix the sync freezing issue, we increased the client QPS/burst QPS from the default 50/100 to 100/200. After the change we were able to collect data on operation/status processor settings.  operation/status processors: 25/50 Sync time: 45 mins\toperation/status processors: 50/100 Sync time: 30 mins   We can see that there is a link between status/operation processors and client QPS/burst QPS settings. Changing one or the other could be required to improve sync times and Argo CD performance depending on your environment. Our recommendation is to first change the status/operation processor settings. If you run into Argo CD locking up or the performance not increasing further, and you have sufficient resources, you can try increasing the client QPS/burst QPS. But as mentioned in the first experiment, ensure you are monitoring the k8s api-server.  ","version":null,"tagName":"h2"},{"title":"Experiment 3: Cluster Scaling​","type":1,"pageTitle":"Argo CD Benchmarking - Pushing the Limits and Sharding Deep Dive","url":"/blog/argo-cd-application-scalability#experiment-3-cluster-scaling","content":" Objective:  The following experiment is designed to test the compute demands of the Argo CD app controller managing clusters with more than 100 applications.  Test Infrastructure:  Central Argo CD cluster with 10 app controller shards running on a single m5.2xlarge node managing 100/250/500 application clusters and 10k 2KB ConfigMap applications.  Observations:  From earlier experiences, we can see that when managing 100 clusters, we are close to the limit of a single m5.2xlarge node. As we push further and to 250/500 clusters, we have two observations. The first observation is that the graph data is less smooth than the sync test of 100 clusters. This can indicate that Prometheus is running out of compute as Argo CD is consuming most of it. Please note that we are not using any resource limits/requests in our experiments. If proper resource limits/requests are set, most likely we would only see performance issues with Argo CD and not Prometheus, when operating at the limit of your compute resources. The second observation is that on both the 250/500 cluster tests, there are some drop off in metric data. For the 250 cluster test, there is a blip at the 16:16 mark for Memory Usage. For the 500 cluster test there are blips in data at the 21.05 mark on the Workqueue depth, CPU usage, and Memory usage. In spite of these observations, the sync process completes in a reasonable time.  Clusters: 100 Sync time: 9 mins\tClusters: 250 Sync time: 9 mins\tClusters: 500 Sync time: 11 mins   From this experiment, you can see that as you approach the limit of your compute resources, Argo CD and other applications running in your k8s environment could experience issues. It is recommended that you set proper resource limits/requests for your monitoring stack to ensure you have insights into what could be causing your performance issues.  ","version":null,"tagName":"h2"},{"title":"Experiment 4: Application Scaling​","type":1,"pageTitle":"Argo CD Benchmarking - Pushing the Limits and Sharding Deep Dive","url":"/blog/argo-cd-application-scalability#experiment-4-application-scaling","content":" Objective:  This experiment is meant to push the Argo CD app controller beyond 10k applications. As the previous rounds of experiments were performed with 10k apps, the intention of these experiments is to scale the Argo CD app controller up to 50k apps.  Test Infrastructure:  We will be performing this experiment on a Central Argo CD cluster with 10 app controller shards and 500 downstream application clusters. As we scale up the applications up to 10k,15k,20k,25k,30k,50k 2KB ConfigMap applications, we will add additional m5.2xlarge node(s) to the Argo CD cluster.  Observations:  Sync test at 15k applications with a single m5.2xlarge. You can see blips in data indicating unhealthy behavior on the cluster.\tCPU and Memory Usage is near 100% utilization of 8 vCPUs and 30 GB of memory.\tAfter adding another node for a total of two m5.2xlarge, we were able to perform a sync in 9 mins.   After adding another node, we were able to continue our application scaling tests. You can see in the graphs below that syncing 20k and 25k apps was not a problem. The sync test of 30k apps shown on the third graph shows some blips in data, indicating that we are at the limits of two nodes.  Apps: 20000 Sync time: 12 mins\tApps: 25000 Sync time: 11 mins\tApps: 30000 Sync time: 19 mins   For the final test in this experiment, we pushed the cluster to sync 50k apps.  While the cluster was able to manage reconciliation for the 50k apps as shown by a stable Sync Status graph from 8:40, when we start the sync at the 9:02 mark, you can see unhealthy behavior in the graph data.\tFrom examining the CPU/Memory Usage, you can see we have 100% CPU utilization across the cluster.\tAfter scaling the cluster to three m5.2xlarge nodes, we were able to perform a sync in 22 mins.   From the scaling tests, we can see that the Argo CD app controller scales effectively by adding compute resources as we increase the number of applications to sync.  ","version":null,"tagName":"h2"},{"title":"Experiment 5: How Many Shards?​","type":1,"pageTitle":"Argo CD Benchmarking - Pushing the Limits and Sharding Deep Dive","url":"/blog/argo-cd-application-scalability#experiment-5-how-many-shards","content":" Objective:  In previous experiments, we utilized ten app controller shards running across multiple nodes. In this experiment, we will explore how the number of app controller shards affect performance.  Test Infrastructure:  Central Argo CD cluster with 3, 6, 9 app controller shards running on 3 m5.2xlarge node(s) managing 500 application clusters and 50k 2KB ConfigMap applications.  Observations:  For the baseline of three shards it took 75 mins to perform a sync. Adding additional shards saw further improvements with a sync time of 37 mins for six shards and a sync time of 21 mins for nine shards. Further increasing shards beyond nine did not yield any improvements.  Shards: 3 Sync time: 75 mins\tShards: 6 Sync time: 37 mins\tShards: 9 Sync time: 21 mins   Looking at the CPU and Memory utilization, you can see that adding shards can improve performance only if there are free resources to consume. With the baseline of three shards, CPU utilization of the nodes are well below eight vCPU that each node is allocated. As we add more shards, we can see CPU utilization increasing until we are close to 100% CPU Utilization with nine shards. Adding any more shards would not yield any performance benefits unless we add more nodes.  Shards: 3\tShards: 6\tShards: 9   From the experiments, the Argo CD app controller sharding mechanism is able to scale as you add more compute resources. Sharding allows both horizontal and vertical scaling. As you add more shards, you can horizontally scale by adding more nodes or vertically scale by utilizing a larger node with more compute resources.  ","version":null,"tagName":"h2"},{"title":"Experiment 6: Sharding Deep Dive​","type":1,"pageTitle":"Argo CD Benchmarking - Pushing the Limits and Sharding Deep Dive","url":"/blog/argo-cd-application-scalability#experiment-6-sharding-deep-dive","content":" Objective:  With the release of Argo CD 2.8, a new sharding algorithm: round-robin was released. The existing legacy sharding algorithm performed a modulo of the number of replicas and the hash sum of the cluster id to determine the shard that should manage the cluster. This led to an imbalance in the number of clusters being managed by each shard. The new round-robin sharding algorithm is supposed to ensure an equal distribution of clusters being managed by each shard. We will also introduce 3 new algorithms: greedy minimum, weighted ring hash, and consistent hash with bounded loads. This experiment will evaluate all the algorithms on shard balance, application distribution and rebalancing on changes to the environment.  Test Infrastructure:  Central Argo CD cluster with 10 app controller shards running on 1 m5.2xlarge node managing 100 application clusters and 10k 2KB ConfigMap applications.  Observations:  Note: For all the observations, we start monitoring-period when we see items in the operations queue. We end the monitoring-period when all the applications are synced. We then look at the avg metric of CPU/Memory usage during the monitoring-period.  Legacy  The graph below shows the CPU Usage/Memory Usage of the 10 different Argo CD App Controller shards. Looking at the avg, you can see a large variation to how much each shard is utilizing its resources. To make an accurate comparison between the different sharding methods, we calculate the variability by determining the range of the data for both avg CPU usage and Memory usage. The CPU usage variability is calculated by taking the shard with the highest CPU usage and subtracting it from the shard with the least CPU usage: 0.55 - 0.23 = 0.32. The Memory usage variability is 452 MiB - 225 MiB = 227 MiB.  Variability:  CPU: 0.32 Memory: 227 MiB    Round-Robin  With the newly introduced Round-Robin algorithm, you can see improved balance across the shards.  Variability:  CPU: 0.02 Memory: 110 MiB    Better but not perfect  The new round-robin algorithm does a better job of keeping the number of clusters balanced across the shards. But in a real world environment, you would not have an equal number of applications running on each cluster and the work done by each shard is determined not by the number of clusters, but the number of applications. A new experiment was run which deploys a random number of applications to each cluster with the results below. Even with the round-robin algorithm, you can see some high variability in CPU/Memory usage.  Variability:  CPU: 0.27 Memory: 136 MiB    Greedy Minimum Algorithm, sharding by the Number of Apps  A new algorithm is introduced in order to shard by the number of applications that are running on each cluster. It utilizes a greedy minimum algorithm to always choose the shard with the least number of apps when assigning shards. A description of the algorithm is shown below:  Iterate through the cluster list:  1. Determine the number of applications per cluster. 2. Find the shard with the least number of applications. 3. Add the number of applications to the assigned shard.   The same experiment with a random number of applications running on each cluster is run again with the results shown below. With the new algorithm, there is better balance across the shards.  Variability:  CPU: 0.06 Memory: 109 MiB    While there is better balance when utilizing the greedy minimum algorithm, there is an issue when changing any aspect of the Argo CD sharding parameters. If you are adding shards, removing shards, adding clusters and/or removing clusters, the algorithm can trigger large scale changes in the shard assignments. Changes to the shard assignments cause shards to waste resources when switching to manage new clusters. This is especially true when utilizing ephemeral clusters in AI/ML training and big data operations where clusters come and go. Starting from the previous experiment from before, we changed the number of shards from 10 to 9 and observed over 75 cluster to shard assignment changes out of 100 clusters excluding the changes associated with the removed shard.  Weighted Ring Hash  In order to decrease the number of shard assignment changes, a well known method called consistent hashing is explored for our use case (Reference). Consistent hashing algorithms utilize a ring hash to determine distribution decisions. This method is already widely utilized by network load balancing applications to evenly distribute traffic in a distributed manner independent of the number of servers/nodes. By utilizing a ring hash algorithm to determine shard assignments, we were able to decrease the number of shard assignment changes when we changed the number of shards from 10 to 9. We observed 48 cluster to shard assignment changes, excluding the changes associated with the removed shard.    To ensure balance, weighting is applied at each shard assignment to ensure the shard with the least number of apps is given the highest weight when choosing shards for assignment. The balancing is not perfect as you can see that CPU variability has increased from the greedy minimum algorithm of 0.06 to 0.12.  Variability:  CPU: 0.12 Memory: 163 MiB  Consistent Hash with Bounded Loads  The ring hash algorithm was never designed to allow dynamically updating the weights based on load. While we were able to utilize it for this purpose, we looked at another algorithm called Consistent Hashing with Bounded Loads (Reference) which looks to solve the problem of consistent hashing and load uniformity. By utilizing this new algorithm, we were able to significantly decrease the redistribution of cluster to shard assignments. When we change the number of shards from 10 to 9, we only observed 15 cluster to shard assignment changes excluding the changes associated with the removed shard.    The trade off is slightly worse cluster/app balancing than the weighted ring hash which increased CPU variability from 0.12 to 0.17.  Variability:  CPU: 0.17 Memory:\t131 MiB  There are no direct recommendations about which algorithm you should utilize, as each of them have their pros and cons. You should evaluate each for your environment whether you are looking for strict balancing of clusters/apps across the shards or whether you want to minimize the impact of making frequent changes to your Argo CD environment.  ","version":null,"tagName":"h2"},{"title":"Conclusion​","type":1,"pageTitle":"Argo CD Benchmarking - Pushing the Limits and Sharding Deep Dive","url":"/blog/argo-cd-application-scalability#conclusion","content":" In this blog post, we continued our scalability tests of the Argo CD app controller by answering some questions we had from our first scalability tests about the common scalability parameters. We showed how QPS/Burst QPS affects the k8s api server, determined why status/operation processors did not affect our previous scalability tests, and how those parameters are linked together. We then continued our scalability tests by pushing the Argo CD app controller to 500 clusters and 50,000 apps. We ended our tests by showing that a key component of scaling the Argo CD app controller is how it performs sharding. By doing a deep dive into how the app controller performs sharding we also determined some ways to improve sharding by adding in and evaluating new sharding algorithms. We are currently evaluating how to contribute these changes back to Argo CD. Stay tuned for those contributions and reach out on the CNCF #argo-sig-scalability or the #cnoe-interest Slack channel to get help optimizing for your use-cases and scenarios. ","version":null,"tagName":"h2"},{"title":"Argo Workflows Controller Scalability Testing on Amazon EKS","type":0,"sectionRef":"#","url":"/blog/argo-workflow-scalability","content":"","keywords":"","version":null},{"title":"Introduction​","type":1,"pageTitle":"Argo Workflows Controller Scalability Testing on Amazon EKS","url":"/blog/argo-workflow-scalability#introduction","content":" In our earlier blog posts, we have discussed scalability tests for Argo CD, where in two consecutive experiments, we pushed the limits of Argo CD to deploy 10,000 applications on ~100 clusters and then 50,000 applications on 500 clusters along with configuration and fine-tuning required to make Argo CD scale effectively. Argo CD deployments, however, do not happen in isolation, and similar to a CNOE stack, Argo CD is often deployed on a cluster along with other tooling which collectively contribute to the performance and scalability bottlenecks we see users run into.  Argo Workflows is one common tool we often see users deploy alongside Argo CD to enable workflow executions (e.g. building images, running tests, cutting releases, etc). Our early experiments with Argo Workflows revealed that, if not tuned properly, it can negatively impact the scalability of a given Kubernetes cluster, particularly if the Kubernetes cluster happens to be the control cluster managing developer workflows across a large group of users. A real world example of some of the scaling challenges you can encounter with Argo Workflows is explored in our recent ArgoCon talk: Key Takeaways from Scaling Adobe's CI/CD Solution to Support 50K Argo CD Apps.  For us to better understand the limitations and tuning requirements for Argo Workflows, in this blog post we publish details on the scalability experiments we ran for Argo Workflows executing Workflows in two different load patterns: increasing rate up to 2100 workflows/min and queued reconciliation of 5000 workflows on an Amazon EKS cluster with 50x m5.large nodes. We show the correlation between the various Argo Workflow's knobs and controls and the processing time as well as performance improvements you can get by determining how you supply the workflows to the control plane.  ","version":null,"tagName":"h2"},{"title":"Test Parameters​","type":1,"pageTitle":"Argo Workflows Controller Scalability Testing on Amazon EKS","url":"/blog/argo-workflow-scalability#test-parameters","content":" ","version":null,"tagName":"h2"},{"title":"Test Workflow​","type":1,"pageTitle":"Argo Workflows Controller Scalability Testing on Amazon EKS","url":"/blog/argo-workflow-scalability#test-workflow","content":" The test workflow is based on the lightweight whalesay container from docker which prints out some text and ASCII art to the terminal. The reason we chose a lightweight container is that we wanted to stress the Argo Workflows controller in managing the Workflow lifecycle (pod creation, scheduling, and cleanup) and minimize the extra overhead on the Kubernetes control plane in dealing with the data plane workloads. An example of the Workflow is below:  var helloWorldWorkflow = wfv1.Workflow{ ObjectMeta: metav1.ObjectMeta{ GenerateName: &quot;hello-world-&quot;, }, Spec: wfv1.WorkflowSpec{ Entrypoint: &quot;whalesay&quot;, ServiceAccountName: &quot;argo&quot;, Templates: []wfv1.Template{ { Name: &quot;whalesay&quot;, Container: &amp;corev1.Container{ Image: &quot;docker/whalesay:latest&quot;, Command: []string{&quot;cowsay&quot;, &quot;hello world&quot;}, }, }, }, PodGC: &amp;wfv1.PodGC{ Strategy: &quot;OnPodSuccess&quot;, }, }, }   ","version":null,"tagName":"h3"},{"title":"Argo Workflows Settings​","type":1,"pageTitle":"Argo Workflows Controller Scalability Testing on Amazon EKS","url":"/blog/argo-workflow-scalability#argo-workflows-settings","content":" We will be detailing how each of these settings affect Argo Workflow in various experiments later in this blog post.  Controller workers: Argo Workflows controller utilizes different workers for various operations in a Workflow lifecycle. We will be looking at t types of workers for our scalability testing. workflow-workers (default: 32): These workers are threads in a single Argo Workflows controller that reconcile Argo Workflow Custom Resources (CRs). When a Workflow is created, a workflow-worker will handle the end-to-end operations of the Workflow from ensuring the pod is scheduled to ensuring the pod has finished. The number of workers can be specified by passing the --workflow-workers flag to the controller. pod-cleanup-workers (default: 4): These workers clean up finished Workflows. When a Workflow has finished executing, depending on your clean-up settings, a pod-cleanup-worker will handle cleaning up the pod from the Workflow. The number of workers can be specified by passing the --pod-cleanup-workers flag to the controller. Client queries per second (QPS)/Burst QPS settings (default: 20/30): These settings control when the Argo Workflows controller’s Kubernetes (K8s) client starts to throttle requests to the K8S API server. The client QPS setting is for limiting sustained QPS for the k8s client while burst QPS is for allowing a burst request rate in excess of the client QPS for a short period of time. The client QPS/burst QPS can be set by passing the --qps and --burst flag to the controller. Sharding: Sharding with multiple Argo Workflows controllers is possible by running each controller in its own namespace. The controller would only reconcile Workflows submitted in that particular namespace. The namespace of each controller can be specified with the --namespaced flag.  ","version":null,"tagName":"h3"},{"title":"Key Metrics​","type":1,"pageTitle":"Argo Workflows Controller Scalability Testing on Amazon EKS","url":"/blog/argo-workflow-scalability#key-metrics","content":" We chose a set of key metrics for the scalability testing because we wanted to measure how many workflows the Argo Workflows controller can reconcile and process. We will also be looking into K8s control plane metrics which might indicate your control plane cannot keep up with the Argo Workflows workload.   Workqueue depth: The workqueue depth shows workflows which have not been reconciled. If the depth starts to increase, it indicates that the Argo Workflows controller is unable to handle the submission rate of Workflows. Workqueue latency: The workqueue latency is the average time workflows spent waiting in the workqueue. A lower value indicates that the Argo Workflows controller is processing workflows faster so that they are not waiting in the workqueue. K8S api server requests per second: The read and write requests per second being made to the K8S api server.  We didn’t include CPU/Memory as a key metric because during our testing we did not see any significant impacts to both. Most likely because of our simplistic workflows utilized for this benchmark.  ","version":null,"tagName":"h2"},{"title":"Environment​","type":1,"pageTitle":"Argo Workflows Controller Scalability Testing on Amazon EKS","url":"/blog/argo-workflow-scalability#environment","content":" We ran the experiments in an AWS environment utilizing a single Amazon EKS cluster. The Kubernetes version is 1.27 and Argo Workflows version is 3.5.4. No resource quotas were utilized on the Argo Workflows controller. For the cluster, we will start by provisioning 1x m5.8xlarge Amazon Elastic Compute Cloud (Amazon EC2) instances which will run the Argo Workflows controller and 50x m5.large instances for executing workflows. The number of execution instances is sufficient to run all 5000 workflows in parallel to ensure that pods are not waiting on resources to execute. Monitoring and metrics for Argo Workflows were provided by Prometheus/Grafana.   ","version":null,"tagName":"h2"},{"title":"Methodology​","type":1,"pageTitle":"Argo Workflows Controller Scalability Testing on Amazon EKS","url":"/blog/argo-workflow-scalability#methodology","content":" There will be two types of load patterns evaluated:  Increasing Rate Test: Workflows will be submitted at an increasing rate (workflows/min) until the Argo Workflows controller cannot keep up. The state at which the controller cannot keep up is when there are &gt;0 workflows in the workflow queue or there is increasing queue latency. That rate of Workflow submissions will be noted as the maximum rate at which the Argo Workflows can be processed with the current settings.  **Queued Reconciliation Test: **5000 workflows are submitted in less than minute. Metrics will be monitored from when the Argo Workflows controller starts processing workflows to when it has reconciled all 5000 workflows. The number of nodes is sufficient for running all the workflows simultaneously.  ","version":null,"tagName":"h2"},{"title":"Experiments​","type":1,"pageTitle":"Argo Workflows Controller Scalability Testing on Amazon EKS","url":"/blog/argo-workflow-scalability#experiments","content":" ","version":null,"tagName":"h2"},{"title":"Experiment 1: Baseline​","type":1,"pageTitle":"Argo Workflows Controller Scalability Testing on Amazon EKS","url":"/blog/argo-workflow-scalability#experiment-1-baseline","content":" In our baseline experiment, we are running in a single Argo Workflows shard (namespace) with default settings.  Increasing Rate Test:  As you can see below, the Argo Workflows controller can process up to 270 workflows/min. The average workqueue latency and workqueue depth are nearly zero. At 300 workflows/min, workqueue latency and workqueue depth starts to increase.    Queued Reconciliation Test:  It takes around 17 mins to reconcile 5000 workflows and peak avg workqueue latency was 5.38 minutes.    ","version":null,"tagName":"h3"},{"title":"Experiment 2: Workflow Workers​","type":1,"pageTitle":"Argo Workflows Controller Scalability Testing on Amazon EKS","url":"/blog/argo-workflow-scalability#experiment-2-workflow-workers","content":" For this experiment, we increase the number of workflow workers from the default of 32 to 128 where the workers use the maximum QPS and burst settings available to them. We also had to increase the number of pod-cleanup-workers to 32 as the Argo Workflows controller was experiencing some instability, where the controller pod was consistently crashing with the default value of 4.  Increasing Rate Test:  For the increasing workflow rate test, we can see exactly when the number of workflow workers is not sufficient to process the load. Both workqueue latency and depth start to increase indicating that workflows are waiting to be reconciled. When we increase the number of workers, the controller is able to reconcile the current load until an additional load is placed on it. For 32 workers, that limit is 300 workflows/min. When we increase the number of workers to 64, it is able to process that load until load is increased to 330 workflows/min. Then we increase the number of workers to 96 and it can process the additional load again. When we increase to 360 workflows/min, we need to bump the number of workers to 128.  Workers\tMax workflows/minute32\t270 64\t300 96\t330 128\t360    For the K8S api server, we see sustained 180 writes/sec and 70 reads/sec during the increasing rate tests.    Queued Reconciliation Test:  For the queued reconciliation test, the time it took to reconcile all the workflows did not change significantly. With 32 workers it took 17 mins to reconcile while with 96 workers it took 16 mins. The peak workqueue latency did decrease from 5.38 mins with 32 workers to 3.19 mins with 96 workers. With 128 workers, the Argo Workflows controller kept crashing.  Workers\tPeak avg latency (mins)\tReconcile time (mins)32\t5.38\t17 64\t5.06\t18 96\t3.19\t16 128\tN/A\tN/A    For the K8S api server, we see peaks of up to 260 writes/sec and 90 reads/sec during the queued reconciliation tests. You notice for the last test that there is no K8S api server activity as the Argo Workflows controller was misbehaving due to client-side throttling.    Observations from Experiment 2:​  Workers play a big part in how fast the Argo Workflows controller is able to reconcile the rate of workflows being submitted. If you are observing workflow latency and backing up the workqueue depth, changing the number of workers is a potential way to improve performance. There are a few observations that we want to call out. One is that if we compare the two different patterns, one where we submit workflows at a constant rate and one in which we load up the workqueue all at once, we can see variations in calculated throughput. We can actually calculate the time it takes to reconcile 5000 apps utilizing the increasing rate test results and compare them to the queued reconciliation test.  Workers\tIncreasing rate test time to reconciling 5000 workflows (mins)\tReconcile time of 5000 workflows queued all at once (mins)32\t18.5\t17 64\t16.6\t18 96\t15.1\t16 128\t13.8\tN/A  We do get some conflicting results when we make this comparison. With 32 and 64 workers, the increasing rate test is actually slower than the queued reconciliation test. But if we increase to 96 workers, we can see that the increasing rate test results are faster. We were unable to compare with 128 workers as the Argo Workflows controller crashed when trying to run the queued reconciliation test. When investigating the cause of the crash, the logs have several messages like the following:  Waited for 6.185558715s due to client-side throttling, not priority and fairness, request: DELETE:https://10.100.0.1:443/api/v1/namespaces/argoworkflows1/pods/hello-world-57cfda8a-dc8b-4854-83a0-05785fb25e4b-3gwthk   These messages indicate that we should increase the Client QPS settings which we will evaluate in the next experiment.  ","version":null,"tagName":"h3"},{"title":"Experiment 3: Client QPS Settings​","type":1,"pageTitle":"Argo Workflows Controller Scalability Testing on Amazon EKS","url":"/blog/argo-workflow-scalability#experiment-3-client-qps-settings","content":" For this experiment, we set the number of workflow workers back to the default of 32. We will then increase the QPS/Burst by increments of 10/10, from 20/30 to 50/60. We chose to only increase by 10/10 because any large increase past 50/60 did not yield any performance improvements. We believe that this is partly because we kept the workers at 32.  Initial Testing​  Increasing Rate Test:  The QPS/Burst settings had a significant impact on the increasing rate test. By increasing the QPS/Burst from 20/30 to 30/40, we see ~50% improvement in max workflows/min from 270 to 420. When we increase the QPS/Burst from 30/40 to 40/50, we see another 28% improvement in max workflows/min from 420 to 540. When increasing from 40/50 to 50/60 there was only an additional 5% improvement. For 32 workers, increasing past 50/60 did not yield any significant improvements to the max workflows/min.  QPS/Burst\tMax workflows/minute20/30\t270 30/40\t420 40/50\t540 50/60\t570    When changing QPS/Burst, we need to also monitor the K8S API server. Looking at the K8S API server req/s, we see sustained 390 writes/sec and 85 read/sec.    Queued Reconciliation Test:  Again, the QPS/Burst settings make a big difference in the queued reconciliation test when compared to just changing the workflow workers. Starting from the default settings of 20/30, we see decreasing reconcile times from 19 mins to 12 mins to 8 mins and finally to 6 mins when setting the QPS/Burst to 50/60. The peak average latency also decreased from 4.79 mins to 1.94 mins. We did note that there was a higher peak avg latency with 30/40 vs 20/30 but if you examine the graph you can see a steeper drop in latency accounting for the shorter reconcile time. Similar to the increasing rate test, increasing the QPS/Burst further did not yield any improvements.  QPS/Burst\tPeak avg latency (mins)\tReconcile time (mins)20/30\t4.79\t19 30/40\t5.66\t12 40/50\t2.98\t8 50/60\t1.94\t6    When looking at the K8S API server, we see peaks of up to 700 writes/sec and 200 reads/sec during the tests.    When compared to the workflow workers testing, you can see increasing the QPS/Burst is able to push the K8S API server and improve Argo Workflows overall performance. We do see some diminishing returns when increasing QPS/Burst past 50/60 even though it appears that the K8S API server has plenty of capacity for additional load. For the next test, we will increase both the workflow workers with the QPS/burst to see how far we can push Argo Workflows and the K8s API server.  Max Load Test​  Increasing Rate Test:  We increased the number of workers to 128 and QPS/burst to 60/70 and observed peak average latency of 54 secs and a reconciliation time of 5 mins. Increasing either the workers or QPS/Burst did not improve these numbers.    Looking at the K8s API server, we saw peaks of 800 writes/sec and 190 reads/sec.    Queued Reconciliation Test:  Starting with 128 workers and QPS/Burst of 60/70, we were able to push Argo Workflows to 810 workflows/min. But past that point, there were no improvements with more workers or increased QPS/Burst limits.    We can see increased K8s API server activity with sustained 700 writes/sec and 160 reads/sec.    Observations from Experiment 3​  One observation we made in the previous experiment with workflow workers is that the two different patterns of submitting workflows can be compared. We made that comparison again with the QPS/Burst tests and saw the following results:  QPS/Burst\tWorkers\tIncreasing rate test time to reconcile 5000 workflows (mins)\tReconcile time of 5000 workflows queued all at once (mins)20/30\t32\t18.5\t19 30/40\t32\t11.9\t12 50/60\t32\t9.2\t8 60/70\t32\t8.7\t6 70/80\t128\t6.1\t5  When we take the data about the comparison in experiment 1 with the data above, we can see a slight improvement in submitting all workflows together vs staggering them. We are not sure why this is the case and more experiments are required to understand this behavior.  It seems that we have hit a wall with 128 workers and a QPS/burst of 60/70 for a single Argo Workflows Controller. We will now evaluate Sharding and see if we can improve our performance from this point.  ","version":null,"tagName":"h3"},{"title":"Experiment 4: Sharding​","type":1,"pageTitle":"Argo Workflows Controller Scalability Testing on Amazon EKS","url":"/blog/argo-workflow-scalability#experiment-4-sharding","content":" For this experiment, we will evaluate 1 shard, 2 shards, and 5 shards of the Argo Workflows controller with the default settings. We will then try for a maximum load test utilizing workflow workers, QPS/burst, and sharding to see the maximum performance on our current infrastructure.  Initial Testing​  Increasing Rate Test:  Sharding the Argo Workflows controller has a linear impact on performance with the increasing rate test. By increasing the number of shards from 1 to 2, we see a 100% improvement in max workflows/min from 270 to 540. When we increase the shards from 2 to 5, we see an additional 150% improvement in max workflows/min from 540 to 1350.  Shards\tMax workflows/min1\t270 2\t540 5\t1350  One thing to note is that each shard is increased by 30 workflows/min when increasing the rate. This means that the difference between two rates with 2 shards * 30 = 60 workflows/min and the difference between two rates with 5 shards * 30 = 150 workflows/min. That is why for 2 shards when the max load was determined at 600 workflows/min, we go down 1 rate which is 600 - 60 = 540 workflows/min.    You can see a significant impact on the K8s API server with sustained 1400 writes/sec and 300 reads/sec.    Queued Reconciliation Test:  As shown in the Increasing Rate Test, sharding has a huge impact on performance for the queued reconciliation test. With 1 shard it takes 18 mins to reconcile 5000 workflows, while with 2 shards it takes 9 mins. With 5 shards the reconcile time is further reduced to 4 mins.  Shards\tPeak avg latency (mins)\tReconcile time (mins)1\t5.43\t18 2\t3.81\t9 5\t1.42\t4    The impact on the K8s API server was not as significant when compared to previous experiments.  Max Load Test​  Increasing Rate Test:  When increasing the workflow workers to 128, QPS/burst to 60/70 and shards to 5, the Argo Workflows controller is able to process up to 2100 workflows/min. Any higher than this seems to run into K8s API Priority and Fairness (APF) limits.    When looking at the K8s API server, we are seeing significant impact with peaks of 1500 writes/sec and 350 reads/sec.    When investigating why we are unable to push higher on the K8s API server, we see that APF limits are coming into effect by looking at the apiserver_flowcontrol_current_inqueue_requests. This metric shows the number of requests waiting in the APF flowcontrol queue.    Queued Reconciliation Test:  With the max load settings, we observed that the peak workqueue latency is only 20 seconds and the reconcile time is 2 minutes.    The impact on K8s API server is actually less than the previous max load queued reconciliation tests.    Observations from Experiment 4​  As we did in previous experiments, we again make the comparison between the two different load patterns:  Shards\tIncreasing rate test time to reconcile 5000 workflows (mins)\tReconcile time of 5000 workflows queued all at once (mins)1\t18.5\t18 2\t9.2\t9 5\t3.7\t4 Max load (5 shards)\t2.3\t2  In general, it appears that submitting all workflows at once performs slightly better than submitting workflows at a steady rate. More experiments will need to be done to further investigate this behavior.  ","version":null,"tagName":"h3"},{"title":"Conclusion​","type":1,"pageTitle":"Argo Workflows Controller Scalability Testing on Amazon EKS","url":"/blog/argo-workflow-scalability#conclusion","content":" In this blog post we discussed our initial efforts in documenting and understanding the scaling characteristics of the Argo Workflows controller. Our findings show that the existing mechanisms for increasing workflow workers, increasing client and burst QPS settings and sharding the controller can help Argo Workflows scale better. Another interesting observation is that we saw differences in performance with how you submit your workflows. For the next set of experiments, we plan to evaluate more environmental variables and different types of workflows: multi-step and/or long running. Stay tuned for the report on our next round of experiments and reach out on the CNCF #argo-sig-scalability Slack channel to get help optimizing for your use-cases and scenarios. ","version":null,"tagName":"h2"},{"title":"Simplifying IDP Deployment and Local Development","type":0,"sectionRef":"#","url":"/blog/intro-to-idpbuilder","content":"","keywords":"","version":null},{"title":"Demo your own IDP implementation​","type":1,"pageTitle":"Simplifying IDP Deployment and Local Development","url":"/blog/intro-to-idpbuilder#demo-your-own-idp-implementation","content":" idpBuilder comes with a set of technologies that enables GitOps workflows all contained within the ephemeral environment. Think of building your IDP solution in a box. It does this by provisioning a kind cluster, Gitea server, ArgoCD, and ingress-nginx. See our documentation site for more information.  in addition, idpbuilder can copy files and Kubernetes manifests checked into Git repositories to the in-cluster Gitrea repositories. Once copied to the in-cluster repositories, ArgoCD can use them to deploy your solutions in minutes. We have examples of this in the Stacks repository.. You can run them in your browser using Codespaces as well. This approach also allows you to experiment with configuration changes and code changes without changing files checked into the external repositories because everything is contained in the cluster.  Carlos Santana does an excellent job of show this in his video. https://www.youtube.com/watch?v=e6Fvivx4Aw8  ","version":null,"tagName":"h2"},{"title":"Local Development and CI integrations​","type":1,"pageTitle":"Simplifying IDP Deployment and Local Development","url":"/blog/intro-to-idpbuilder#local-development-and-ci-integrations","content":" Due to the number of technologies involved and the complexity in integrating them, many organizations struggle with fragmented development environments. Different teams often work in silos, using disparate tools and workflows. This fragmentation is a major barrier for organizations hoping to create cohesive internal developer platforms as it is difficult to design and develop features which span multiple capabilities. Furthermore, the lack of a reference development environment leads to significant inefficiencies including slower development cycles, especially for cross-capability functionality. idpBuilder can set up identical environments for local development and CI pipelines. With idpBuilder, you get:  Reduced &quot;It Works on My Machine&quot; Syndrome: With consistent environments, discrepancies between local and CI setups become a thing of the past.Early Issue Detection: Integration problems are caught earlier, saving time and resources in the long run.Improved Collaboration: Developers can confidently work on the same project, knowing they're all using identical environments.Streamlined Workflow: The seamless transition from local development to CI pipelines accelerates the development cycle.Local GitOps Workflow: A zero-configuration approach to GitOps: start immediately with a pre-configured local Git server, no external repositories or credentials required.  During KubeCon 2024, AutoDesk touches on these topics and shares their experience using it for their platform development: https://www.youtube.com/watch?v=x_cTXvRgwdA  ","version":null,"tagName":"h2"},{"title":"Crossplane Testing​","type":1,"pageTitle":"Simplifying IDP Deployment and Local Development","url":"/blog/intro-to-idpbuilder#crossplane-testing","content":" Another example use of idpBuilder is in development and testing with Crossplane functions. At the All Day DevOps event, Imagine Learning highlighted their use of idpBuilder:  Local Development: idpBuilder deploys Crossplane, a local OCI registry, composite resource definitions, compositions, and composition functions within a single local Kubernetes environment.Enhanced Security: This setup avoids publishing images to public registries, improving security and privacy posture.Local AWS Simulation: A local stack simulates an AWS environment, enabling thorough testing without external resources.  More details about their implementation can be found in their repository and their presentation at the All Day DevOps event.  ","version":null,"tagName":"h2"},{"title":"Conclusion​","type":1,"pageTitle":"Simplifying IDP Deployment and Local Development","url":"/blog/intro-to-idpbuilder#conclusion","content":" idpBuilder simplifies creating and testing Internal Developer Platform Capabilities, solving common development and maintenance challenges. It allows you to rapidly deploy functional solutions with minimal setup by offering consistency across development stages.  However, idpBuilder isn't a one-size-fits-all solution. Organizations must assess their specific needs and existing infrastructure. While it's excellent for testing and development, production deployments may need further adjustments.  Overall, idpBuilder enhances IDP management, making it worth exploring for teams aiming to improve development processes and environmental consistency.  ","version":null,"tagName":"h2"},{"title":"Take the Next Step:​","type":1,"pageTitle":"Simplifying IDP Deployment and Local Development","url":"/blog/intro-to-idpbuilder#take-the-next-step","content":" Try idpBuilder: Download and start using idpBuilder today.. Follow our quick-start guide in the documentation to set up your first IDP environment.Join Our Community: Have questions or want to share your experience? Join our community on Slack. We're here to help and learn from each other.Learn More: Explore our documentation and resources on our website to deepen your understanding of idpBuilder and its capabilities.Contribute: idpBuilder is an open-source project, and we welcome contributions. Whether it's code, documentation, or feature suggestions, your input can help shape the future of idpBuilder. ","version":null,"tagName":"h3"},{"title":"Optimizing for Data Quality in your Developer Portal","type":0,"sectionRef":"#","url":"/blog/optimizing-data-quality-in-dev-portals","content":"","keywords":"","version":null},{"title":"Establishing the source of truth​","type":1,"pageTitle":"Optimizing for Data Quality in your Developer Portal","url":"/blog/optimizing-data-quality-in-dev-portals#establishing-the-source-of-truth","content":" There are different approaches to representing entities like Kubernetes objects and cloud resources in Backstage. In such context, platform engineers need to optimize for creation of reliable data. The last thing you as a platform provider want to see happen is to lose trust of end users because you are displaying incorrect information. There are however, a number of key decisions to be made when building entity representations in Backstage. Particularly:  What gets represented in Backstage and what doesn'tHow to ensure the Backstage entity offers an accurate representation of its real world counterpartWhat establishes the source of truth for an entity  Embracing GitOps practices, the answer to that last question may sound rather trivial: GIT, git is obviously the source of truth, since, you know ... GitOps!  However, while git represents the intended source of truth, truth is actually realized where the resource is deployed, revealing its beloved resource status. That is why you may hear people sarcastically refer to git as the source of hope in GitOps.  Our current collective of practices reveals that there is no silver bullet when deciding entity representations in a developer portal. What establishes the actual source of truth, from which Backstage entity representations to be drawn, primarily depends on company practices and tools DevOps teams have available to them.  If you operate a Hub and Spoke model, where a single control plane cluster is responsible for handling platform requirements and separate compute clusters handle the actual workload, the hub cluster could very well become the data source for the Backstage entities. On the other hand, if you operate a federated environment where control plane and data plane workloads are scattered across multiple clusters, Backstage could become the unifier that implements custom entity providers to pull and consolidate data from multiple data sources (i.e. the set of clusters with the right data). In a third approach, the CI may take on the job of hydrating entity definitions with metadata and status information it collects from several data sources, eventually pushing the constructed entity to another repository where it can be observed.  Next we discuss these approaches in more details.  ","version":null,"tagName":"h2"},{"title":"Use your existing CI/CD pipelines to construct the source of truth​","type":1,"pageTitle":"Optimizing for Data Quality in your Developer Portal","url":"/blog/optimizing-data-quality-in-dev-portals#use-your-existing-cicd-pipelines-to-construct-the-source-of-truth","content":" Starting from the specification of entities and infrastructure resources in a git repository, this approach utilizes tasks in the CI to hydrate entities with information on entity relations, extra metadata, and status of deployed resources. To avoid conflating user changes and automated CI changes, the hydrated entities are often kept in a separate git repository that mirrors and expands entities in the original git repository with intended application specifications.  On the positive side:  This is a relatively simple approach and works for smaller teams with smaller number of applications or systemsHaving a second git repository to capture the end state of an entity stays closer to the core GitOps practicesDoes not require significant modification to the developer portal  On the negative side:  There is inherent duplications that are happeningAdding custom metadata by application teams is not as trivial as it requires making changes to the integration workflow, thus bringing load and demand to the DevOps teamsLess abstraction in place as end application users are directly exposed to the yaml specification of the entitiesDoes not scale well as the number of systems and entities grow    ","version":null,"tagName":"h2"},{"title":"Use a central control plane as the source of truth​","type":1,"pageTitle":"Optimizing for Data Quality in your Developer Portal","url":"/blog/optimizing-data-quality-in-dev-portals#use-a-central-control-plane-as-the-source-of-truth","content":" The hub and spoke model is the most advocated for model when applying GitOps practices. Your control plane cluster runs and manages your platform tools, your CI, your CD, developer portal, infrastructure as code tooling, etc.  On the positive side:  There really is a single place to inspect the status of entities. E.g., Argo applications can tell you the status of deployed applications. You can also inspect the status of workflows, infrastructure resources, and any other entity that the control plane cluster manages.You can use the Backstage Kubernetes plugin seamlessly and maybe with some little tweaks. Alternatively this can be achieved by introducing fairly light-weight Backstage custom entity providers which pull and show the status of entities in the Backstage portal.In an organization with a diverse set of distributed systems, the control plane cluster can be used as the integration layer by wrapping legacy APIs and or implementing native controllers.  On the negative side:  Most organizations do not have a central control plane and adopting one as the source of truth is often a significant change, especially if an organization is early in their GitOps transition.For organizations deep into a federated model of operation with different teams running and managing their platforms separately and rather independently, it could be challenging to offer a single control plane that aggregates data across all teams.Management of change could become cumbersome. Existence of a single control plane could create bottlenecks where changes occur to a set of entities or practices. Changes in organizations or systems may result in changes to various entities managed across several teams. Bringing GitOps practices to the mix, this requires chains of approvals to happen across multiple entities and across several repositories for deployments to start flowing. Depending on the size of the organization, this could lead to organizational nightmares.You may need to jump through a few hoops before getting from the representation of the application, to the actual deployment of it, e.g., going from git to your continuous delivery and from there to your target cluster.    ","version":null,"tagName":"h2"},{"title":"Use Backstage as the source of truth​","type":1,"pageTitle":"Optimizing for Data Quality in your Developer Portal","url":"/blog/optimizing-data-quality-in-dev-portals#use-backstage-as-the-source-of-truth","content":" Where control planes and compute workloads are scattered, the unifying layer lies in the developer portal, i.e. Backstage. Hence, it is reasonable to construct an entity by collecting and aggregating data from various data sources, each providing partial data on the entity, making Backstage be the source of truth. This generally starts with Backstage querying git for the entities that exist. Then using the identifiers for the entities to collect metadata on how the entity contributes to a system. This could involve querying the control plane clusters and the workload clusters via some custom entity provider that looks for certain information and putting collected pieces together to come close to the core promise of a developer portal, providing reliable information on the entities.  On the positive side:  This model copes better with legacy systemsUsers are not exposed to and often times not even aware of the underlying platforms, hence underlying platform and tooling is more rigorously abstracted awayChanges to the system are only isolated to the entities of the particular system as managed by the underlying resources and platform. This causes less chaos when definitions, metadata, or properties of entities need to change.  On the negative side:  The git service may not be able to scale, technically or financially. This is particularly because Backstage may hit the git service endpoints too frequently and exceed the API limits. This could cause delays in displaying data for end users or display wrong information if partially available data is mishandled. This can be mitigated via approaches like using an eventing mechanism to notify Backstage of changes, or alternatively to store entity definitions in an alternative storage space (e.g. Amazon S3). There are challenges to such approaches too, for example when using Amazon S3, change history will be lost. Also, using an eventing mechanism could introduce security challenges that we discuss next.Securing Backstage could be a challenge. For Backstage to proactively receive updates on entity changes, it would work best to configure event hooks to provide callbacks to Backstage when changes occur. Backstage, being the entry point for user workflows, sits on the critical path of platform operations. As such, platform engineers need to solve for a chicken and egg problem by deciding how to expose Backstage endpoints to receive events and yet to limit access for security reasons. The authentication methods that GitHub supports may not satisfy the security standards that an organization requires.Changes to entities may not be as trivial. DevOps engineers need to manage entities that they may not control. For example, if a new mandatory field is introduced to a catalog file, DevOps engineers may need to talk to the respective repository owners, create a PR, then get approval for all affected repositories.    ","version":null,"tagName":"h2"},{"title":"Conclusion​","type":1,"pageTitle":"Optimizing for Data Quality in your Developer Portal","url":"/blog/optimizing-data-quality-in-dev-portals#conclusion","content":" We discussed multiple approaches to creating reliable representation of system entities in the developer portals. We do not necessarily recommend one approach over another, but it is important to find the right approach given the patterns and practices in your organization. It is also worth noting that you can choose to combine multiple approaches depending on the requirements of your teams. For example, while continuous integration can still be used to construct the actual state of the world by collecting status data and other related information, Backstage extensions can be introduced to expand on entity relations, providing better representation of a system. Stating the obvious here, but your proper selection of patterns that work for you will go a long way in increasing your overall team velocity down the road.  Reach out on #cnoe-interest CNCF slack channel to share thoughts and get involved in developing CNOE. ","version":null,"tagName":"h2"},{"title":"CNOE - A Joint Effort to Share Internal Developer Platform Tools and Best Practices.","type":0,"sectionRef":"#","url":"/blog/welcome","content":"","keywords":"","version":null},{"title":"Member Announcements​","type":1,"pageTitle":"CNOE - A Joint Effort to Share Internal Developer Platform Tools and Best Practices.","url":"/blog/welcome#member-announcements","content":" Announcement on the AWS WebsiteAnnouncement on the Autodesk Website ","version":null,"tagName":"h3"},{"title":"Technology Capabilities","type":0,"sectionRef":"#","url":"/docs/capabilities","content":"","keywords":"","version":"Next"},{"title":"Artifact Registries​","type":1,"pageTitle":"Technology Capabilities","url":"/docs/capabilities#artifact-registries","content":" The artifact registry allows for the packaged components endorsed by the CNOE community to be signed, accessible, and traceable for its users. By storing the list of components in an OCI registry or Git repository, the CNOE packaging framework will be able to deal with versioned and compatible artifacts that have already been tested and verified in working together. This also allows the combination of the registry and the packaging mechanism to undergo secure software supply chain (SSSC) best practices to further increase the level of confidence in leveraging these tools by the CNOE users.  Canonical location for durable long term artifact storage.Catalog + metadata about artifacts. Used for discovery of artifacts.Can be used in conjunction with Role Based Access Control (RBAC) to limit access to artifacts.Should be versioned and is often immutableOften used with static analysis tools to verify artifacts are free from known vulnerabilities.  ","version":"Next","tagName":"h2"},{"title":"Code Repositories​","type":1,"pageTitle":"Technology Capabilities","url":"/docs/capabilities#code-repositories","content":" Code repositories are a historical lineage of changes to a codebase (think source code for apps and libraries). They allow for developers to work collaboratively on common codebases and often asynchronously. While git and other source control tooling can allow for decentralized collaboration, usually we choose to centralize the common workflows associated with code review and automation driven by git aka “git-ops”. When appropriately hardened and durable, pull requests (and associated merges to protected branches) can be used as a “system of record” for change control and approval in regulatory environments  Allows for developers to collaborate on code asynchronously This includes peer reviews and change request approvals Usually centralized even when using decentralized tooling like git for the purposes of building workflowsThey can also be the mechanism used for peer reviews and change request approvals  ","version":"Next","tagName":"h2"},{"title":"Compute Platform​","type":1,"pageTitle":"Technology Capabilities","url":"/docs/capabilities#compute-platform","content":" This is the platform runtime. It can also be thought of as a deployment target for the applications that make up the platform. It offers some formalized patterns for interoperability between platform capabilities.  Can offer similar discoverability and uniformity as that of service oriented architectures (SOA) Can also offer a common medium for data exchange between services like an enterprise service bus or (ESB)  Frequently Kubernetes is the compute and also the substrate for the foundation of platform capabilities.  ","version":"Next","tagName":"h2"},{"title":"Config Repositories​","type":1,"pageTitle":"Technology Capabilities","url":"/docs/capabilities#config-repositories","content":" Config repositories are similar to code repositories but specific to application configuration. Often takes the form of serialized key value pairs or similar simple data structures. Frequently the keys are appended or tagged with meta-data about environment specifics so that they can be targeted. May be built on a hierarchy, tree or graph structure to further instill meta-data about the contents of the keys and values. Can be centralized or distributed, but should only have one source of truth for a fully qualified key-value pair. The values should not contain embedded secrets but often contains references to secrets that can be found within secret repositories. The data should be versioned and immutable to allow for point in time snapshots for things like rollbacks.  Usually key/value or other serialized structured data formatOften appended or tagged with meta-data about env specificsKeys can be structured in hierarchical or graph formatValues should not contain secrets but can contain referencesValues should be versioned and immutableKeys should only have one current source of truth for their values  ","version":"Next","tagName":"h2"},{"title":"Continuous Delivery (CD)​","type":1,"pageTitle":"Technology Capabilities","url":"/docs/capabilities#continuous-delivery-cd","content":" Continuous delivery’s ultimate goal is to get infrastructure and application resources into a state, ready for receiving production workload.  GitOps is a new trend in continuous delivery where automation is put in place to ensure the desired state of the world matches the perceived state of the world. This is achieved by connecting the source of truth (usually a git repository holding definition of application and infrastructure resources) to a reconciling controller that ensures consistency of the spun up resource to what is stored in Git. ArgoCD and FluxCD are two prominent implementations of these CD practices. While very similar in nature, ArgoCD and FluxCD and the likes could work in tandem and are not mutually exclusive.  Under the CD category, the CNOE community can help users evaluate which personas (e.g operator, developer) would be the most likely beneficiaries from each category of tooling. It is also worth noting that while GitOps is the dominant CD strategy in the CNCF space, it does not need to be the one or the only practice adopted by the CNOE users. Pluggability aspects of CNOE should ensure that customers have enough freedom in choosing their alternative.  Automation to build, test and release software upon every successful merge to a mainline branchAllows for fully automated deployments when “Continuous Deployment” is enabledFacilitates testing that goes beyond simple unit or integration tests. Frequently used in conjunction with end to end (E2E) or functional tests.Can be used in conjunction with safe production deployment methods like Blue/Green or Canary deploymentsCan also make use of feature flags to allow for “soft” or “dark launches” of features and functionality not yet ready for broad consumptionGenerally gets code in the hands of consumers faster, surfacing bugs quicker and shortening product feedback loops.  ","version":"Next","tagName":"h2"},{"title":"Deployment Targets​","type":1,"pageTitle":"Technology Capabilities","url":"/docs/capabilities#deployment-targets","content":" These are the runtime environments that product apps and services run on. This includes static content or data published for distribution.  Often abstractions hiding the details of underlying environments from the product developers. Regions or localities are a good example of what one might want to mask. Common deployment targets include: KubernetesLambdaVirtual MachinesElastic Container ServiceStatic Content  ","version":"Next","tagName":"h2"},{"title":"Developer Portal​","type":1,"pageTitle":"Technology Capabilities","url":"/docs/capabilities#developer-portal","content":" The CNOE cohort will work towards striking a balance on expectations across all its stake holders. This basically means that the set of tooling put together under CNOE will have to be as useful to the application developers as it is to other stakeholders. In order for this to be achieved, big emphasis is put on offering the right developer productivity tool that would serve as an overarching umbrella for including and presenting the underlying tooling in a user-friendly manner. Backstage is a popular open source tool supporting configurability and pluggability that can be utilized to achieve such level of developer productivity.  Software catalog of all components, systems and domains.One-stop location to find all about the software we build (docs, source repository, dashboards, support location, owners, etc.)API DocumentationDependencies on other softwareDocumentation system using the docs-as-code approach. Docs are typically in Markdown, and stored in code repositories.Software templates for creating new projects.Onboarding automation for security and trust.  ","version":"Next","tagName":"h2"},{"title":"Identity and Access​","type":1,"pageTitle":"Technology Capabilities","url":"/docs/capabilities#identity-and-access","content":" In the context of a platform, identity and access is most frequently a service that can be used to wire up Authentication and Authorization in a common well understood manner. By offering Identity and Access management as a capability of the platform, we can avoid product applications from having to reinvent the wheel for such critical functionality.  This capability can differ greatly depending on the needs of applications and services that consume it, but generally it will allow for an application to delegate the login, or challenge for proof of identity to the platform. Then the application can utilize the results of that challenge process to use credentials presented to the user by the identity access process to access sensitive information or processes.  The technical aspects of how the Identity and Access service can be consumed by client apps should use rigourously tested standards. Often the Identity and Access service will allow for client apps to bring their own sources of identity through a process of federation. This allows for client apps to root their identity in their existing systems but still make use of the common Auth service offered by the platform.  Machine identity and in particular the SPIFFE Protocol is a relatively new method to make use of trust built into workloads running in known good environments as an authentication mechanism. This is considered more secure than the use of long lived pre-shared secrets like those used by services users or API tokens.  Must provide authenticationMay provide primitives or framework for authorizationMust be well understood and easy to reason aboutReduces duplication of effort through delegationCan be tested independently and in conjunction with consumer applicationsIdentity can be federatedMachine Identity can use modern protocols like SPIFFEExamples of Standard Protocols: OAuth and OpenID ConnectSAMLMutual TLS and pre-shared certificatesAPI tokens or Bearer Authentication  ","version":"Next","tagName":"h2"},{"title":"Infrastructure as Code (IaC)​","type":1,"pageTitle":"Technology Capabilities","url":"/docs/capabilities#infrastructure-as-code-iac","content":" Infrastructure as Code or IaC, builds upon the Infrastructure as a Service (IaaS) offerings from cloud providers and modern datacenter automation. It is the APIs and programmatic libraries utilized within software frameworks built specifically for managing the life cycles of cloud infrastructure. It frequently encapsulates the tooling and automation used to spin up infrastructure resources for a given application.  By masking away the inconsistency of underlying cloud provider APIs, IaC offers the ability to build common patterns across a mix of heterogeneous resources. It also allows platform teams the ability to build higher order resources that meet specific business needs (beyond the low level APIs of the cloud providers). Furthermore, sane defaults and security and compliance concerns can be injected in a uniformly and made compulsory  We are seeing two categories of OSS tools in use at large: That which is occasionally reconciled like Terraform, Pulumi, CDK and continuously reconciled solutions like Crossplane or Amazon Controllers for Kubernetes (ACK).  The CNOE cohort will have to decide on the ideal IaC tool that works in tandem with the rest of delivery components, gains the overall community approval, and becomes the defacto service in use by the CNOE cohort.  Cohesive libraries, APIs and patterns for reconciling IaaS provider resourcesAllows for higher order abstractions to be builtCan inject sane defaults and enforce security best practicesCan be continuously reconciled when used in conjunction with KubernetesCommon implementations are TerraformCloudFormationPulumiCrossplane  ","version":"Next","tagName":"h2"},{"title":"Observability​","type":1,"pageTitle":"Technology Capabilities","url":"/docs/capabilities#observability","content":" The overall well-being of the system is tracked via proper integration with state of the art observability tooling.  Building on the existing set of technologies available in the CNCF ecosystem, CNOE needs to work in tandem with open telemetry data collectors and allow its users to view and analyze collected data using technologies such as Prometheus and Grafana.  ","version":"Next","tagName":"h2"},{"title":"Packaging and Templating​","type":1,"pageTitle":"Technology Capabilities","url":"/docs/capabilities#packaging-and-templating","content":" Packaging and templating languages and frameworks are required to ensure the delivery of complete and functional sets of tools to target specific capabilities endorsed and usable by the CNOE community. While opinionated, extensibility and configuration must meet the needs of users, but guide towards best practices when combining the tooling in the package. Some candidates for templating and packaging languages include the open component model, the Kubernetes packaging tool (KPT), and the OCI distribution specifications.  Packaged sets of tools and configuration endorsed and usable by the CNOE communityOpinionated and oriented toward producing best practices for the majority of use casesOpen and extensible, allowing for configurability of the targeted capabilities.  ","version":"Next","tagName":"h2"},{"title":"Secret Management​","type":1,"pageTitle":"Technology Capabilities","url":"/docs/capabilities#secret-management","content":" The life cycle and distribution of secrets must be managed safely and securely. Secrets Management aims to shift this important responsibility to the platform where it can be implemented and audited in one place rather than many.  Secrets Management works in conjunction with secrets repositories to securely source and deliver secrets on demand and just-in-time to applications and services.  Can be built with workflow-orchestration but must be treated with great careShould have additional security scrutiny applied beyond other non-secret artifact delivery toolingOften provides the ability to promote secrets between environments, distribute, roll and revoke secrets  ","version":"Next","tagName":"h2"},{"title":"Secret Repositories​","type":1,"pageTitle":"Technology Capabilities","url":"/docs/capabilities#secret-repositories","content":" Secrets repositories are secure long term storage locations for sensitive data. They parallel the centralized storage, versioning and meta-data capabilities offered by configuration repositories, but usually with stricter access controls and auditing. The storage of secrets should be encrypted. They may be encrypted with Hardware Security Modules or HSMs. They may be used in conjunction with other encryption and cryptographic solutions like Public Key Infrastructure or PKI. Secrets repositories may also offer the ability to generate, lease, rotate and revoke certain types of secrets like certificates.  Secure and durableUsually key value pairs or similar structured dataValues must be encryptedKeys and meta-data may not be encryptedMust have canonical source of truth for a fully qualified keyMay offer ability to generate/lease/rotate/revoke secret values such as certificatesCommon tooling includes: Hashicorp VaultCyberark ConjurAWS Secrets ManagerAzure Key VaultGoogle Secret Manager  ","version":"Next","tagName":"h2"},{"title":"Service Discovery​","type":1,"pageTitle":"Technology Capabilities","url":"/docs/capabilities#service-discovery","content":" Service discovery is a capability that allows for the dynamic lookup or querying of a producer’s interface/API details by consumers of that service. Frequently this is based on some sort of centralized key/value or database called a Service Registry, but it can be distributed like in the case of the Domain Name System (DNS). When distributed, care must be taken to handle inconsistency in the results of queries to the Service Registry.  Service discovery can be used in conjunction with configuration repositories, and secret repositories to allow for consumers to bootstrap themselves at startup or accept dynamic runtime changes to configuration.  Allows for dynamic lookup or querying of service informationUsually based on a database or registryCan be decentralized but care must be taken to handle inconsistencyOften used in conjunction with config and secret repositories for app bootstrappingCommon Tooling: DNSConsulZooKeeperetcd  ","version":"Next","tagName":"h2"},{"title":"Signing​","type":1,"pageTitle":"Technology Capabilities","url":"/docs/capabilities#signing","content":" Cryptographic signing of artifacts to allow for verification of the consistency and integrity of the data they contain. Data frequently includes source code commits, configs, binaries and meta-data but can also be any data blob. Cryptographic signatures can also provide attribution and provenance data (lineage and chain of custody). When combined with attestations (meta-data with a specific predicate in regards to the material being signed) they can be used to build up “trust telemetry” or verifiable signals about the material and how it was processed. These are foundational elements of a Secure Software Supply Chain.  Allows for verifying Consistency and Integrity of contentsCan also provide provenance and attributionCan be combined with attestations to create &quot;Trust Telemetry&quot;Foundational to Secure Software Supply Chain practicesCommon tools to perform signing include: SigstorePGPPKCS #11  ","version":"Next","tagName":"h2"},{"title":"Validation​","type":1,"pageTitle":"Technology Capabilities","url":"/docs/capabilities#validation","content":" Platforms can make use of API specifications and code generation to create validators for client interactions and data exchange. Kubernetes does this with its type system and Open API Spec V3 (at the time of this writing). Proper validation ensures that clients of the platform fail quickly and loudly if their requests are malformed or inconsistent with the platform’s API schemas.  Kubernetes also offers “admission control” as a lifecycle hook on client requests in addition to validation against type schemas. However this type of ad-hoc validation can be implemented within many phases or locations with platform tooling. Admission control can also be a common substrate for injecting policy controls or building guardrails within the platform to meet security or regulatory requirements.  When paired with Cryptographic signing, verification of the signatures on configurations and artifacts (like container images) can be done with admission control. This allows for the enforcement of policy only allowing verifiably good materials into an environment.  Ensures API specifications are abidedCan leverage code generation with proper toolingKubernetes Admission Control can enable a common policy planeCrypographic signing can be used to enforce validation for things like binary authorization  ","version":"Next","tagName":"h2"},{"title":"Workflow Orchestration​","type":1,"pageTitle":"Technology Capabilities","url":"/docs/capabilities#workflow-orchestration","content":" This is the tooling that allows for explicit orchestration of tasks. Usually this involves the process to get applications ready for delivery.  This can be things like defining the set of activities deemed necessary as part of CI, including but not limited to running tests (unit tests, smoke tests, integration tests, acceptance tests, etc), validations, verifications, and configuration changes to the deployment environments.  Frequently imperative definitions of steps to be completedCan use DSL for describing state machines or graphsCan enable side effects like notifications or manual interventions ","version":"Next","tagName":"h2"},{"title":"AWS Reference Implementation","type":0,"sectionRef":"#","url":"/docs/contributing/aws-ref-impl-CONTRIBUTING","content":"","keywords":"","version":"Next"},{"title":"Getting Started​","type":1,"pageTitle":"AWS Reference Implementation","url":"/docs/contributing/aws-ref-impl-CONTRIBUTING#getting-started","content":" ","version":"Next","tagName":"h2"},{"title":"Prerequisites​","type":1,"pageTitle":"AWS Reference Implementation","url":"/docs/contributing/aws-ref-impl-CONTRIBUTING#prerequisites","content":" Before contributing, ensure you have the following tools installed:  AWS CLIkubectlyqhelmGit  ","version":"Next","tagName":"h3"},{"title":"Development Environment Setup​","type":1,"pageTitle":"AWS Reference Implementation","url":"/docs/contributing/aws-ref-impl-CONTRIBUTING#development-environment-setup","content":" Fork the repository to your GitHub organizationClone your fork locally: git clone https://github.com/your-org/reference-implementation-aws.git cd reference-implementation-aws Set up your development environment following the Getting Started guide  ","version":"Next","tagName":"h3"},{"title":"How to Contribute​","type":1,"pageTitle":"AWS Reference Implementation","url":"/docs/contributing/aws-ref-impl-CONTRIBUTING#how-to-contribute","content":" ","version":"Next","tagName":"h2"},{"title":"Reporting Issues​","type":1,"pageTitle":"AWS Reference Implementation","url":"/docs/contributing/aws-ref-impl-CONTRIBUTING#reporting-issues","content":" Use GitHub Issues to report bugs or request featuresSearch existing issues before creating new onesProvide detailed information including: Steps to reproduceExpected vs actual behaviorEnvironment details (AWS region, EKS version, etc.)Relevant logs or error messages  ","version":"Next","tagName":"h3"},{"title":"Making Changes​","type":1,"pageTitle":"AWS Reference Implementation","url":"/docs/contributing/aws-ref-impl-CONTRIBUTING#making-changes","content":" Create a feature branch: git checkout -b feature/your-feature-name Make your changes following the project structure: Addons: Add new addons in packages/ directoryScripts: Update installation/management scripts in scripts/Documentation: Update docs in docs/ directoryTemplates: Add Backstage templates in templates/Examples: Add usage examples in examples/ Test your changes: # Test installation ./scripts/install.sh # Verify addons are healthy kubectl get applications -n argocd Commit your changes: git add . git commit -m &quot;feat: add new addon for X&quot; Push and create a pull request: git push origin feature/your-feature-name  ","version":"Next","tagName":"h3"},{"title":"Project Structure​","type":1,"pageTitle":"AWS Reference Implementation","url":"/docs/contributing/aws-ref-impl-CONTRIBUTING#project-structure","content":" ├── cluster/ # EKS cluster configurations (eksctl/terraform) ├── docs/ # Documentation and images ├── examples/ # Usage examples and demos ├── packages/ # Helm charts and addon configurations ├── private/ # GitHub App credentials (templates) ├── scripts/ # Installation and management scripts ├── templates/ # Backstage templates └── config.yaml # Main configuration file   ","version":"Next","tagName":"h2"},{"title":"Adding New Addons​","type":1,"pageTitle":"AWS Reference Implementation","url":"/docs/contributing/aws-ref-impl-CONTRIBUTING#adding-new-addons","content":" To add a new addon:  Create a directory in packages/your-addon/Add values.yaml with Helm chart configurationUpdate packages/addons/values.yaml to include your addonAdd documentation in docs/ if neededTest the addon installation  ","version":"Next","tagName":"h2"},{"title":"Code Standards​","type":1,"pageTitle":"AWS Reference Implementation","url":"/docs/contributing/aws-ref-impl-CONTRIBUTING#code-standards","content":" Follow existing code style and patternsUse meaningful commit messages (conventional commits preferred)Update documentation for any user-facing changesEnsure scripts are executable and include proper error handlingTest changes in a real EKS environment when possible  ","version":"Next","tagName":"h2"},{"title":"Pull Request Guidelines​","type":1,"pageTitle":"AWS Reference Implementation","url":"/docs/contributing/aws-ref-impl-CONTRIBUTING#pull-request-guidelines","content":" Keep PRs focused on a single feature or fixInclude tests or validation stepsUpdate relevant documentationReference related issues in PR descriptionEnsure CI checks pass  ","version":"Next","tagName":"h2"},{"title":"Testing​","type":1,"pageTitle":"AWS Reference Implementation","url":"/docs/contributing/aws-ref-impl-CONTRIBUTING#testing","content":" Before submitting:  Test the full installation flow: ./scripts/install.sh Verify all addons are healthy: kubectl get applications -n argocd Test cleanup process: ./scripts/uninstall.sh  ","version":"Next","tagName":"h2"},{"title":"Documentation​","type":1,"pageTitle":"AWS Reference Implementation","url":"/docs/contributing/aws-ref-impl-CONTRIBUTING#documentation","content":" Update README.md for user-facing changesAdd or update documentation in docs/ directoryInclude examples in examples/ directory when applicableUpdate configuration tables and addon lists as needed  ","version":"Next","tagName":"h2"},{"title":"Getting Help​","type":1,"pageTitle":"AWS Reference Implementation","url":"/docs/contributing/aws-ref-impl-CONTRIBUTING#getting-help","content":" Check existing documentationReview troubleshooting guideOpen an issue for questions or problemsJoin community discussions in GitHub Discussions  ","version":"Next","tagName":"h2"},{"title":"License​","type":1,"pageTitle":"AWS Reference Implementation","url":"/docs/contributing/aws-ref-impl-CONTRIBUTING#license","content":" By contributing, you agree that your contributions will be licensed under the same license as the project. ","version":"Next","tagName":"h2"},{"title":"Customizing idpbuilder","type":0,"sectionRef":"#","url":"/docs/idpbuilder/override","content":"","keywords":"","version":"Next"},{"title":"Core Packages​","type":1,"pageTitle":"Customizing idpbuilder","url":"/docs/idpbuilder/override#core-packages","content":" Core Packages are fully customizable with the flag -c. This flag accepts a path to a file containing Kubernetes manifests. The specified file can contain multiple yaml documents. The format of this flag is &lt;PACKAGE_NAME&gt;:&lt;PATH&gt;. Where &lt;PACKAGE_NAME&gt; is one of argocd, nginx, and gitea. You can find the built-in manifests in your local Gitea repositories or in our source files:  ArgoCDGiteaNginx  For example, if you'd like to override the ArgoCD ConfigMap, you can run idpbuilder like this:  $idpbuilder create -c argocd:/tmp/override.yaml  The contents of /tmp/override.yaml is:  apiVersion: v1 data: application.resourceTrackingMethod: annotation resource.exclusions: | - kinds: - ProviderConfigUsage apiGroups: - &quot;*&quot; kind: ConfigMap metadata: labels: app.kubernetes.io/name: argocd-cm app.kubernetes.io/part-of: argocd name: argocd-cm   The corresponding built-in manifest can be found here.  This instructs idpbuilder to use the provided manifest for argocd-cm only. The built-in Kubernetes manifests are used for everything but argocd-cm.  ","version":"Next","tagName":"h2"},{"title":"CoreDNS​","type":1,"pageTitle":"Customizing idpbuilder","url":"/docs/idpbuilder/override#coredns","content":" CoreDNS is used as the in-cluster DNS provider for Kind clusters. idpbuilder configures CoreDNS service during cluster creation to ensure domain names given by the --host flag resolves correctly. It configures CoreDNS by creating a custom CoreDNS configuration files as Kubernetes ConfigMap, then mounting them on the CoreDNS pods. They are not managed by ArgoCD and can be fully customized. If DNS resolutions provided by idpbuilder does not work for you, you can override them with custom packages.  Default CoreDNS configurations: The main configuration file is mounted at /etc/coredns/Corefile and looks like this:  :53 { errors health { lameduck 5s } ready import ../coredns-configs/*.conf ... }   CoreDNS allows you to import configuration files matching a pattern in a specified directory. The import ../coredns-configs/*.conf line instructs CoreDNS to look for configuration files in the /etc/coredns-configs/ directory.  idpbuilder creates two ConfigMaps then mount them in the CoreDNS pods under the /etc/coredns-configs/ directory.  First ConfigMap is called coredns-conf-default and contains configuration like this:  rewrite stop { name regex (.*).cnoe.localtest.me ingress-nginx-controller.ingress-nginx.svc.cluster.local } rewrite name exact cnoe.localtest.me ingress-nginx-controller.ingress-nginx.svc.cluster.local   The first rewrite rule resolves subdomain names to ingress IP address. For example gitea.cnoe.localtest.me becomes ingress-nginx-controller.ingress-nginx.svc.cluster.local.  The second rewrite rule resolves the domain name to ingress IP address. For example cnoe.localtest.me becomes ingress-nginx-controller.ingress-nginx.svc.cluster.local.  Second ConfigMap is called coredns-conf-custom and is left empty. This is intended to be used by custom packages that need additional DNS resolution. For example, if you'd like to resolve a domain name my.cnoe.io to home.cnoe.io, then you can populate the CM's data filed like so:  apiVersion: v1 kind: ConfigMap metadata: name: coredns-conf-custom namespace: kube-system data: custom.conf: | rewrite name exact my.cnoe.io home.cnoe.io   ","version":"Next","tagName":"h2"},{"title":"Self Signed Certificate​","type":1,"pageTitle":"Customizing idpbuilder","url":"/docs/idpbuilder/override#self-signed-certificate","content":" As described in the self-signed certificate, idpbuilder creates a self-signed certificate and uses it as the default TLS certificate for ingress-nginx. This default certificate cannot be overridden at cluster creation and is used when no certificate is specified on the Ingress object. This means, you can specify certificate to use at Ingress level by specifying a TLS secret like this:  apiVersion: networking.k8s.io/v1 kind: Ingress metadata: name: example-ingress annotations: kubernetes.io/ingress.class: nginx spec: tls: - hosts: - cnoe.io secretName: my-tls-secret # specify secret here   Please see the Kubernetes docs for more information. ","version":"Next","tagName":"h2"},{"title":"Installation","type":0,"sectionRef":"#","url":"/docs/idpbuilder/installation","content":"","keywords":"","version":"Next"},{"title":"Introduction​","type":1,"pageTitle":"Installation","url":"/docs/idpbuilder/installation#introduction","content":" idpBuilder is a powerful tool that enables you to easily spin up a complete internal developer platform (IDP) on your local machine.  Go to idpbuilder Overview page to get more details on the concepts.  ","version":"Next","tagName":"h2"},{"title":"Running ipdbuilder in local machine​","type":1,"pageTitle":"Installation","url":"/docs/idpbuilder/installation#running-ipdbuilder-in-local-machine","content":" A container engine is needed locally.  Docker desktop is supported.Podman desktop is not supported however idpbuilder can create a cluster using rootful. You need tp set the DOCKER_HOST env var property using podman to let idpbuilder to talk with the engine (e.g export DOCKER_HOST=&quot;unix:///var/run/docker.sock&quot;)  Option 1: Using Bash Script  You can execute the following bash script to get started with a running version of the idpBuilder (inspect the script first if you have concerns):  $curl -fsSL https://raw.githubusercontent.com/cnoe-io/idpbuilder/main/hack/install.sh | bash  verify a successful installation by running the following command and inspecting the output for the right version:  $idpbuilder version  Option 2: Manual installation  You can run the following commands for a manual installation:  $version=$(curl -Ls -o /dev/null -w %{url_effective} https://github.com/cnoe-io/idpbuilder/releases/latest) $version=${version##*/} $curl -L -o ./idpbuilder.tar.gz &quot;https://github.com/cnoe-io/idpbuilder/releases/download/${version}/idpbuilder-$(uname | awk '{print tolower($0)}')-$(uname -m | sed 's/x86_64/amd64/').tar.gz&quot; $tar xzf idpbuilder.tar.gz $./idpbuilder version # example output # idpbuilder 0.4.1 go1.21.5 linux/amd64  Option 3: Release page binary  The easiest way to get started is to grab the idpbuilder binary for your platform and run it. You can visit our nightly releases page to download the version for your system, or run the following commands:  $arch=$(if [[ &quot;$(uname -m)&quot; == &quot;x86_64&quot; ]]; then echo &quot;amd64&quot;; else uname -m; fi) $os=$(uname -s | tr '[:upper:]' '[:lower:]') $idpbuilder_latest_tag=$(curl --silent &quot;https://api.github.com/repos/cnoe-io/idpbuilder/releases/latest&quot; | grep '&quot;tag_name&quot;:' | sed -E 's/.*&quot;([^&quot;]+)&quot;.*/\\1/') $curl -LO https://github.com/cnoe-io/idpbuilder/releases/download/$idpbuilder_latest_tag/idpbuilder-$os-$arch.tar.gz $tar xvzf idpbuilder-$os-$arch.tar.gz  ","version":"Next","tagName":"h2"},{"title":"Running ipdbuilder in Codespaces​","type":1,"pageTitle":"Installation","url":"/docs/idpbuilder/installation#running-ipdbuilder-in-codespaces","content":" You can run idpbuilder in Codespaces.  Create a Codespaces instance.   Wait for it to be ready. It may take several minutes. Get the latest release of idpbuilder: $version=$(curl -Ls -o /dev/null -w %{url_effective} https://github.com/cnoe-io/idpbuilder/releases/latest) $version=${version##*/} $curl -L -o ./idpbuilder.tar.gz &quot;https://github.com/cnoe-io/idpbuilder/releases/download/${version}/idpbuilder-$(uname | awk '{print tolower($0)}')-$(uname -m | sed 's/x86_64/amd64/').tar.gz&quot; $tar xzf idpbuilder.tar.gz Run idpbuilder: $idpbuilder create --protocol http \\ --host ${CODESPACE_NAME}-8080.${GITHUB_CODESPACES_PORT_FORWARDING_DOMAIN} \\ --port 8080 --use-path-routing Because Codespaces gives a single externally routable host name for an instance, idpbuilder must deploy with path based routing. This means ArgoCD and Gitea UIs are given with the following commands. ArgoCD: echo https://${CODESPACE_NAME}-8080.${GITHUB_CODESPACES_PORT_FORWARDING_DOMAIN}/argocdGitea: echo https://${CODESPACE_NAME}-8080.${GITHUB_CODESPACES_PORT_FORWARDING_DOMAIN}/gitea Note that not all examples work with path based routing.  Codespaces tips and tricks Codespaces tips and tricks​ By default all port forwarding in a Codespace environment is private which means that you will not be able to access the OCI registry directly from your local machine's CLI. You can however use the github CLI to port-forward a port on your local machine to the codespace which is running the OCI registry and listening on port 8443. To do this, make sure you have the latest github cli installed. Instructions here: [https://github.com/cli/cli#installation] (https://github.com/cli/cli#installation) Next you will need to login to github and give your CLI access to the codespace: $gh auth login -h github.com -s codespace Follow the prompts to perform the auth via your local machine's browser and make sure to choose the codespace you are running idpbuilder in. $gh auth login -h github.com -s codespace ! First copy your one-time code: 0076-1071 Press Enter to open https://github.com/login/device in your browser... Opening in existing browser session. ✓ Authentication complete. List the ports on your codespace: $gh codespace ports ? Choose codespace: cnoe-io/idpbuilder [main*]: expert chainsaw LABEL PORT VISIBILITY BROWSE URL 8443 private https://expert-chainsaw-7vjwj6qqgcprjp-8443.app.github.dev 37065 private https://expert-chainsaw-7vjwj6qqgcprjp-37065.app.github.dev Then perform the port-forward. Make sure to use the same port that the codespace has listed in it's port column. Likely this is 8443 which is the default at the time of this writing. $gh codespace ports forward 8443:8443 -c expert-chainsaw-7vjwj6qqgcprjp If you see a message like the following then you may already have another service on your local machine that is listening on 8443. Make sure to shut it down. (Maybe you were running idpbuilder locally as well?) failed to listen to local port over tcp: listen tcp :8443: bind: address already in use Once you have setup the port-forward you will see the following: $gh codespace ports forward 8443:8443 -c expert-chainsaw-7vjwj6qqgcprjp Forwarding ports: remote 8443 &lt;=&gt; local 8443 You can now connect directly to the registry hosted on idpbuilder in your codespace environment. $docker login cnoe.localtest.me:8443/gitea Authenticating with existing credentials... Stored credentials invalid or expired Username (giteaAdmin): giteaadmin Password: WARNING! Your password will be stored unencrypted in /home/sanforj/.docker/config.json. Configure a credential helper to remove this warning. See https://docs.docker.com/engine/reference/commandline/login/#credential-stores Login Succeeded IMPORTANT! As you may have noticed, you must use cnoe.localtest.me:8443 (or whatever port number was listed) as the registry name. This will allow for compatibility with the oci clients that are working in the codespace as well as those that are running on the idpbuilder kubernetes cluster. As long as you tag your images and push them to cnoe.localtest.me:8443/gitea/giteaadmin/imagename:tag they will be able to be referenced on your local machine, on the cli within the codespace and on the idbpuilder k8s cluster at that same registry/repo/imagename:tag location. Example mirroring Alpine image​ So to be clear. On your local machine you have to tag your images appropriately like so: $docker tag alpine:latest cnoe.localtest.me:8443/gitea/giteaadmin/alpine:latest Then you can push once your port-forwarding is working: $docker push cnoe.localtest.me:8443/gitea/giteaadmin/alpine:latest The push refers to repository [cnoe.localtest.me:8443/gitea/giteaadmin/alpine] 3e01818d79cd: Layer already exists latest: digest: sha256:fa7042902b0e812e73bbee26a6918a6138ccf6d7ecf1746e1488c0bd76cf1f34 size: 527 Then on the cli inside your codespace you can pull it: $docker pull cnoe.localtest.me:8443/gitea/giteaadmin/alpine:latest latest: Pulling from gitea/giteaadmin/alpine Digest: sha256:fa7042902b0e812e73bbee26a6918a6138ccf6d7ecf1746e1488c0bd76cf1f34 Status: Image is up to date for cnoe.localtest.me:8443/gitea/giteaadmin/alpine:latest cnoe.localtest.me:8443/gitea/giteaadmin/alpine:latest And when you run an image in your idpbuilder k8s cluster just make sure to reference it at the same location: apiVersion: v1 kind: Pod metadata: name: alpine-from-local-registry spec: containers: - name: alpine-from-local-registry image: cnoe.localtest.me:8443/gitea/giteaadmin/alpine:latest restartPolicy: Never  ","version":"Next","tagName":"h2"},{"title":"Cloud Native Operational Excellence (CNOE)","type":0,"sectionRef":"#","url":"/docs/overview/cnoe","content":"","keywords":"","version":"Next"},{"title":"What is CNOE?​","type":1,"pageTitle":"Cloud Native Operational Excellence (CNOE)","url":"/docs/overview/cnoe#what-is-cnoe","content":" Enterprises that adopt OSS as the foundation of their cloud platforms face the challenge of choosing technologies that will support their business outcomes for 3-5 years. The cost of retooling and re-platforming for large organizations is high, which makes bets on specific technologies fundamental to their technology strategies. In order to de-risk these bets, enterprises take into consideration the investments of their peer organizations. The goal for the CNOE framework is to bring together a cohort of enterprises operating at the same scale so that they can navigate their operational technology decisions together, de-risk their tooling bets, coordinate contribution, and offer guidance to large enterprises on which CNCF technologies to use together to achieve the best cloud efficiencies.  ","version":"Next","tagName":"h2"},{"title":"Problem Statement​","type":1,"pageTitle":"Cloud Native Operational Excellence (CNOE)","url":"/docs/overview/cnoe#problem-statement","content":" As software development processes have evolved, infrastructure and related tooling have become more and more fragmented and complex. Standalone tools (i.e., Spinnaker, Jenkins, CloudFormation) for operating in cloud-native environments are no longer effective for most customers on their own. While some of this is the nature of technology evolution and growth, a number of root causes are contributing to customers augmenting or replacing their existing tooling to address their larger-scale challenges.  The current tooling “standard” is a moving target. The size and scope of the CNCF landscape alongside the ever-increasing breadth of tools creates a paralyzation of choice. Customers are forced to adopt a wide-ranging array of tools with minimal direction and implement them in environment-specific ways, leading to a lack of consensus between customers. This also contributes to significant supportability and maintainability problems within the communities that govern those tools. The definitions of traditional continuous integration and continuous delivery/deployment (CI/CD) have become blurry. Legacy systems have grown to be bloated and contributions have fallen behind in lieu of lighter more modern tools (i.e., ArgoCD, Flux, Tekton) that focus on newer paradigms like GitOps. The advent and growth of declarative, centralized control planes for infrastructure (e.g. Kubernetes) creates an ecosystem that is fundamentally different and arguably inoperable with previous generation tooling. However, many application environments still expect (and will continue to expect) to interface with “traditional” virtual machine or bare metal based infrastructure points. Developers’ core workflows have remained more-or-less the same over the past years, focused more on understanding the intricacies of a language or framework and implementing them using appropriate versioning and collaborative tooling. Many of the abstractions in *-Ops today were designed to accommodate differences in infrastructure, leading to a discontinuity between developers and delivery. Fragmentation between software delivery and deployment methods have led to a multitude of languages, infrastructure as code platforms, templating engines, specs, and packaging systems. This creates an endless combination of non-portable software components that are difficult to reconcile into a singular application.  ","version":"Next","tagName":"h2"},{"title":"Tenets​","type":1,"pageTitle":"Cloud Native Operational Excellence (CNOE)","url":"/docs/overview/cnoe#tenets","content":" The CNOE working group will operate based on the following tenets.  Open source first: use of open source technology is prioritized over proprietary technology for each of the technology verticals discussed later in the doc. This helps ensure alignment across all the participating members by allowing them to coordinate on collaborations while having the freedom to update and modify a given technology to their needs Community driven: Decisions on the direction of the working group is driven by the community and its governing body. This involves the selection of technologies, level of commitment, and level of contribution. Tools and not Practices: CNOE offers suggestions on which tools to use and with what configurations. What practices a given company builds around and above those tools is out of scope for CNOE. Powered by Kubernetes, but not limited to orchestrate to Kubernetes: The CNOE working group relies heavily on the success of the CNCF community to choose technologies that are deemed useful to the type of operations required by the community. As such, Kubernetes is considered the de-facto environment to operate CNOE tooling. However, choosing of Kubernetes as the operating environment, does not require for it to be the environment to orchestrate against. Using the right infrastructure as code tooling, the CNOE community can choose to orchestrate against any compute platform of their choice. Standardized to the infrastructure, customizable by the developers: CNOE aims at addressing the usability requirements of its stakeholders. While the requirements of the platform could be enforced by the security engineers and infrastructure operators, the usability of it needs to be guaranteed by platform operators and application developers. Built to be shared: All CNOE deliverables including the reference architecture and the deployment packages will be developed out in the open and by collaboration of all its participating members and with the goal of making it sharable and usable by the larger open source community of interest.  ","version":"Next","tagName":"h2"},{"title":"What CNOE is not​","type":1,"pageTitle":"Cloud Native Operational Excellence (CNOE)","url":"/docs/overview/cnoe#what-cnoe-is-not","content":" not only a unified control plane but building blocks for them to expand and extend the unified control plane not only a CI/CD tool but other components and capabilities that extend and enhance the integration and delivery of applications not new technologies or set of managed services, but a way to interact and integrate. There is still an expectation that companies will need to fund and operate the various open source tools used within the IDP not installers or proprietary packaging mechanisms. it will be fully open source and customizable and available to use by any one not responsible for operationalizing of the toolchain. There is still an expectation that companies will need to fund and operate the various open source tools used within the IDP  ","version":"Next","tagName":"h2"},{"title":"Who cares about CNOE? (Personas)​","type":1,"pageTitle":"Cloud Native Operational Excellence (CNOE)","url":"/docs/overview/cnoe#who-cares-about-cnoe-personas","content":" Application Developers: Experts in writing business-logic-specific code to be consumed by “customers”. Familiar with traditional programming languages and frameworks with minimal interest in infrastructure components outside of the ones in-use for their applications. Package Builders: Experts in stitching together multiple components into reusable blueprints and delivering those as a service. Package builders are likely to “wrap” multiple infrastructure and application parts into singular deployables that can be leveraged by application developers. Infrastructure Operators: Experts in deployment and management of the infrastructure and platform components that provide the foundation to business applications. Familiar with infra-as-code primitives and automation/scripting languages, as well the fundamental characteristics of network, storage, and database. Also likely to have experience with application orchestration platforms and their underlying functionality. Information Security Engineers (ISE): Experts in applying and enforcing security and compliance best practices. ISE’s partner with package builders to approve production ready packages to be used across the organization.  ","version":"Next","tagName":"h2"},{"title":"Approach​","type":1,"pageTitle":"Cloud Native Operational Excellence (CNOE)","url":"/docs/overview/cnoe#approach","content":" CNOE takes a multitudinal and communal approach toward solving problems faced by DevOps teams. In order to address selection challenges within the fragmented and complex ecosystem of CNCF DevOps tooling, CNOE seeks community consensus on the categorical subdivision of delivery needs based on the size and scale of its users. This involves defining categories of tools deemed necessary for a successful DevOps strategy, as seen by the cohorts of users and based on the size of the company, the nature of the operation, and the type of workload. CNOE then endorses a set of tools in each category that when configured together, can deliver the top-of-the-line DevOps experience.  Pluggability and Extensibility: Splitting a DevOps delivery strategy into subcategories with logical boundaries requires for CNOE to allow pluggability and extensibility for tools within each category. This means that CNOE needs to ensure and facilitate integration of tools from one category with tools from another category as part of its delivery pipeline. As a concrete example, assuming that users will have the option to choose between Tekton or Argo Workflows for their CI and Weaveworks Flux or Argo CD for their CD, any combination of tools from the two categories should effectively work within the context of CNOE. This helps reduce fragmentation while providing options for adoption. On the other hand, a list of CNOE-endorsed tools that fit the defined logical DevOps boundaries is aimed at better right-tooling of the delivery pipelines. This in turn reduces the complexity in selecting the right tools for the job and enabling CNOE users to get a compliant delivery pipeline up and running as quickly as possible. Powered by but not limited to Kubernetes: As discussed earlier, CNOE aims at simplifying selection, integration, and operation of DevOps tools available within the CNCF ecosystem. A question that may arise is whether CNOE assumes strong dependency to Kubernetes. Our take is that, while modern CNCF tools require Kubernetes to run on, they do not have to orchestrate resources and deployments against Kubernetes. This means that while users of CNOE assume dependency to Kubernetes for the operation of CNOE tool set, their workload does not need to be tied to Kubernetes. Within this context, using CNOE to deploy to discrete cloud platforms such as AWS Elastic Containers Service (ECS) or GCP Cloud Functions is a totally fair game. Building Patterns and Tooling: For seamless transition into a CNOE-compliant delivery pipeline, CNOE will aim at delivering &quot;packaging specifications&quot;, &quot;templating mechanisms&quot;, as well as &quot;deployer technologies&quot;, an example of which is enabled via the idpBuilder tool we have released. The combination of templates, specifications, and deployers allow for bundling and then unpacking of CNOE recommended tools into a user's DevOps environment. This enables teams to share and deliver components that are deemed to be the best tools for the job. Modernizing a delivery pipeline according to CNOE guidelines then becomes the practice of devising a migration plan from the old set of tools used by an organization into the new set of tools endorsed by CNOE. This is another area where a community approach to endorsing, adhering to, and executing on CNOE-compliant delivery pipelines will be critical. For it to succeed, CNOE relies on commitments and contributions from its community members to develop and contribute migration plans and tools that empower transitioning from the legacy environments to the new environments. ","version":"Next","tagName":"h2"},{"title":"IDPBuilder","type":0,"sectionRef":"#","url":"/docs/idpbuilder","content":"","keywords":"","version":"Next"},{"title":"Introduction​","type":1,"pageTitle":"IDPBuilder","url":"/docs/idpbuilder#introduction","content":" idpBuilder is a powerful tool that enables you to easily spin up a complete internal developer platform (IDP) on your local machine. By leveraging industry-standard technologies like Kubernetes, ArgoCD, and Backstage, idpBuilder provides a comprehensive and reliable solution for setting up a reference IDP implementation. The key differentiator of idpBuilder is that it requires only Docker as a local dependency, making it accessible and easy to set up on a wide range of development environments.  The key purpose of idpBuilder is to simplify the process of creating and managing an IDP environment, allowing developers, DevOps engineers, and platform teams to focus on their core responsibilities without getting bogged down in complex infrastructure setup and configuration.  With idpBuilder, you can achieve the following benefits:  Reference IDP Implementation: idpBuilder provides a pre-configured and opinionated IDP setup, allowing you to quickly create a reference implementation that can be used for demonstrations, proofs of concept, and training purposes. Integration Testing: By running idpBuilder on a local machine, you can use the resulting IDP environment for integration testing of your applications and services, ensuring seamless deployment and functionality before pushing to production. Local Development for IDP Engineers: idpBuilder can serve as a powerful local development environment for IDP engineers, enabling them to experiment with new features, test configurations, and validate updates to the IDP platform without impacting production systems.  By leveraging idpBuilder, teams can accelerate their cloud-native adoption, improve developer productivity, and enhance the overall efficiency of their internal developer platform, all while adhering to industry-standard practices and technologies.  ","version":"Next","tagName":"h2"},{"title":"Overview​","type":1,"pageTitle":"IDPBuilder","url":"/docs/idpbuilder#overview","content":" When idpbuilder creates an environment for you, it performs the following tasks.  1. idpbuilder creates a local kind cluster if one does not exist yet Create a self-signed certificate, then set it as the default TLS certificate for ingress-nginx.Configure CoreDNS to ensure names are resolved correctly. 2. idpbuilder installs the following core packages to the cluster. ArgoCD is the GitOps solution to deploy manifests to Kubernetes clusters. In this project, a package is an ArgoCD application.Gitea server is the in-cluster Git server that ArgoCD can be configured to sync resources from. You can sync from local file systems to this. This Gitea installation includes an embedded OCI-compliant container registry for hosting container images as &quot;packages&quot; .Ingress-nginx is used as a method to access in-cluster resources such as ArgoCD UI and Gitea UI. 3. Once the core packages are installed, idpbuilder passes control over these packages to ArgoCD by storing manifests in Gitea repositories then creating ArgoCD applications. From here on, ArgoCD manages them based on manifests checked into Git repositories.    For more detail on idpbuilder architecture and project information check idpbuilder contribution.  ","version":"Next","tagName":"h2"},{"title":"Security​","type":1,"pageTitle":"IDPBuilder","url":"/docs/idpbuilder#security","content":" ","version":"Next","tagName":"h2"},{"title":"Self Signed Certificate​","type":1,"pageTitle":"IDPBuilder","url":"/docs/idpbuilder#self-signed-certificate","content":" To ensure applications inside the cluster can talk to other services, idpbuilder creates a self-signed TLS certificate. The certificate is a wild card certificate for the domain name and any subdomains given by the --host flag. For example, if you use the default domain name cnoe.localtest.me the certificate is issued for cnoe.localtest.me and *.cnoe.localtest.me  This certificate is then used by ingress-nginx as [the default TLS certificate](https://kubernetes.github.io/ingress-nginx/user-guide/tls/#default-ssl-certificate_. This means you can override TLS certificate used at ingress level if desired.  The certificate is also imported to ArgoCD as one of trusted CAs. This is necessary to make sure ArgoCD can talk to Gitea services without disabling TLS.  Finally, the certificate is exposed as a secret named idpbuilder-cert in the default namespace. To retrieve it, run the following command:  $kubectl get secret -n default idpbuilder-cert  ","version":"Next","tagName":"h3"},{"title":"Getting Relevant Secrets​","type":1,"pageTitle":"IDPBuilder","url":"/docs/idpbuilder#getting-relevant-secrets","content":" The idpbuilder get secrets command retrieves the following:  ArgoCD initial admin password.Gitea admin user credentials.Any secrets labeled with cnoe.io/cli-secret=true.  You can think of the command as executing the following kubectl commands:  $kubectl -n argocd get secret argocd-initial-admin-secret $kubectl get secrets -n gitea gitea-admin-secret $kubectl get secrets -A -l cnoe.io/cli-secret=true  If you want to retrieve secrets for a package, you can use the -p flag. To get secrets for a package named gitea:  $idpbuilder get secrets -p gitea  For the -p flag to work, you must label the secret with cnoe.io/package-name. For example, to make secret values available in a secret named my-secret for a package named foo:  $kubectl label secret my-secret &quot;cnoe.io/package-name=foo&quot; &quot;cnoe.io/cli-secret=true&quot;  The secret will then be listed when issuing the idpbuilder get secrets command. Alternatively, you can use the following command to retrieve the individual secret:  idpbuilder get secrets -p foo   ","version":"Next","tagName":"h3"},{"title":"Networking​","type":1,"pageTitle":"IDPBuilder","url":"/docs/idpbuilder#networking","content":" ","version":"Next","tagName":"h2"},{"title":"Traffic Flow​","type":1,"pageTitle":"IDPBuilder","url":"/docs/idpbuilder#traffic-flow","content":" The default Docker-on-Linux configuration for kind cluster establishes the following setup:  A Kubernetes node runs as a Docker container with port 443 mapped to host port 8443. You can confirm this by running docker container lsThe ingress-nginx service is configured as NodePort mode, listening on port 443. You can confirm this by running kubectl get service -n ingress-nginx ingress-nginx-controller  When a request is made to https://gitea.cnoe.localtest.me:8443, the traffic flow follows this sequence:  The domain name resolves to the local loopback addressA request is sent to 127.0.0.1:8443 with the host header gitea.cnoe.localtest.me:8443The request is forwarded to container port 443Ingress-nginx examines the SNI and host header to route traffic to the Gitea serviceGitea processes the request and returns a response  ","version":"Next","tagName":"h3"},{"title":"DNS Configuration​","type":1,"pageTitle":"IDPBuilder","url":"/docs/idpbuilder#dns-configuration","content":" External DNS Resolution​  By default, idpbuilder uses cnoe.localtest.me as the base domain for exposing services like ArgoCD and Gitea. The localtest.me domain and its subdomains automatically resolve to the local loopback address, providing a consistent naming scheme without requiring localhost. For more details, visit the localtest.me documentation.  In-cluster DNS Configuration​  To ensure proper name resolution both inside and outside the cluster, idpbuilder configures the cluster's CoreDNS service. While the default domain (cnoe.localtest.me) resolving to 127.0.0.1 works for external access through the NodePort service, it creates challenges for in-cluster communication.  For example, when an ArgoCD pod tries to access gitea.cnoe.localtest.me, the address would resolve to the pod's own loopback interface 127.0.0.1. To address this, idpbuilder configures CoreDNS with rewrite rules like:  rewrite name gitea.cnoe.localtest.me ingress-nginx-controller.ingress-nginx.svc.cluster.local   This CoreDNS rewrite rule instructs CoreDNS to resolve requests made for gitea.cnoe.localtest.me using the address given by ingress-nginx-controller.ingress-nginx.svc.cluster.local  ","version":"Next","tagName":"h3"},{"title":"Routing Modes​","type":1,"pageTitle":"IDPBuilder","url":"/docs/idpbuilder#routing-modes","content":" idpbuilder supports two modes of routing requests to in-cluster resources: domain-based and path-based. The behavior is configured with the --use-path-routing flag, which defaults to false.  ","version":"Next","tagName":"h2"},{"title":"Domain-based routing​","type":1,"pageTitle":"IDPBuilder","url":"/docs/idpbuilder#domain-based-routing","content":" This is the default behavior of idpbuilder. In this mode, services are exposed under their own domain names. For example:  ArgoCD UI is accessed via https://argocd.cnoe.localtest.meGitea UI is accessed via https://gitea.cnoe.localtest.me  This approach is generally cleaner and offers more flexible routing options because it requires less complex ingress configurations.  ","version":"Next","tagName":"h3"},{"title":"Path-based routing​","type":1,"pageTitle":"IDPBuilder","url":"/docs/idpbuilder#path-based-routing","content":" When you use the --use-path-routing flag, idpbuilder configures all services under a single domain name, with routing based on path parameters. For example:  ArgoCD UI is accessed via https://cnoe.localtest.me/argocdGitea UI is accessed via https://cnoe.localtest.me/gitea  This is useful when you are constrained to using a single domain name and cannot use subdomains. A good example is when using GitHub Codespaces. When forwarding ports in Codespaces, you are given a single domain name (like wild-broomstick-abc.github.dev) to reach all services running in your codespace. In such situations, you cannot use subdomains (e.g., argocd.wild-broomstick-abc.github.dev would not work), making path-based routing the appropriate choice.  ","version":"Next","tagName":"h3"},{"title":"Local OCI Registry​","type":1,"pageTitle":"IDPBuilder","url":"/docs/idpbuilder#local-oci-registry","content":" The local Gitea instance created by idpbuilder contains a built-in OCI registry for hosting container images as &quot;packages&quot; in Gitea nomenclature. It is a standard OCI registry, so the API should be compatible with any tools that are OCI compliant. That includes the docker cli.  ","version":"Next","tagName":"h2"},{"title":"Pushing image​","type":1,"pageTitle":"IDPBuilder","url":"/docs/idpbuilder#pushing-image","content":" $docker login gitea.cnoe.localtest.me:8443 # see the note section below for retrieving your password. Username: giteaAdmin Password: $docker pull docker.io/library/ubuntu:24.04 # default way $docker tag docker.io/library/ubuntu:24.04 gitea.cnoe.localtest.me:8443/giteaadmin/ubuntu:24.04 $docker push gitea.cnoe.localtest.me:8443/giteaadmin/ubuntu:24.04 # Pushing image using path based routing. You can also use the OCI registry with path based routing mode (the `--use-path-routing` flag) # docker tag docker.io/library/ubuntu:24.04 cnoe.localtest.me:8443/giteaadmin/ubuntu:24.04 # docker push cnoe.localtest.me:8443/giteaadmin/ubuntu:24.04 ```bash **NOTE**: You can get the giteaAdmin password in the same way as you do for the web or git interface. $idpbuilder get secrets -p gitea Or you can use this to login directly: $idpbuilder get secrets -p gitea -o json | \\ jq '.[0].password' -r | \\ docker login -u giteaAdmin --password-stdin gitea.cnoe.localtest.me:8443  ","version":"Next","tagName":"h3"},{"title":"Tagging Image​","type":1,"pageTitle":"IDPBuilder","url":"/docs/idpbuilder#tagging-image","content":" Images pushed to Gitea OCI registry must be tagged with the following naming convention:  {registry}/{owner}/{image}  For example: gitea.cnoe.localtest.me:8443/giteaadmin/ubuntu:24.04  This is a naming convention enforced by Gitea. Please see the Gitea documentation for more information.  ","version":"Next","tagName":"h3"},{"title":"Pulling Images​","type":1,"pageTitle":"IDPBuilder","url":"/docs/idpbuilder#pulling-images","content":" You can pull an image back to your local machine using your docker client like so:  $docker pull gitea.cnoe.localtest.me:8443/giteaadmin/ubuntu:24.04  No Pull Secret Needed​  The Gitea instance allows for anonymous read access. This means that you can pull git repo contents and container images without logging in.  ","version":"Next","tagName":"h3"},{"title":"Referencing Images In Manifests On The Idpbuilder K8s Cluster​","type":1,"pageTitle":"IDPBuilder","url":"/docs/idpbuilder#referencing-images-in-manifests-on-the-idpbuilder-k8s-cluster","content":" You can create a pod or a deployment that references images in the local registry. For example, to create a pod:  apiVersion: v1 kind: Pod metadata: namespace: default name: debug-pod spec: containers: - image: gitea.cnoe.localtest.me:8443/giteaadmin/ubuntu:24.04 name: debug-pod command: - sleep - &quot;3600&quot;   ","version":"Next","tagName":"h3"},{"title":"Pulling Images From Inside Idpbuilder K8s Cluster:​","type":1,"pageTitle":"IDPBuilder","url":"/docs/idpbuilder#pulling-images-from-inside-idpbuilder-k8s-cluster","content":" Because we are using an NGINX Ingress and pushing our image from off cluster, Gitea and its OCI registry think all images pushed to it are prefixed with gitea.cnoe.localtest.me:8443.  This is correct by the OCI spec standards. However, when you are on the cluster, that ingress is not available to you. You can use the service name of gitea, but gitea will not know what images are being asked for at the svc domain name. To work around this issue, we use containerd to rewrite those image names so that they can be referenced at the external url:  See the Kind config for how this is done.  ","version":"Next","tagName":"h3"},{"title":"Transferring images from remote registries to idbpbuilder​","type":1,"pageTitle":"IDPBuilder","url":"/docs/idpbuilder#transferring-images-from-remote-registries-to-idbpbuilder","content":" Now that you have a registry up and running at cnoe.localtest.me:8443 you can copy your images to it. This is especially convenient if you want to pre-load a number of images from some remote before going offline. You can also use this technique to load images into codespaces that are behind a corporate firewall.  To make this even easier, you can use a tool like ORAS or regclient to copy between them. These tools are beyond the scope of this help document, but at the time of this writing a simple copy command using regclient looks like:  $regctl registry login cnoe.localtest.me:8443 Enter Username [giteaadmin]: giteaadmin Enter Password: $regctl registry set cnoe.localtest.me:8443 --tls=insecure time=2024-12-29T21:50:58.354-05:00 level=WARN msg=&quot;Changing TLS settings for registry&quot; orig=enabled new=insecure host=cnoe.localtest.me:8443 $regctl image copy docker.io/library/alpine:latest cnoe.localtest.me:8443/gitea/giteaadmin/alpine:latest time=2024-12-29T21:50:07.489-05:00 level=WARN msg=&quot;Changing TLS settings for registry&quot; orig=enabled new=disabled host=expert-chainsaw-7vjwj6qqgcprjp-8443.app.github.dev time=2024-12-29T21:50:07.489-05:00 level=WARN msg=&quot;Changing TLS settings for registry&quot; orig=enabled new=insecure host=cnoe.localtest.me:8443 Manifests: 17/17 | Blobs: 0.000B copied, 0.000B skipped | Elapsed: 0s cnoe.localtest.me:8443/gitea/giteaadmin/alpine:latest ","version":"Next","tagName":"h3"},{"title":"Technology Radars","type":0,"sectionRef":"#","url":"/docs/overview/radar","content":"Technology Radars Skip to main content DocsBlog Loading data... DOCS IntroductionContribute SOCIAL SlackCommunity Meeting Calendar MORE BlogGitHub Copyright © 2025 CNOE","keywords":"","version":"Next"},{"title":"Technology Choices","type":0,"sectionRef":"#","url":"/docs/overview/technology","content":"Technology Choices Every organization has slightly different requirements for their internal developer platforms (IDPs) and as such designing an all inclusive solution for an IDP is neither reasonable nor possible. tip Despite the differences in IDPs, there are common tooling, patterns, and practices that emerge across organizations. While there is common agreements in how to use different tools across existing capabilities in IDPs, there is little to no references on how these tools can be configured and combined together to deliver the desired platform engineering practices efficiently. The goal for CNOE is to capture and provide references for tools commonly used by platform engineers to design their IDPs, the way these tools are configured, and implementations for common patterns and practices that can be extended and used across organizations. CNOE by no means tries to be comprehensive, but instead it aims to collect community driven patterns and best practices based on what is commonly deployed in production. For CNOE reference implementations we will provide configurations, patterns, and practices with the following (growing) list of technologies. Capability\tTechnologiesCode Repository\tGit Config Repository\tGit Artifact Registry\tContainer Registries Secret Repository\tExternal Secrets (with Vault and KMS) Validations\tCNOE Validators Secret Management\tExternal Secrets Infra as Code\tTerraform, Crossplane Continuous Delivery\tArgo CD, Flux Continuous Integrations\tArgo Workflows, Tekton Identity &amp; Access\tKeyCloak Developer Portals\tBackstage","keywords":"","version":"Next"},{"title":"Using IDPBuilder","type":0,"sectionRef":"#","url":"/docs/idpbuilder/usage","content":"","keywords":"","version":"Next"},{"title":"Basic usage​","type":1,"pageTitle":"Using IDPBuilder","url":"/docs/idpbuilder/usage#basic-usage","content":" The most basic command which creates a Kubernetes Cluster (Kind cluster) with the core packages installed.  $idpbuilder create  Once idpbuilder finishes provisioning cluster and packages, you can access GUIs by going to the following addresses in your browser.  ArgoCD: https://argocd.cnoe.localtest.me:8443/Gitea: https://gitea.cnoe.localtest.me:8443/  You can obtain credentials for them by running the following command:  $idpbuilder get secrets  Color Output idpbuilder supports colored output with the --color flag. $idpbuilder create --color  ","version":"Next","tagName":"h2"},{"title":"Example commands​","type":1,"pageTitle":"Using IDPBuilder","url":"/docs/idpbuilder/usage#example-commands","content":" For more advanced use cases, check out the Stacks Repository.  ","version":"Next","tagName":"h2"},{"title":"Create​","type":1,"pageTitle":"Using IDPBuilder","url":"/docs/idpbuilder/usage#create","content":" Specify the kubernetes version by using the --kube-version flag. Supported versions are available here.  $idpbuilder create --kube-version v1.27.3  Specify your own kind configuration file, use the --kind-config flag.  $idpbuilder create --build-name local --kind-config ./my-kind.yaml  Override ArgoCD configmap.  $idpbuilder create --package-custom-file=argocd:path/to/argocd-cm.yaml  Example Contents of argocd-cm.yaml This configuration allows for anonymous login apiVersion: v1 kind: ConfigMap metadata: labels: # Labels below are required by ArgoCD app.kubernetes.io/name: argocd-cm app.kubernetes.io/part-of: argocd Test: Data name: argocd-cm data: # Enables anonymous user access. The anonymous users get default role permissions specified argocd-rbac-cm.yaml. users.anonymous.enabled: &quot;true&quot; application.resourceTrackingMethod: annotation resource.exclusions: | - kinds: - ProviderConfigUsage apiGroups: - &quot;*&quot;   Use a public repository to pull extra packages. See this section for more information.  $idpbuilder create -p https://github.com/cnoe-io/stacks//basic/package1  Use a private repository to pull extra packages.  $git clone https://github.com/cnoe-io/stacks-private $idpbuilder create -p ./stacks-private/basic/package1  Increase the verbosity of idpbuilder for troubleshooting.  $idpbuilder create -l debug  For available flags and subcommands:  $idpbuilder create --help  ","version":"Next","tagName":"h3"},{"title":"Get​","type":1,"pageTitle":"Using IDPBuilder","url":"/docs/idpbuilder/usage#get","content":" Get all relevant secrets. See this section for more information.  $idpbuilder get secrets  Get secrets for a package named gitea.  $idpbuilder get secrets -p gitea  ","version":"Next","tagName":"h3"},{"title":"Delete​","type":1,"pageTitle":"Using IDPBuilder","url":"/docs/idpbuilder/usage#delete","content":" Delete a cluster named localdev.  $idpbuilder delete --name localdev  ","version":"Next","tagName":"h3"},{"title":"Gitea Integration​","type":1,"pageTitle":"Using IDPBuilder","url":"/docs/idpbuilder/usage#gitea-integration","content":" idpbuilder creates an internal Gitea server (accessible from your laptop and kind cluster only). This can be used for various purposes such as sources for ArgoCD, container registry, and more. To facilitate interactions with Gitea, idpbuilder creates a token with administrator scope, then stores it in a Kubernetes secret.  The token can be obtained by running the following command:  # print all secrets associated with gitea $idpbuilder get secrets -p gitea # get token only $idpbuilder get secrets -p gitea -o json | jq -r '.[0].data.token  Here are a some examples for using the token:  Create a Gitea Organization $TOKEN=$(idpbuilder get secrets -p gitea -o json | jq -r '.[0].data.token' ) $curl -k -X POST \\ https://gitea.cnoe.localtest.me:8443/api/v1/orgs \\ -H 'Content-Type: application/json' \\ -H &quot;Authorization: Bearer $TOKEN&quot; \\ -d '{&quot;description&quot;: &quot;my-org&quot;, &quot;email&quot;: &quot;my-org@my.m&quot;, &quot;full_name&quot;: &quot;my-org&quot;, &quot;username&quot;: &quot;my-org&quot;}'  Create a Gitea User $TOKEN=$(idpbuilder get secrets -p gitea -o json | jq -r '.[0].data.token' ) $curl -k -X POST \\ https://gitea.cnoe.localtest.me:8443/api/v1/admin/users \\ -H 'Content-Type: application/json' \\ -H &quot;Authorization: Bearer $TOKEN&quot; \\ -d '{&quot;email&quot;: &quot;my-org@my.m&quot;, &quot;full_name&quot;: &quot;user one&quot;, &quot;username&quot;: &quot;user1&quot;, &quot;password&quot;: &quot;password&quot;, &quot;must_change_password&quot;: true}'  ","version":"Next","tagName":"h2"},{"title":"Custom Packages​","type":1,"pageTitle":"Using IDPBuilder","url":"/docs/idpbuilder/usage#custom-packages","content":" Idpbuilder supports specifying custom packages using the flag -p flag. This flag expects a directory (local or remote) containing ArgoCD application files and / or ArgoCD application set files. In case of a remote directory, it must be a directory in a git repository, and the URL format must be a kustomize remote URL format.  Examples of using custom packages are available in the stacks repository. Let's take a look at this example. This defines two custom package directories to deploy to the cluster.  To deploy these packages, run the following command:  $./idpbuilder create \\ -p https://github.com/cnoe-io/stacks//basic/package1 \\ -p https://github.com/cnoe-io/stacks//basic/package2  Alternatively, you can use the local directory format.  # clone the stacks repository $git clone https://github.com/cnoe-io/stacks.git $cd stacks # run idpbuilder against the local directory $./idpbuilder create -p examples/basic/package1 -p examples/basic/package2  Running this command should create three additional ArgoCD applications in your cluster.  $kubectl get Applications -n argocd -l example=basic NAME SYNC STATUS HEALTH STATUS guestbook Synced Healthy guestbook2 Synced Healthy my-app Synced Healthy  Let's break this down. The first package directory defines an application. This corresponds to the my-app application above. In this application, we want to deploy manifests from local machine in GitOps way.  The directory contains an ArgoCD application file. This is a normal ArgoCD application file except for one field.  apiVersion: argoproj.io/v1alpha1 kind: Application spec: source: repoURL: cnoe://manifests   The cnoe:// prefix in the repoURL field indicates that we want to sync from a local directory. Values after cnoe:// is treated as a relative path from this file. In this example, we are instructing idpbuilder to make ArgoCD sync from files in the manifests directory.  As a result the following actions were taken by idpbuilder:  Create a Gitea repository.Fill the repository with contents from the manifests directory.Update the Application spec to use the newly created repository.  You can verify this by going to this address in your browser: https://gitea.cnoe.localtest.me:8443/giteaAdmin/idpbuilder-localdev-my-app-manifests    This is the repository that corresponds to the manifests folder. It contains a file called alpine.yaml, synced from the manifests directory above.  You can also view the updated Application spec by going to this address: https://argocd.cnoe.localtest.me:8443/applications/argocd/my-app    The second package directory defines two normal ArgoCD applications referencing a remote repository. They are applied as-is.  ","version":"Next","tagName":"h2"},{"title":"Workflows​","type":1,"pageTitle":"Using IDPBuilder","url":"/docs/idpbuilder/usage#workflows","content":" In some situations, you need to run imperative jobs such as creating users in your service, managing secrets, or calling APIs. ArgoCD Resource Hooks are perfect for these scenarios. These hooks allow you to execute imperative workflows at various stages of the ArgoCD sync process.  For example, you can create a Kubernetes job that runs after a PostgreSQL database is created and ready by using the PostSync hook. Here's an example:  Example PostgreSQL User Creation Hook apiVersion: batch/v1 kind: Job metadata: name: create-db-user annotations: argocd.argoproj.io/hook: PostSync argocd.argoproj.io/hook-delete-policy: HookSucceeded spec: template: spec: containers: - name: create-user image: bitnami/postgresql:latest command: [&quot;/bin/bash&quot;, &quot;-c&quot;] args: - | PGPASSWORD=$POSTGRES_PASSWORD psql -h postgresql -U postgres &lt;&lt;'EOF' DO $$ BEGIN IF NOT EXISTS (SELECT FROM pg_catalog.pg_roles WHERE rolname = 'myapp') THEN CREATE USER myapp WITH PASSWORD 'mypassword'; GRANT ALL PRIVILEGES ON DATABASE mydatabase TO myapp; END IF; END $$; EOF env: - name: POSTGRES_PASSWORD valueFrom: secretKeyRef: name: postgresql key: postgres-password restartPolicy: Never backoffLimit: 3   More complex examples are available here  ","version":"Next","tagName":"h2"},{"title":"Exposing Services​","type":1,"pageTitle":"Using IDPBuilder","url":"/docs/idpbuilder/usage#exposing-services","content":" Idpbuilder comes with ingress-nginx, and this is meant to be used as an easy way to expose services to the outside world. See the networking overview section for more information. By default, idpbuilder exposes the ingress-nginx service on host port 8443 and Kubernetes Ingress objects are created for core packages. For example, an ingress object for Gitea looks something like this:  apiVersion: networking.k8s.io/v1 kind: Ingress spec: ingressClassName: nginx rules: - host: gitea.cnoe.localtest.me http: paths: - path: / backend: service: name: my-gitea-http   With this configuration, nginx routes traffic to Gitea service when http requests are made for gitea.cnoe.localtest.me.  Similarly, you can expose your own service by defining an ingress object. For example, to expose a service named my-service at my-service.cnoe.localtest.me, the ingress object may look something like this.  apiVersion: networking.k8s.io/v1 kind: Ingress metadata: name: my-service spec: ingressClassName: nginx rules: - host: my-service.cnoe.localtest.me http: paths: - backend: service: name: my-service port: number: 80 path: / pathType: Prefix   ","version":"Next","tagName":"h2"},{"title":"Running IDPBuilder on a remote host​","type":1,"pageTitle":"Using IDPBuilder","url":"/docs/idpbuilder/usage#running-idpbuilder-on-a-remote-host","content":" ","version":"Next","tagName":"h2"},{"title":"Option 1: SSH Port forwarding​","type":1,"pageTitle":"Using IDPBuilder","url":"/docs/idpbuilder/usage#option-1-ssh-port-forwarding","content":" This option is the most flexible and involves using an ssh connection to forward traffic from local ports to the server where IDPBuilder was run. First create your cluster on the server:  user@server:~/$ idpbuilder create   Once your cluster is created we need to configure our port forwards:  user@local:~/$ ssh -L 8443:server:8443 -L 32222:server:32222 user@server   -L 8443:server:8443 adds portforwarding for the ingress.  -L 32222:server:32222 adds portforwarding for the gitea ssh port.  If you want to use kubectl on your local machine first find the port the kube-api is exposed on:  user@server:~/$ idpbuilder get clusters NAME EXTERNAL-PORT KUBE-API TLS KUBE-PORT NODES localdev 8443 https://127.0.0.1:36091 false 6443 localdev-control-plane   In this case it is exposed on 36091. Then add the following to your ssh command:  -L 36091:server:36091  Finally copy the kube config from the server to the local machine:  user@local:~/$ mkdir -p ~/.kube user@local:~/$ scp user@server:~/.kube/config ~/.kube/config   ","version":"Next","tagName":"h3"},{"title":"Option 2: Changing the ingress host​","type":1,"pageTitle":"Using IDPBuilder","url":"/docs/idpbuilder/usage#option-2-changing-the-ingress-host","content":" If you only need remote access to the ingress you can build your remote cluster using the following options:  user@server:~/$ idpbuilder create --host SERVER.DOMAIN.NAME.HERE --use-path-routing   note that this doesn't work with the --dev-password flag. ","version":"Next","tagName":"h3"},{"title":"Installation Flow","type":0,"sectionRef":"#","url":"/docs/reference-implementation/aws/docs/installation_flow","content":"","keywords":"","version":"Next"},{"title":"Overview​","type":1,"pageTitle":"Installation Flow","url":"/docs/reference-implementation/aws/docs/installation_flow#overview","content":" The CNOE AWS Reference Implementation uses a GitOps approach to deploy and manage addons on an EKS cluster. The installation process uses helm to bootstrap the EKS cluster. Detailed installation sequence is described below.  ","version":"Next","tagName":"h2"},{"title":"Installation Process​","type":1,"pageTitle":"Installation Flow","url":"/docs/reference-implementation/aws/docs/installation_flow#installation-process","content":" User Approval User starts by executing the scripts/install.sh script which displays details such as target EKS cluster and AWS Region etc. It also requests approval from the user to proceed with installation. Setup Configuration: AWS Secrets Manager secrets are created to store configuration and GitHub App credentials using create-config-secrets.sh script. These secrets are fetched into the cluster by External Secret Operator.The config.yaml file is used to configure the installation.install.sh script reads the config.yaml and based on the specified cluster name, fetches kubeconfig of EKS cluster using AWS CLI. This kubeconfig is used for helm installation by overriding default kubeconfig. EKS Cluster Bootstrap: The script first performs helm installation of Argo CD and External Secret Operator (ESO) on the EKS cluster. It will use the temporary kubeconfig for accessing the EKS cluster. The values used for installation are static values from packages/&lt;addon-name&gt;/values.yaml which are the same files used by addons later.Then the script applies custom manifests for these addons from the directory packages/&lt;addon-name&gt;/manifests/. For ESO, this directory contains the AWS Secret Manager ClusterStore manifest and for Argo CD, it contains manifests for External Secrets of in-cluster Argo CD secret and Github App Argo CD repository credentials. These External Secrets use AWS Secret Manager ClusterStore.Then ESO will create corresponding kubernetes secrets for Argo CD cluster secret and repository credentials by fetching values from AWS Secret Manager which were created earlier. Addons Deployment: The script will wait 10 seconds and install the AppSet chart on the EKS cluster which creates ApplicationSets for all the enabled addons based on values in packages/addons/values.yaml.Each ApplicationSet will use Argo CD Cluster Generator to create respective Argo CD Application. The Cluster Generator will generate one Argo CD Application for each enabled addon as there is only one Argo CD cluster secret.Although the Argo CD Applications for each addon are created, each addon will take some time to reach Healthy state due to dependencies explained in the dependency section. Addon Configuration: Addons are configured using helm valuesStatic values are stored in packages/&lt;addon-name&gt;/values.yamlDynamic values from Argo CD cluster secret labels/annotations depend on configuration from AWS Secrets Manager. Monitoring and Verification: The installation script waits for all Argo CD applications to become healthyAddons can be accessed through the configured domain based on path routing settings  ","version":"Next","tagName":"h2"},{"title":"Addons Dependencies​","type":1,"pageTitle":"Installation Flow","url":"/docs/reference-implementation/aws/docs/installation_flow#addons-dependencies","content":" The following is the order for addons reaching healthy state when using Path Routing.    The colors of edges in this diagram indicate the parallel progress of addons to reach healthy state. As seen in the diagram, all the addons will reach the Healthy state in parallel except Cert Manager, Keycloak, Backstage and Argo Workflows.Both Backstage and Argo Workflow addons depend on the Healthy status of External DNS, Cert-Manager, NGINX and Keycloak.This sequential order for these addons is due to dependency of Keycloak Client creation for Backstage and Argo Workflows and both these addons also need to reach Keycloak using external URL to verify SSO configuration. Therefore, both Backstage and Argo Workflows will stay unhealthy until Keycloak reaches healthy state.The Keycloak client creation is done using a Job pod (packages/keycloak/manifests/user-sso-config-job.yaml). This job pod creates the Keycloak clients for Argo CD, Backstage and Argo Workflows. It also creates the kubernetes secret keycloak-clients containing client secrets.Once the client creation is successful, The ClusterSecretStore (packages/keycloak/manifests/keycloak-cluster-secret-store.yaml) is created so that ESO can create kubernetes secrets for Client Secrets in Backstage and Argo Workflows namespace.When the kubernetes secrets for Keycloak Client Secrets are created in Backstage and Argo Workflows namespace, these addons will reach Healthy state.  ","version":"Next","tagName":"h2"},{"title":"Uninstallation Process​","type":1,"pageTitle":"Installation Flow","url":"/docs/reference-implementation/aws/docs/installation_flow#uninstallation-process","content":" The uninstallation process follows these steps:  Remove idpbuilder Local Cluster: The local Kind cluster created by idpbuilder is deleted Remove Addons: Addons are removed in a specific order to handle dependenciesApplicationSets are deleted with orphan deletion policyPVCs for stateful applications are cleaned up CRD Cleanup (Optional): Custom Resource Definitions can be cleaned up using the cleanup-crds.sh scriptThis is optional and useful when you want to completely remove all traces of the installation ","version":"Next","tagName":"h2"},{"title":"Set up IDP Reference Implementation on Local Machine","type":0,"sectionRef":"#","url":"/docs/reference-implementation/local","content":"","keywords":"","version":"Next"},{"title":"Prerequisites​","type":1,"pageTitle":"Set up IDP Reference Implementation on Local Machine","url":"/docs/reference-implementation/local#prerequisites","content":" Ensure you have the following tools installed on your computer.  Required  Complete the idpbuilder installationidpbuilder: version 0.3.0 or later.kubectl: version 1.27 or laterYour computer should have at least 6 GB RAM allocated to Docker. If you are on Docker Desktop, see this guide.  Optional  AWS credentials: Access Key and secret Key. If you want to create AWS resources in one of examples below.  ","version":"Next","tagName":"h2"},{"title":"Installation​","type":1,"pageTitle":"Set up IDP Reference Implementation on Local Machine","url":"/docs/reference-implementation/local#installation","content":" note If you'd like to run this in your web browser through Codespaces, please follow the instructions here to install instead. This example assumes that you run the reference implementation with the default port configguration of 8443 for the idpBuilder. If you happen to configure a different host or port for the idpBuilder, the manifests in the reference example need to be updated and be configured with the new host and port.  Run the following command from the root of this repository.  $idpbuilder create --use-path-routing \\ --package https://github.com/cnoe-io/stacks//ref-implementation  This will take ~6 minutes for everything to come up. To track the progress, you can go to the ArgoCD UI.  ","version":"Next","tagName":"h2"},{"title":"What was installed?​","type":1,"pageTitle":"Set up IDP Reference Implementation on Local Machine","url":"/docs/reference-implementation/local#what-was-installed","content":" Argo Workflows to enable workflow orchestrations.Backstage as the UI for software catalog and templating. Source is available here. Also check server side authentication for Backstage users access.Crossplane, AWS providers, and basic compositions for deploying cloud related resources (needs your credentials for this to work)External Secrets to generate secrets and coordinate secrets between applications.Keycloak as the identity provider for applications. Also check keycloak authentication for Backstage users access.Spark Operator to demonstrate an example Spark workload through Backstage.  If you don't want to install a package above, you can remove the ArgoCD Application file corresponding to the package you want to remove. For example, if you want to remove Spark Operator, you can delete this file.  # remove spark operator from this installation. $rm examples/ref-implementation/spark-operator.yaml  The only package that cannot be removed this way is Keycloak because other packages rely on it.  ","version":"Next","tagName":"h3"},{"title":"Concepts​","type":1,"pageTitle":"Set up IDP Reference Implementation on Local Machine","url":"/docs/reference-implementation/local#concepts","content":" Access Management​  This section details how access management is implemented using Keycloak as the identity provider and also explaining the current server-side authentication pattern in Backstage where all users share the same credential level.  Infrastructure Control Plane​  The infrastructure control plane utilizes Crossplane for AWS resource management and ArgoCD for manifest synchronization, combining GitOps and Crossplane compositions to provision and govern external resources through Kubernetes APIs. This approach allows for the enforcement of security and configuration requirements, such as tagging and encryption for S3 buckets, while also enabling developer self-service through YAML files in a Git repository.  Secrets Management​  The External Secrets Operator is a Kubernetes Operator that retrieves secrets from external secret stores (like Vault and AWS Secrets Manager) and creates corresponding Kubernetes secrets within the cluster. The operator can manage various types of secrets including TLS certificates, with the ability to sync them between external stores and the cluster, while also providing features like automatic backup during uninstallation to avoid hitting rate limits with services like Let's Encrypt.  ","version":"Next","tagName":"h3"},{"title":"Accessing UIs​","type":1,"pageTitle":"Set up IDP Reference Implementation on Local Machine","url":"/docs/reference-implementation/local#accessing-uis","content":" Argo CD: https://cnoe.localtest.me:8443/argocdArgo Workflows: https://cnoe.localtest.me:8443/argo-workflowsBackstage: https://cnoe.localtest.me:8443/Gitea: https://cnoe.localtest.me:8443/giteaKeycloak: https://cnoe.localtest.me:8443/keycloak/admin/master/console/  ","version":"Next","tagName":"h3"},{"title":"Logging into Backstage​","type":1,"pageTitle":"Set up IDP Reference Implementation on Local Machine","url":"/docs/reference-implementation/local#logging-into-backstage","content":" Once applications are ready, go to the backstage URL.  Click on the Sign-In button, you will be asked to log into the Keycloak instance. There are two users set up in this configuration, and their password can be retrieved with the following command:  $idpbuilder get secrets  Use the username user1 and the password value given by USER_PASSWORD field to login to the backstage instance.user1 is an admin user who has access to everything in the cluster, while user2 is a regular user with limited access. Both users use the same password retrieved above.  If you want to create a new user or change existing users:​  Go to the Keycloak UI. Login with the username cnoe-admin. Password is the KEYCLOAK_ADMIN_PASSWORD field from the command above.Select cnoe from the realms drop down menu.Select users tab.  ","version":"Next","tagName":"h3"},{"title":"Usecases​","type":1,"pageTitle":"Set up IDP Reference Implementation on Local Machine","url":"/docs/reference-implementation/local#usecases","content":" For the demonstration, we will walk through few example usecases.  In the below examples, we have used the pattern of creating a new repository for every app, then having ArgoCD deploy it. This is done for convenience and demonstration purposes only. There are alternative actions that you can use. For example, you can create a PR to an existing repository, create a repository but not deploy them yet, etc. If Backstage's pipelining and templating mechanisms is too simple, you can use more advanced workflow engines like Tekton or Argo Workflows. You can invoke them in Backstage templates, then track progress similar to how it was described above.  ","version":"Next","tagName":"h2"},{"title":"Basic Deployment​","type":1,"pageTitle":"Set up IDP Reference Implementation on Local Machine","url":"/docs/reference-implementation/local#basic-deployment","content":" Let's start by deploying a simple application to the cluster through Backstage.  Click on the Create... button on the left, then select the Create a Basic Deployment template.    In the next screen, type demo for the name field, then click Review, then Create. Once steps run, click the Open In Catalog button to go to the entity page.    In the demo entity page, you will notice a ArgoCD overview card associated with this entity. You can click on the ArgoCD Application name to see more details.    What just happened?​  Backstage created a git repository, then pushed templated contents to it.Backstage created an ArgoCD Application and pointed it to the git repository.Backstage registered the application as a component in Backstage.ArgoCD deployed the manifests stored in the repo to the cluster.Backstage retrieved application health from ArgoCD API, then displayed it.    ","version":"Next","tagName":"h3"},{"title":"Argo Workflows and Spark Operator​","type":1,"pageTitle":"Set up IDP Reference Implementation on Local Machine","url":"/docs/reference-implementation/local#argo-workflows-and-spark-operator","content":" In this example, we will deploy a simple Apache Spark job through Argo Workflows.  Click on the Create... button on the left, then select the Basic Argo Workflow with a Spark Job template.    Type demo2 for the name field, then click create. You will notice that the Backstage templating steps are very similar to the basic example above. Click on the Open In Catalog button to go to the entity page.    Deployment processes are the same as the first example. Instead of deploying a pod, we deployed a workflow to create a Spark job.  In the entity page, there is a card for Argo Workflows, and it should say running or succeeded. You can click the name in the card to go to the Argo Workflows UI to view more details about this workflow run. When prompted to log in, click the login button under single sign on. Argo Workflows is configured to use SSO with Keycloak allowing you to login with the same credentials as Backstage login.  Note that Argo Workflows are not usually deployed this way. This is just an example to show you how you can integrate workflows, backstage, and spark.  Back in the entity page, you can view more details about Spark jobs by navigating to the Spark tab.  ","version":"Next","tagName":"h3"},{"title":"Application with cloud resources.​","type":1,"pageTitle":"Set up IDP Reference Implementation on Local Machine","url":"/docs/reference-implementation/local#application-with-cloud-resources","content":" Similar to the above, we can deploy an application with cloud resources using Backstage templates. In this example, we will create an application with a S3 Bucket.  Add the Crossplane integration as discussed here.  Choose a template named App with S3 bucket, type demo3 as the name, then choose a region to create this bucket in.  Once you click the create button, you will have a very similar setup as the basic example. The only difference is we now have a resource for a S3 Bucket which is managed by Crossplane.  Note that Bucket is not created because Crossplane doesn't have necessary credentials to do so. If you'd like it to actually create a bucket, update the credentials secret file, then run idpbuilder create --package examples/ref-implementation.  In this example, we used Crossplane to provision resources, but you can use other cloud resource management tools such as Terraform instead. Regardless of your tool choice, concepts are the same. We use Backstage as the templating mechanism and UI for users, then use Kubernetes API with GitOps to deploy resources. ","version":"Next","tagName":"h3"},{"title":"Troubleshooting","type":0,"sectionRef":"#","url":"/docs/reference-implementation/aws/docs/troubleshooting","content":"","keywords":"","version":"Next"},{"title":"Investigating Failures​","type":1,"pageTitle":"Troubleshooting","url":"/docs/reference-implementation/aws/docs/troubleshooting#investigating-failures","content":" All adoons are deployed as ArgoCD application in a two-step process.  Bootstraping the EKS cluster with Argo CD and External Secret Operator using idpbuilderCreating rest of the addons through Argo CD on EKS cluster.  Therefore, the best way to investigate and issue is to navigate to respective ArgoCD UI and review any errors in Argo CD application or in logs of the specific addon.  First, switch context to kind-localdev cluster (idpbuilder) or EKS cluster and run following command to retrieve passwordof Argo CD.  kubectl get secrets -n argocd argocd-initial-admin-secret -oyaml | yq '.data.password' | base64 -d # OR idpbuilder get secrets -p argocd -o yaml  To Access idpbuilder Argo CD:  In a web browser, Visit https://cnoe.localtest.me:8443/argocd.  To Access EKS Cluster Argo CD:Verify if the Argo CD, Ingress NGINX and Cert-Manager addons on EKS cluster are healthy.  kubectl get applications -n argocd   If these addons are healthy then the EKS cluster Argo CD can be accessed directly in web browser using URL https://argocd.[domain_name] or https://[domain_name]/argocd  Otherwise, start a kubernetes port forward session for Argo CD:  kubectl port-forward -n argocd svc/argocd-server 8080:80   After this, visit https://localhost:8080 or https://localhost:8080/argocd in a web browser.  ","version":"Next","tagName":"h2"},{"title":"Common issues​","type":1,"pageTitle":"Troubleshooting","url":"/docs/reference-implementation/aws/docs/troubleshooting#common-issues","content":" ","version":"Next","tagName":"h2"},{"title":"DNS Records not updated after reinstallation​","type":1,"pageTitle":"Troubleshooting","url":"/docs/reference-implementation/aws/docs/troubleshooting#dns-records-not-updated-after-reinstallation","content":" External DNS does not delete DNS records during uninstallation. After reinstallation, External DNS might not be able to update the records with new values. in such cases, delete A, AAAA and TXT records from the Route 53 Hosted Zone and restart the external DNS pods. This will trigger a creation of new records.  ","version":"Next","tagName":"h3"},{"title":"Certificate not issued by Cert Manager​","type":1,"pageTitle":"Troubleshooting","url":"/docs/reference-implementation/aws/docs/troubleshooting#certificate-not-issued-by-cert-manager","content":" Describe the pending certificate challenge. If it shows message similar to:  Reason: Waiting for HTTP-01 challenge propagation: failed to perform self check GET request 'http://DOMAIN_NAME/.well-known/acme-challenge/6AQ5cRc7J6FNQ9xGOBDI5_G1lHsNM5J5ivbS3iSHd3c': Get &quot;http://DOMAIN_NAME/.well-known/acme-challenge/6AQ5cRc7J6FNQ9xGOBDI5_G1lHsNM5J5ivbS3iSHd3c&quot;: dial tcp: lookup argo.DOMAIN_NAME on 10.100.0.10:53: no such host   This is due to DNS propagation delay in the cluster. Once DNS entries are propagated (may take ~10 min), certificate should be issued.  The reference implentation uses Lets Encrypt production API for requesting certificates. This API has certain limits on number of certificates issued. Due to these rate limits certificates may not be issued. Refer to Lets Encrypt documentation for more information about this API throttling. ","version":"Next","tagName":"h3"},{"title":"AWS Reference Implementation","type":0,"sectionRef":"#","url":"/docs/reference-implementation/aws","content":"","keywords":"","version":"Next"},{"title":"Architecture Overview​","type":1,"pageTitle":"AWS Reference Implementation","url":"/docs/reference-implementation/aws#architecture-overview","content":"   ","version":"Next","tagName":"h2"},{"title":"Addons​","type":1,"pageTitle":"AWS Reference Implementation","url":"/docs/reference-implementation/aws#addons","content":" All the addons are helm charts with static values configured in packages/&lt;addon-name&gt;/values.yaml and dynamic values based on Argo CD cluster secret label/annotations values in packages/addons/values.yaml.  Name\tNamespace\tPurpose\tChart Version\tChartArgo CD\targocd\tInstallation and management of addon Argo CD application\t8.0.14\tLink Argo Workflows\targo\tWorkflow tool for continuous integration tasks\t0.45.18\tLink Backstage\tbackstage\tSelf-Service Web UI (Developer Portal) for developers\t2.6.0\tLink Cert Manager\tcert-manager\tCertificate manager for addons and developer applications using Let's Encrypt\t1.17.2\tLink Crossplane\tcrossplane-system\tIaC controller for provisioning infrastructure\t1.20.0\tLink ACK\tack-system\tIaC controller for provisioning infrastructure\tTBD\tComing soon check #54 External DNS\texternal-dns\tDomain management using Route 53\t1.16.1\tLink External Secrets\texternal-secrets\tSecret Management using AWS Secret Manager and AWS Systems Manager Parameter Store\tVersion\tLink Ingress NGINX\tingress-nginx\tIngress controller for L7 network traffic routing\t4.7.0\tLink Keycloak\tkeycloak\tIdentity provider for User Authentication\t24.7.3\tLink  Check out more details about the installation flow.  ","version":"Next","tagName":"h2"},{"title":"Installation Flow Diagram​","type":1,"pageTitle":"AWS Reference Implementation","url":"/docs/reference-implementation/aws#installation-flow-diagram","content":" This diagram illustrates the high-level installation flow for the CNOE AWS Reference Implementation. It shows how the local environment interacts with AWS resources to deploy and configure the platform on an EKS cluster.    ","version":"Next","tagName":"h2"},{"title":"Getting Started​","type":1,"pageTitle":"AWS Reference Implementation","url":"/docs/reference-implementation/aws#getting-started","content":" ","version":"Next","tagName":"h2"},{"title":"Step 1. ⚙️ Prepare Environment for Installation​","type":1,"pageTitle":"AWS Reference Implementation","url":"/docs/reference-implementation/aws#step-1-️-prepare-environment-for-installation","content":" 📦 Install Binaries​  The installation requires the following binaries in the local environment:  AWS CLIkubectlyqhelm  🔐 Configure AWS Credentials​  Configure the AWS CLI with credentials of an IAM role which has access to the EKS cluster. Follow the instructions in the AWS documentation to configure the AWS CLI.  If the installation steps are being executed on an EC2 instance, ensure that the EC2 IAM instance role has permissions to access the EKS cluster or the AWS CLI is configured as mentioned above.  ","version":"Next","tagName":"h3"},{"title":"Step 2. 🏢 Create GitHub Organization​","type":1,"pageTitle":"AWS Reference Implementation","url":"/docs/reference-implementation/aws#step-2--create-github-organization","content":" Backstage and Argo CD in this reference implementation are integrated with GitHub. Both Backstage and ArgoCD use Github Apps for authenticating with Github.  Therefore, a GitHub Organization should be created in order to create GitHub Apps for these integrations. Follow the instructions in GitHub documentation to create new organization or visit here.  note It is recommended to use a Github Organization instead of a personal github ID as Backstage has certain limitations for using personal account Github Apps for authenticating to Github. Also, the Github Organization is FREE.  ","version":"Next","tagName":"h3"},{"title":"Step 3. 🍴 Fork the Repository​","type":1,"pageTitle":"AWS Reference Implementation","url":"/docs/reference-implementation/aws#step-3--fork-the-repository","content":" Once the organization is created, fork this repository to the new GitHub Organization by following instructions in GitHub documentation.  ","version":"Next","tagName":"h3"},{"title":"Step 4. 💻 Create GitHub Apps​","type":1,"pageTitle":"AWS Reference Implementation","url":"/docs/reference-implementation/aws#step-4--create-github-apps","content":" There are two ways to create a GitHub App. You can use the Backstage CLI npx @backstage/cli create-github-app &lt;github-org&gt; as per instructions in the Backstage documentation, or create it manually per these instructions in the GitHub documentation.  Create the following apps and store them in the corresponding file path.  App Name\tPurpose\tRequired Permissions\tFile Path\tExpected ContentBackstage\tUsed for automatically importing Backstage configuration such as Organization information, templates and creating new repositories for developer applications.\tFor All Repositories - Read access to members, metadata, and organization administration - Read and write access to administration and code\tprivate/backstage-github.yaml Argo CD\tUsed for deploying resources to cluster specified by Argo CD applications.\tFor All Repositories - Read access to checks, code, members, and metadata\tprivate/argocd-github.yaml\t  The template files for both these Github Apps are available in private directory. Copy these template files to above mentioned file path by running following command:  cp private/argocd-github.yaml.template private/argocd-github.yaml cp private/backstage-github.yaml.template private/backstage-github.yaml   After this, update the values in these files by getting them from files created by backstage-cli (if used) or get the values from Github page of App Overview.  Argo CD requires url and installationId of the GitHub app. The url is the GitHub URL of the organization. The installationId can be captured by navigating to the app installation page with URL https://github.com/organizations/&lt;Organization-name&gt;/settings/installations/&lt;ID&gt;. You can find more information on this page.  warning If the app is created using the Backstage CLI, it creates files in the current working directory. These files contain credentials. Handle them with care. It is recommended to remove these files after copying the content over to files in the private directory  note The rest of the installation process assumes the GitHub apps credentials are available in private/backstage-github.yaml and private/argocd-github.yaml  Step 5. ⚙️ Configure Reference Implementation​  The reference implementation uses config.yaml file in the repository root directory to configure the installation values. The config.yaml should be updated with appropriate values before proceeding. Refer to the following table and update all the values appropriately. All the values are required.  Parameter\tDescription\tTypecluster_name\tName of the EKS cluster for reference implementation (The name should satisfy criteria of a valid kubernetes resource name)\tstring auto_mode\tSet to &quot;true&quot; if EKS cluster is Auto Mode, otherwise &quot;false&quot;\tstring repo.url\tGitHub URL of the fork in the Github Org\tstring repo.revision\tBranch or tag which should be used for Argo CD Apps\tstring repo.basepath\tDirectory in which the configuration of addons is stored\tstring region\tAWS Region of the EKS cluster and config secret\tstring domain\tBase Domain name for exposing services (This should be base domain or sub domain of the Route53 Hosted Zone)\tstring route53_hosted_zone_id\tRoute53 hosted zone ID for configuring external-dns\tstring path_routing\tEnable path routing (&quot;true&quot;) vs domain-based routing (&quot;false&quot;)\tstring tags\tArbitrary key-value pairs for AWS resource tagging\tobject  tip If these values are updated after installation, ensure to run the command in the next step to update the values in AWS Secret Manager. Otherwise, the updated values will not reflect in the live installation.  Step 6. 🔒 Create Secrets in AWS Secret Manager​  The values required for the installation are stored in AWS Secret Manager in two secrets:  cnoe-ref-impl/config: Stores values from config.yaml in JSONcnoe-ref-impl/github-app: Stores GitHub App credentials with file name as key and content of the file as value from private directory.  Run the command below to create new secrets or update the existing secrets if they already exist.  ./scripts/create-config-secrets.sh  warning DO NOT move to next steps without completing all the instructions in this step  ","version":"Next","tagName":"h3"},{"title":"Step 7. ☸️ Create EKS Cluster​","type":1,"pageTitle":"AWS Reference Implementation","url":"/docs/reference-implementation/aws#step-7-️-create-eks-cluster","content":" The reference implementation can be installed on a new EKS cluster which can be created like this:  export REPO_ROOT=$(git rev-parse --show-toplevel) $REPO_ROOT/scripts/create-cluster.sh  You will be prompted to select eksctl or terraform  For more details on each type of tools check the corresponding guides:  eksctl: Follow the instructionsterraform: Follow the instructions  This will create all the prerequisite AWS Resources required for the reference implementation, which includes:  EKS cluster with Auto Mode or Without Auto Mode (Managed Node Group with 4 nodes)Pod Identity Associations for following Addons:  Name\tNamespace\tService Account Name\tPermissionsCrossplane\tcrossplane-system\tprovider-aws\tAdmin Permissions but with permission boundary External Secrets\texternal-secrets\texternal-secrets\tPermissions External DNS\texternal-dns\texternal-dns\tPermissions AWS Load Balancer Controller (When not using Auto Mode)\tkube-system\taws-load-balancer-controller\tPermissions AWS EBS CSI Controller (When not using Auto Mode)\tkube-system\tebs-csi-controller-sa\tPermissions  note Using Existing EKS Cluster The reference implementation can be installed on an existing EKS Cluster only if the above prerequisites are completed.  ","version":"Next","tagName":"h3"},{"title":"Step 8. 🚀 Deployment​","type":1,"pageTitle":"AWS Reference Implementation","url":"/docs/reference-implementation/aws#step-8--deployment","content":" note Before moving forward, ensure that the kubectl context is set to the EKS cluster and the configured AWS IAM role has access to the cluster.  ▶️ Start the Installation Process​  All the addons are installed as Argo CD apps. At the start of the installation, Argo CD and External Secret Operator are installed on the EKS cluster as a helm chart. Once Argo CD on EKS is up, other addons are installed through it and finally the Argo CD on EKS also manages itself and External Secret Operator. Check out more details about the installation flow. Run the following command to start the installation.  scripts/install.sh  ","version":"Next","tagName":"h3"},{"title":"Step 9. 🌐 Accessing the Platform​","type":1,"pageTitle":"AWS Reference Implementation","url":"/docs/reference-implementation/aws#step-9--accessing-the-platform","content":" The addons with Web UI are exposed using the base domain configured in Step 5. The URLs can be retrieved by running the following command:  scripts/get-urls.sh  The URL depends on the setting for path_routing. Refer to following table for URLs:  App Name\tURL (w/ Path Routing)\tURL (w/o Path Routing)Backstage\thttps://[domain]\thttps://backstage.[domain] Argo CD\thttps://[domain]/argocd\thttps://argocd.[domain] Argo Workflows\thttps://[domain]/argo-workflows\thttps://argo-workflows.[domain]  📊 Monitor Deployment Process​  The installation script will continue to run until all the Argo CD apps for addons are healthy. To monitor the process, use the instructions below to access the instance of Argo CD running on EKS.  Check if the kubectl context is set to the EKS cluster and it can access the EKS cluster.  You can use kubectl to check the status of the Argo CD applications  kubectl get applications -n argocd --watch  Get the credentials for Argo CD and start a port-forward with this command:  kubectl get secrets -n argocd argocd-initial-admin-secret -oyaml | yq '.data.password' | base64 -d &amp;&amp; echo kubectl port-forward -n argocd svc/argocd-server 8080:80  Depending upon the configuration, Argo CD will be accessible at http://localhost:8080 or http://localhost:8080/argocd.  All the addons are configured with Keycloak SSO user1 and the user password for it can be retrieved using the following command:  kubectl get secret -n keycloak keycloak-config -o jsonpath='{.data.USER1_PASSWORD}' | base64 -d &amp;&amp; echo  Once all the Argo CD apps on the EKS cluster are reporting healthy status, try out the examples to create a new application through Backstage. For troubleshooting, refer to the troubleshooting guide.  ","version":"Next","tagName":"h3"},{"title":"Cleanup​","type":1,"pageTitle":"AWS Reference Implementation","url":"/docs/reference-implementation/aws#cleanup","content":" warning Before proceeding with the cleanup, ensure any Kubernetes resources created outside of the installation process such as Argo CD Apps, deployments, volumes etc. are deleted.  Run the following command to remove all the addons created by this installation:  scripts/uninstall.sh  This script will only remove resources other than CRDs from the EKS cluster so that the same cluster can be used for re-installation which is useful during development. To remove CRDs, use the following command:  scripts/cleanup-crds.sh ","version":"Next","tagName":"h2"},{"title":"Access Management","type":0,"sectionRef":"#","url":"/docs/reference-implementation/local/access-management","content":"","keywords":"","version":"Next"},{"title":"Keycloak​","type":1,"pageTitle":"Access Management","url":"/docs/reference-implementation/local/access-management#keycloak","content":" In the implementation, Keycloak is used as the identity provider. This instance is used to login into UIs such as Backstage and Argo.  Although it is not configured to be a identity broker or a user federation provider, you can configured it to be one. For example, you can configure it to federate users from Active Directory. Keycloak supports a large number of identity providers to integrate with. Please refer to the documentation for more information.  ","version":"Next","tagName":"h2"},{"title":"Backstage and Kubernetes Authentication​","type":1,"pageTitle":"Access Management","url":"/docs/reference-implementation/local/access-management#backstage-and-kubernetes-authentication","content":" In the reference implementation, it uses the server side authentication pattern. Server side authentication is the pattern that all users on Backstage share the same credential and access level when accessing resources in the cluster. For example, for accessing secret resources, the same service account token is used for a configured Kubernetes cluster regardless of the user requesting resources. This is not ideal for use cases where a Backstage instance is shared by multiple teams. For example, when tying infrastructure and application provisioning to Backstage, it is important to ensure only authorized persons can access certain actions. For example, only admins should be able to delete a Kubernetes cluster in AWS.  Backstage has the ability to enforce policies through the Permission Framework about who can invoke what API actions. Although it is not enabled for the implementation currently, we would like to enable this in the future. Expanding on Backstage's permissions framework, examples provided in the documentation requires writing policies in TypeScript, and they need to be pulled into the Backstage application code. From the Kubernetes centric platform perspective, it makes a lof of sense to leverage policy engines like Kyverno or OPA Gatekeeper if possible.  Client side authentication can be more fine tuned. Client side authentication means actions are performed using the user's credentials. This means even if a cluster is listed and configured for use in Backstage, as long as the logged in user does not have permissions for the cluster, performing actions on the cluster is denied. Currently this is not natively supported by Backstage for EKS clusters. This requires more complex configuration and support from Backstage frontend plugin to properly pass user credentials to the cluster through the Kubernetes proxy in Backstage backend. ","version":"Next","tagName":"h2"},{"title":"Infrastructure Control Plane","type":0,"sectionRef":"#","url":"/docs/reference-implementation/local/control-plane","content":"Infrastructure Control Plane In the reference implementation, Crossplane is used as the control plane for AWS resources and manifests are synced to the cluster using ArgoCD. This pattern is quite powerful because it allows you to combine the power of GitOps and the flexibility of Crossplane compositions. It is not limited to just provisioning external resources through Kubernetes APIs. You can also bake security and governance requirements into compositions. For example, you can create a composition for S3 buckets for use with applications. In the composition, we can enforce certain configuration options such as tagging requirements and encryption key choices. Once a bucket is created through Crossplane, it continuously enforces these configuration options. Even if an end user updates configuration manually through API calls or the console, the changes are reverted back automatically because Kubernetes operators continuously work to sync external resources with the specifications stored in the cluster. Kubernetes CD solutions like ArgoCD is a great companion for this. It allows you to automatically sync resources from a Git repository with many flexible options. With ArgoCD and Crossplane, many application infrastructure needs can be condensed to a YAML file that developers can self-service through a developer portal. This pattern is not limited to Crossplane. There are other Kubernetes Controllers for Infrastructure as code toolings. Take Terraform controller for example. This controller allows you to run Terraform modules in Kubernetes and exposes commonly used Terraform features as fields in the CRD. In the terraform module you can enforce your organizational requirements. Whichever tool you choose to use, use of a policy engine such as Kyverno and OPA Gatekeeper is essential in securing your cluster and external resources. We will include more example of this pattern in the future.","keywords":"","version":"Next"},{"title":"Installation using IDPBuilder","type":0,"sectionRef":"#","url":"/docs/reference-implementation/aws/docs/installation_with_idpbuilder","content":"","keywords":"","version":"Next"},{"title":"Installation Flow Diagram​","type":1,"pageTitle":"Installation using IDPBuilder","url":"/docs/reference-implementation/aws/docs/installation_with_idpbuilder#installation-flow-diagram","content":" This diagram illustrates the high-level installation flow for the CNOE AWS Reference Implementation using idpbuilder. It shows how the idpbuilder and local environment interact with AWS resources to deploy and configure the platform on an EKS cluster.    ","version":"Next","tagName":"h2"},{"title":"Getting Started​","type":1,"pageTitle":"Installation using IDPBuilder","url":"/docs/reference-implementation/aws/docs/installation_with_idpbuilder#getting-started","content":" note The installation requires AWS credentials to access the EKS cluster to deploy kubernetes resources. Therefore, the installation steps can be executed on local machine or on an EC2 instance with IAM instance role. If using local machine, please use aws-vault command to run local EC2 credentials server. Find more information about this requirement in installation flow document.  ","version":"Next","tagName":"h2"},{"title":"Step 1. ☸️ Create EKS Cluster​","type":1,"pageTitle":"Installation using IDPBuilder","url":"/docs/reference-implementation/aws/docs/installation_with_idpbuilder#step-1-️-create-eks-cluster","content":" The reference implementation can be installed on new EKS cluster which can be created with following tools:  eksctl: Follow the instructionsterraform: Follow the instructions  This will create all the pre-requisite AWS Resources required for the reference implementation. Which includes:  EKS cluster with Auto Mode or Without Auto Mode (Managed Node Group with 4 nodes)Pod Identity Associations for following Addons:  Name\tNamespace\tService Account Name\tPermissionsCrossplane\tcrossplane-system\tprovider-aws\tAdmin Permissions but with permission boundary External Secrets\texternal-secrets\texternal-secrets\tPermissions External DNS\texternal-dns\texternal-dns\tPermissions AWS Load Balancer Controller (When not using Auto Mode)\tkube-system\taws-load-balancer-controller\tPermissions AWS EBS CSI Controller (When not using Auto Mode)\tkube-system\tebs-csi-controller-sa\tPermissions  note Using Existing EKS Cluster The reference implementation can be installed on existing EKS Cluster only if above pre-requisites are completed.  ","version":"Next","tagName":"h3"},{"title":"Step 2. 🏢 Create GitHub Organization​","type":1,"pageTitle":"Installation using IDPBuilder","url":"/docs/reference-implementation/aws/docs/installation_with_idpbuilder#step-2--create-github-organization","content":" Backstage and Argo CD in this reference implementation are integrated with GitHub. Therefore, a GitHub Organization should be created in order to create GitHub Apps for these integrations. Follow the instructions in GitHub documentation to create new organization.  ","version":"Next","tagName":"h3"},{"title":"Step 3. 🍴 Fork the Repository​","type":1,"pageTitle":"Installation using IDPBuilder","url":"/docs/reference-implementation/aws/docs/installation_with_idpbuilder#step-3--fork-the-repository","content":" Once the organization is created, fork this repository to the new GitHub Organization by following instructions in GitHub documentation.  ","version":"Next","tagName":"h3"},{"title":"Step 4. 💻 Create GitHub Apps​","type":1,"pageTitle":"Installation using IDPBuilder","url":"/docs/reference-implementation/aws/docs/installation_with_idpbuilder#step-4--create-github-apps","content":" There are two ways to create GitHub App. You can use the Backstage CLI npx @backstage/cli create-github-app &lt;github-org&gt; as per instructions in Backstage documentation, or create it manually per these instructions in GitHub documentation.  Create following apps and store it in corresponding file path.  App Name\tPurpose\tRequired Permissions\tFile Path\tExpected ContentBackstage\tUsed for automatically importing Backstage configuration such as Organization information, templates and creating new repositories for developer applications.\tFor All Repositories - Read access to members, metadata, and organization administration - Read and write access to administration and code\tprivate/backstage-github.yaml Argo CD\tUsed for deploying resources to cluster specified by Argo CD applications.\tFor All Repositories - Read access to checks, code, members, and metadata\tprivate/argocd-github.yaml\t  Argo CD requires url and installationId of the GitHub app. The url is the GitHub URL of the organization. The installationId can be captured by navigating to the app installation page with URL https://github.com/organizations/&lt;Organization-name&gt;/settings/installations/&lt;ID&gt;. You can find more information on this page.  warning If the app is created using backstage CLI, it creates files in current working directory. These files contains credentials. Handle it with care. It is recommended to remove these files after copying the content over to files in private directory  note The rest of the installation process assumes the GitHub apps credentials are available in private/backstage-github.yaml and private/argocd-github.yaml  ","version":"Next","tagName":"h3"},{"title":"Step 5. ⚙️ Prepare Environment for Installation​","type":1,"pageTitle":"Installation using IDPBuilder","url":"/docs/reference-implementation/aws/docs/installation_with_idpbuilder#step-5-️-prepare-environment-for-installation","content":" 📦 Install Binaries​  The installation requires following binaries in the local environment:  AWS CLIDockeryqhelm (Required only if using plain shell script for installation)IDPBuilder (Required only if using ipdbuilder for installation)AWS Vault (Required only for local machine installation)  🔐 Configure AWS Credentials​  If the installation steps are being executed on EC2 instance, just ensure that the EC2 IAM instance role has permissions to access EKS cluster. No other configuration is required in this case.  If the steps are being executed on a laptop/desktop, follow below steps:  Configure the AWS CLI with credentials of an IAM role which has access to the EKS cluster. Follow instructions in AWS documentation to configure AWS CLI. Once AWS CLI is configured, install and start the EC2 credentials server. aws-vault exec &lt;AWS_PROFILE&gt; --ec2-server Verify that the EC2 credentials server is started. curl -s http://169.254.169.254/latest/meta-data/iam/security-credentials/local-credentials  ⚙️ Configure Reference Implementation​  The reference implementation uses config.yaml file in the repository root directory to pass values. Refer to following table and update all the values appropriately. All the values are required.  Parameter\tDescription\tTyperepo.url\tGitHub URL of the fork in Github Org\tstring repo.revision\tBranch or Tag which should be used for Argo CD Apps\tstring repo.basepath\tDirectory in which configuration of addons is stored\tstring cluster_name\tName of the EKS cluster for reference implementation (The name should satisfy criteria of a valid kubernetes resource name)\tstring auto_mode\tSet to &quot;true&quot; if EKS cluster is Auto Mode, otherwise &quot;false&quot;\tstring region\tAWS Region of the EKS cluster and config secret\tstring domain\tBase Domain name for exposing services (This should be base domain or sub domain of the Route53 Hosted Zone)\tstring route53_hosted_zone_id\tRoute53 hosted zone ID for configuring external-dns\tstring path_routing\tEnable path routing (&quot;true&quot;) vs domain-based routing (&quot;false&quot;)\tstring tags\tArbitrary key-value pairs for AWS resource tagging\tobject  🔒 Create Secrets in AWS Secret Manager​  The values required for the installation to work are stored in AWS Secret Manager in two secrets:  cnoe-ref-impl/config: Stores values from config.yaml in JSONcnoe-ref-impl/github-app: Stores GitHub App credentials with file name as key and content of the file as value from private directory.  Run below command to create new secrets or update the existing secrets if already exists.  ./scripts/create-config-secrets.sh  warning DO NOT move to next steps without completing all the instructions in this step  ","version":"Next","tagName":"h3"},{"title":"Step 6. 🚀 Installation​","type":1,"pageTitle":"Installation using IDPBuilder","url":"/docs/reference-implementation/aws/docs/installation_with_idpbuilder#step-6--installation","content":" ▶️ Start the Installation Process​  The installation can be done using plain shell script or idpbuilder. All the addons are installed as Argo CD apps. When using bash script, Argo CD and External Secret Operator are installed on EKS cluster as helm chart. When installing with idpbuilder, the Argo CD in idpbuilder is used install these initial addons. Once Argo CD on EKS is up, other addons are installed through it and finally the Argo CD on EKS also manages itself. Check out more details about the installation flow.  Install using script: ./scripts/install.sh Install using idpbuilder: ./scripts/install-using-idpbuilder.sh  📊 Monitor Installation Process​  The installation script will continue to run until all the addon Argo CD apps are healthy. To monitor the process, use below instructions to access Argo CD instances. (If using EC2 instance, make sure the port-forward from EC2 to local machine is set up)  idpbuilder Argo CD: idpbuilder exposes its Argo CD instance at https://cnoe.localtest.me:8443/argocd which can be accessed through browser. EKS Argo CD: Start the kubernetes port-forward session for Argo CD service and access the Argo CD UI in browser. In Argo CD UI, monitor the health of all Argo CD Apps kubectl port-forward -n argocd svc/argocd-server 8080:80  Depending upon the configuration, Argo CD will be accessible at http://localhost:8080 or http://localhost:8080/argocd.  Switch between the kubernetes context of idpbuilder or EKS and retrieve the credentials for Argo CD can be retrieved with following command:  kubectl get secrets -n argocd argocd-initial-admin-secret -oyaml | yq '.data.password' | base64 -d # OR idpbuilder get secrets -p argocd -o yaml  ","version":"Next","tagName":"h3"},{"title":"Step 7. 🌐 Accessing the Platform​","type":1,"pageTitle":"Installation using IDPBuilder","url":"/docs/reference-implementation/aws/docs/installation_with_idpbuilder#step-7--accessing-the-platform","content":" The addons are exposed using the base domain configured in Step 5. The URL depends on the setting for path_routing. Refer to following table for URLs:  App Name\tURL (w/ Path Routing)\tURL (w/o Path Routing)Backstage\thttps://[domain]\thttps://backstage.[domain] Argo CD\thttps://[domain]/argocd\thttps://argocd.[domain] Argo Workflows\thttps://[domain]/argo-workflows\thttps://argo-workflows.[domain]  All the addons are configured with Keycloak SSO USER1 and the user password for it can be retrieved using following command:  kubectl get secrets -n keycloak keycloak-config -o go-template='{{range $k,$v := .data}}{{printf &quot;%s: &quot; $k}}{{if not $v}}{{$v}}{{else}}{{$v | base64decode}}{{end}}{{&quot;\\n&quot;}}{{end}}'  Once, all the Argo CD apps on EKS cluster are reporting healthy status, try out examples to create new application through Backstage. For troubleshooting, refer to the troubleshooting guide.  ","version":"Next","tagName":"h3"},{"title":"Cleanup​","type":1,"pageTitle":"Installation using IDPBuilder","url":"/docs/reference-implementation/aws/docs/installation_with_idpbuilder#cleanup","content":" warning Before proceeding with the cleanup, ensure any Kubernetes resource created outside of the installation process such as Argo CD Apps, deployments, volume etc. are deleted.  Run following command to remove all the addons created by this installation:  ./scripts/uninstall.sh   This script will only remove resources other than CRDs from the EKS cluster so that the same cluster can used for re-installation which is useful during development. To remove CRDs, use following command:  ./scripts/cleanup-crds.sh   Installation Flow  This document describes the installation flow for the CNOE AWS Reference Implementation.  ","version":"Next","tagName":"h2"},{"title":"Overview​","type":1,"pageTitle":"Installation using IDPBuilder","url":"/docs/reference-implementation/aws/docs/installation_with_idpbuilder#overview","content":" The CNOE AWS Reference Implementation uses a GitOps approach to deploy and manage addons on an EKS cluster. The installation process uses helm to bootstrap the EKS cluster with Argo CD and other addons. Detailed installation sequence is described below.  ","version":"Next","tagName":"h2"},{"title":"Installation Sequence​","type":1,"pageTitle":"Installation using IDPBuilder","url":"/docs/reference-implementation/aws/docs/installation_with_idpbuilder#installation-sequence","content":" Configuration Setup: The config.yaml file is used to configure the installationAWS Secrets Manager secrets are created to store configuration and GitHub App credentials using create-config-secrets.sh script Local Environment Preparation: Using plain shell script: install.sh script reads the config.yaml and based on the specified cluster name, performs helm installation on EKS cluster. Using idpbuilder: install-using-idpbuilder.sh script reads the config.yaml and based on the specified cluster name, builds a Argo CD cluster secret from eks kubeconfig.idpbuilder creates a local Kind cluster with Argo CD, Gitea and Argo CD cluster secret for EKS cluster.This local environment serves as a bootstrap mechanism for the remote EKS cluster using Argo CD in Kind cluster. EKS Cluster Bootstrap: Using plain shell script: The script performs helm installation of Argo CD and External Secret Operator on the EKS cluster. It will use the temporary kubeconfig for accessing EKS cluster. Using idpbuilder: idpbuilder applies Argo CD applications from the root of packages directory to the local Kind cluster, mainly boostrap.yaml and addons-appset.yaml.Argo CD in the Kind cluster installs Argo CD and External Secret Operator on the EKS cluster. It will use AWS credentials to authenticate with EKS cluster. Addons Deployment: The addons-appset.yaml creates an ApplicationSet in the EKS cluster's Argo CDThis ApplicationSet creates individual Argo CD applicationSet for each addon using cluster generator.Addons are installed in a specific order to handle dependencies Addon Configuration: Addons are configured using helm valuesStatic values are stored packages/&lt;addon-name&gt;/values.yamlDynamic values from Argo CD cluster secret labels/annotations which depend on configuration from AWS Secrets Manager. Monitoring and Verification: The installation script waits for all Argo CD applications to become healthyAddons can be accessed through the configured domain based on path routing settings  ","version":"Next","tagName":"h2"},{"title":"Uninstallation Process​","type":1,"pageTitle":"Installation using IDPBuilder","url":"/docs/reference-implementation/aws/docs/installation_with_idpbuilder#uninstallation-process","content":" The uninstallation process follows these steps:  Remove idpbuilder Local Cluster: The local Kind cluster created by idpbuilder is deleted Remove Addons: Addons are removed in a specific order to handle dependenciesApplicationSets are deleted with orphan deletion policyPVCs for stateful applications are cleaned up CRD Cleanup (Optional): Custom Resource Definitions can be cleaned up using the cleanup-crds.sh scriptThis is optional and useful when you want to completely remove all traces of the installation  ","version":"Next","tagName":"h2"},{"title":"Key Components​","type":1,"pageTitle":"Installation using IDPBuilder","url":"/docs/reference-implementation/aws/docs/installation_with_idpbuilder#key-components","content":" helm (if using install.sh): Bootstraps EKS cluster through helm chart installation.idpbuilder (if using install-using-idpbuilder.sh): Creates a local Kind cluster with Argo CD and Gitea, which bootstraps the EKS clusterArgo CD: Manages the deployment of addons on the EKS cluster using GitOpsExternal Secret Operator: Manages secrets from AWS Secrets ManagerAddons: Various tools and services that make up the Internal Developer Platform  ","version":"Next","tagName":"h2"},{"title":"AWS Resources​","type":1,"pageTitle":"Installation using IDPBuilder","url":"/docs/reference-implementation/aws/docs/installation_with_idpbuilder#aws-resources","content":" The installation relies on these AWS resources:  EKS Cluster: The Kubernetes cluster where the platform is deployedAWS Secrets Manager: Stores configuration and GitHub App credentialsIAM Roles: For pod identity associations required by various addonsRoute53: For DNS management via External DNS ","version":"Next","tagName":"h2"},{"title":"Create GO App with S3 Bucket","type":0,"sectionRef":"#","url":"/docs/tutorials/aws/app-with-aws-resources","content":"Create GO App with S3 Bucket","keywords":"","version":"Next"},{"title":"Secret Management","type":0,"sectionRef":"#","url":"/docs/reference-implementation/local/secrets","content":"","keywords":"","version":"Next"},{"title":"External Secrets Operator​","type":1,"pageTitle":"Secret Management","url":"/docs/reference-implementation/local/secrets#external-secrets-operator","content":" If your organization requires sensitive data to be stored in a secret store such as Vault and Secrets Manager, you may need a way to retrieve secrets from your secret store into your cluster. External Secrets Operator is a Kubernetes Operator that fetches secrets from external APIs and creates Kubernetes secrets.  The reference implementation uses this operator to sync secrets between the cluster and AWS Secrets Manager. Information such as generated user password, Keycloak admin password, and database password are stored as an entity in AWS secrets manager.  ","version":"Next","tagName":"h2"},{"title":"TLS Certificates​","type":1,"pageTitle":"Secret Management","url":"/docs/reference-implementation/local/secrets#tls-certificates","content":" If you opted to use cert manager to manage certificates for you endpoints, certificates and their private keys are stored as Kubernetes secrets. If this does not meet your security standard, you can store it in a secret store of your choice, then use External Secrets Operator to sync it. An example manifest for Secrets Manager would look something like this.  apiVersion: external-secrets.io/v1beta1 kind: ExternalSecret metadata: name: backstage-prod-tls namespace: backstage spec: refreshInterval: 12h secretStoreRef: name: keycloak kind: SecretStore target: name: backstage-prod-tls template: type: kubernetes.io/tls data: tls.crt: &quot;{{ .public }}&quot; tls.key: &quot;{{ .private }}&quot; data: - secretKey: private remoteRef: key: cnoe/tls/dev # path to the tls cert in Secrets Manager property: PRIVATE_KEY - secretKey: public remoteRef: key: cnoe/tls/dev property: CERT   When removing the reference implementation installation from your cluster, the uninstall script will back up the secrets to a local directory. This is to avoid re-issuing Let's Encrypt certificate for the same host because Let's Encrypt has a limit on how many times you can request certificates in a given time. ","version":"Next","tagName":"h2"},{"title":"Explore Backstage Plugins in CNOE","type":0,"sectionRef":"#","url":"/docs/tutorials/plugin","content":"","keywords":"","version":"Next"},{"title":"Available CNOE Backstage Plugins​","type":1,"pageTitle":"Explore Backstage Plugins in CNOE","url":"/docs/tutorials/plugin#available-cnoe-backstage-plugins","content":" CNOE Backstage Plugin\tMaintainer\tRepository Location\tDescriptionTerraform Backstage Plugin\tCNOE\tcnoe-io/plugin-terraform\tThis plugin can show Terraform outputs/resources from TFState files associated with a particular Backstage components. Argo Workflows Backstage Plugin\tCNOE\tcnoe-io/plugin-argo-workflows\tThis plugin displays your Argo Workflows in Backstage Scaffolder Actions Plugin\tCNOE\tcnoe-io/plugin-scaffolder-actions\tCollection of extended actions for the Backstage Scaffolder plugin, designed to enhance the developer experience and enable more customized scaffolding workflows within the Backstage ecosystem Scaffolder Frontend Plugin\tCNOE\tcnoe-io/plugin-scaffolder-actions-frontend\tAllows you to display and select Kubernetes clusters configured in your Backstage configuration. Apache Spark Backstage Plugin\tCNOE\tcnoe-io/plugin-apache-spark\tThis plugin allows you to display information related to your Apache Spark Applications running in Kubernetes on Backstage. ","version":"Next","tagName":"h2"},{"title":"Set up IDP on Local Machine","type":0,"sectionRef":"#","url":"/docs/reference-implementation/local/idpbuilder","content":"","keywords":"","version":"Next"},{"title":"About​","type":1,"pageTitle":"Set up IDP on Local Machine","url":"/docs/reference-implementation/local/idpbuilder#about","content":" GitHub Repo cnoe-io/idpbuilder  ","version":"Next","tagName":"h2"},{"title":"Introduction​","type":1,"pageTitle":"Set up IDP on Local Machine","url":"/docs/reference-implementation/local/idpbuilder#introduction","content":" idpBuilder is a powerful tool that enables you to easily spin up a complete internal developer platform (IDP) on your local machine.  Go to idpbuilder Overview page to get more details on the concepts.  ","version":"Next","tagName":"h2"},{"title":"Running ipdbuilder in local machine​","type":1,"pageTitle":"Set up IDP on Local Machine","url":"/docs/reference-implementation/local/idpbuilder#running-ipdbuilder-in-local-machine","content":" A container engine is needed locally.  Docker desktop is supported.Podman desktop is not supported however idpbuilder can create a cluster using rootful. You need tp set the DOCKER_HOST env var property using podman to let idpbuilder to talk with the engine (e.g export DOCKER_HOST=&quot;unix:///var/run/docker.sock&quot;)  Option 1: Using Bash Script  You can execute the following bash script to get started with a running version of the idpBuilder (inspect the script first if you have concerns):  $curl -fsSL https://raw.githubusercontent.com/cnoe-io/idpbuilder/main/hack/install.sh | bash  verify a successful installation by running the following command and inspecting the output for the right version:  $idpbuilder version  Option 2: Manual installation  You can run the following commands for a manual installation:  $version=$(curl -Ls -o /dev/null -w %{url_effective} https://github.com/cnoe-io/idpbuilder/releases/latest) $version=${version##*/} $curl -L -o ./idpbuilder.tar.gz &quot;https://github.com/cnoe-io/idpbuilder/releases/download/${version}/idpbuilder-$(uname | awk '{print tolower($0)}')-$(uname -m | sed 's/x86_64/amd64/').tar.gz&quot; $tar xzf idpbuilder.tar.gz $./idpbuilder version # example output # idpbuilder 0.4.1 go1.21.5 linux/amd64  Option 3: Release page binary  The easiest way to get started is to grab the idpbuilder binary for your platform and run it. You can visit our nightly releases page to download the version for your system, or run the following commands:  $arch=$(if [[ &quot;$(uname -m)&quot; == &quot;x86_64&quot; ]]; then echo &quot;amd64&quot;; else uname -m; fi) $os=$(uname -s | tr '[:upper:]' '[:lower:]') $idpbuilder_latest_tag=$(curl --silent &quot;https://api.github.com/repos/cnoe-io/idpbuilder/releases/latest&quot; | grep '&quot;tag_name&quot;:' | sed -E 's/.*&quot;([^&quot;]+)&quot;.*/\\1/') $curl -LO https://github.com/cnoe-io/idpbuilder/releases/download/$idpbuilder_latest_tag/idpbuilder-$os-$arch.tar.gz $tar xvzf idpbuilder-$os-$arch.tar.gz  ","version":"Next","tagName":"h2"},{"title":"Running ipdbuilder in Codespaces​","type":1,"pageTitle":"Set up IDP on Local Machine","url":"/docs/reference-implementation/local/idpbuilder#running-ipdbuilder-in-codespaces","content":" You can run idpbuilder in Codespaces.  Create a Codespaces instance.   Wait for it to be ready. It may take several minutes. Get the latest release of idpbuilder: $version=$(curl -Ls -o /dev/null -w %{url_effective} https://github.com/cnoe-io/idpbuilder/releases/latest) $version=${version##*/} $curl -L -o ./idpbuilder.tar.gz &quot;https://github.com/cnoe-io/idpbuilder/releases/download/${version}/idpbuilder-$(uname | awk '{print tolower($0)}')-$(uname -m | sed 's/x86_64/amd64/').tar.gz&quot; $tar xzf idpbuilder.tar.gz Run idpbuilder: $idpbuilder create --protocol http \\ --host ${CODESPACE_NAME}-8080.${GITHUB_CODESPACES_PORT_FORWARDING_DOMAIN} \\ --port 8080 --use-path-routing Because Codespaces gives a single externally routable host name for an instance, idpbuilder must deploy with path based routing. This means ArgoCD and Gitea UIs are given with the following commands. ArgoCD: echo https://${CODESPACE_NAME}-8080.${GITHUB_CODESPACES_PORT_FORWARDING_DOMAIN}/argocdGitea: echo https://${CODESPACE_NAME}-8080.${GITHUB_CODESPACES_PORT_FORWARDING_DOMAIN}/gitea Note that not all examples work with path based routing.  Codespaces tips and tricks Codespaces tips and tricks​ By default all port forwarding in a Codespace environment is private which means that you will not be able to access the OCI registry directly from your local machine's CLI. You can however use the github CLI to port-forward a port on your local machine to the codespace which is running the OCI registry and listening on port 8443. To do this, make sure you have the latest github cli installed. Instructions here: [https://github.com/cli/cli#installation] (https://github.com/cli/cli#installation) Next you will need to login to github and give your CLI access to the codespace: $gh auth login -h github.com -s codespace Follow the prompts to perform the auth via your local machine's browser and make sure to choose the codespace you are running idpbuilder in. $gh auth login -h github.com -s codespace ! First copy your one-time code: 0076-1071 Press Enter to open https://github.com/login/device in your browser... Opening in existing browser session. ✓ Authentication complete. List the ports on your codespace: $gh codespace ports ? Choose codespace: cnoe-io/idpbuilder [main*]: expert chainsaw LABEL PORT VISIBILITY BROWSE URL 8443 private https://expert-chainsaw-7vjwj6qqgcprjp-8443.app.github.dev 37065 private https://expert-chainsaw-7vjwj6qqgcprjp-37065.app.github.dev Then perform the port-forward. Make sure to use the same port that the codespace has listed in it's port column. Likely this is 8443 which is the default at the time of this writing. $gh codespace ports forward 8443:8443 -c expert-chainsaw-7vjwj6qqgcprjp If you see a message like the following then you may already have another service on your local machine that is listening on 8443. Make sure to shut it down. (Maybe you were running idpbuilder locally as well?) failed to listen to local port over tcp: listen tcp :8443: bind: address already in use Once you have setup the port-forward you will see the following: $gh codespace ports forward 8443:8443 -c expert-chainsaw-7vjwj6qqgcprjp Forwarding ports: remote 8443 &lt;=&gt; local 8443 You can now connect directly to the registry hosted on idpbuilder in your codespace environment. $docker login cnoe.localtest.me:8443/gitea Authenticating with existing credentials... Stored credentials invalid or expired Username (giteaAdmin): giteaadmin Password: WARNING! Your password will be stored unencrypted in /home/sanforj/.docker/config.json. Configure a credential helper to remove this warning. See https://docs.docker.com/engine/reference/commandline/login/#credential-stores Login Succeeded IMPORTANT! As you may have noticed, you must use cnoe.localtest.me:8443 (or whatever port number was listed) as the registry name. This will allow for compatibility with the oci clients that are working in the codespace as well as those that are running on the idpbuilder kubernetes cluster. As long as you tag your images and push them to cnoe.localtest.me:8443/gitea/giteaadmin/imagename:tag they will be able to be referenced on your local machine, on the cli within the codespace and on the idbpuilder k8s cluster at that same registry/repo/imagename:tag location. Example mirroring Alpine image​ So to be clear. On your local machine you have to tag your images appropriately like so: $docker tag alpine:latest cnoe.localtest.me:8443/gitea/giteaadmin/alpine:latest Then you can push once your port-forwarding is working: $docker push cnoe.localtest.me:8443/gitea/giteaadmin/alpine:latest The push refers to repository [cnoe.localtest.me:8443/gitea/giteaadmin/alpine] 3e01818d79cd: Layer already exists latest: digest: sha256:fa7042902b0e812e73bbee26a6918a6138ccf6d7ecf1746e1488c0bd76cf1f34 size: 527 Then on the cli inside your codespace you can pull it: $docker pull cnoe.localtest.me:8443/gitea/giteaadmin/alpine:latest latest: Pulling from gitea/giteaadmin/alpine Digest: sha256:fa7042902b0e812e73bbee26a6918a6138ccf6d7ecf1746e1488c0bd76cf1f34 Status: Image is up to date for cnoe.localtest.me:8443/gitea/giteaadmin/alpine:latest cnoe.localtest.me:8443/gitea/giteaadmin/alpine:latest And when you run an image in your idpbuilder k8s cluster just make sure to reference it at the same location: apiVersion: v1 kind: Pod metadata: name: alpine-from-local-registry spec: containers: - name: alpine-from-local-registry image: cnoe.localtest.me:8443/gitea/giteaadmin/alpine:latest restartPolicy: Never  ","version":"Next","tagName":"h2"},{"title":"Use IDPBuilder Stacks","type":0,"sectionRef":"#","url":"/docs/tutorials/idpbuilder/idpbuilder-stack","content":"","keywords":"","version":"Next"},{"title":"Prerequisites​","type":1,"pageTitle":"Use IDPBuilder Stacks","url":"/docs/tutorials/idpbuilder/idpbuilder-stack#prerequisites","content":" Ensure you have completed the following setup  Complete the idp Reference Prerequisite setupComplete the idp Reference Installation setup  ","version":"Next","tagName":"h2"},{"title":"Specifiy stack​","type":1,"pageTitle":"Use IDPBuilder Stacks","url":"/docs/tutorials/idpbuilder/idpbuilder-stack#specifiy-stack","content":" Idpbuilder supports adding stack by specifying custom packages using the flag -p flag. This flag expects a directory (local or remote) containing ArgoCD application files and / or ArgoCD application set files. In case of a remote directory, it must be a directory in a git repository, and the URL format must be a kustomize remote URL format.  ","version":"Next","tagName":"h2"},{"title":"CNOE IDP stacks available​","type":1,"pageTitle":"Use IDPBuilder Stacks","url":"/docs/tutorials/idpbuilder/idpbuilder-stack#cnoe-idp-stacks-available","content":" CNOE idp Stack\tMaintainer\tRepository Location\tDescriptionLocalstack\tCNOE\tstacks/localstack-integration/\tDeploys an IDP reference implementation with an Argo application that adds Localstack, as well as integrating with Crossplane. Local Backup\tCNOE\tstacks/local-backup/\tcreates a configuration that allows you to back up Kubernetes objects to your local machine (or wherever you are running idpbuilder from) Terraform Integrations\tCNOE\tstacks/terraform-integrations/\tThe deployment automation capabilities of this stack include automated syncing of Terraform configuration from a Git repository using the FluxCD source repository controller, and a custom &quot;tofu-controller&quot; that manages the full lifecycle of Terraform deployments directly from the Kubernetes cluster. Dapr Integrations\tCNOE\tstacks/dapr-integration/\tprovides a Dapr integration for the idpBuilder tool, allowing users to easily deploy a Dapr control plane, state store, and pub/sub components along with a Redis instance to support them. Crossplane Integrations\tCNOE\tstacks/crossplane-integrations/\tprovides a way to deploy applications with cloud resources using Backstage templates, where the cloud resources are managed and provisioned by Crossplane, a Kubernetes-native control plane for cloud services. Istio-Ambient Stack\tCommunity\tstacks/istio-ambient/\tinstalls the Istio Ambient mesh and supporting observability tools to monitor traffic, metrics, and traces. Jupyterhub Stack\tCommunity\tstacks/jupyterhub/\tdeploys a JupyterHub instance that is integrated with Keycloak for single sign-on (SSO) authentication. Kyverno Stack\tCommunity\tstacks/kyverno-integration/\timplements Kyverno, a Kubernetes native policy management engine, to provide policy enforcement and audit capabilities for a Kubernetes platform. vcluster multi-env\tCommunity\tstacks/vcluster-multi-env/\tcreates a multi-environment emulation setup on top of CNOE, allowing you to easily manage and enroll multiple vClusters (e.g. staging and production) in your ArgoCD deployment.  ","version":"Next","tagName":"h3"},{"title":"Create a basic CNOE idp stack​","type":1,"pageTitle":"Use IDPBuilder Stacks","url":"/docs/tutorials/idpbuilder/idpbuilder-stack#create-a-basic-cnoe-idp-stack","content":" Let's take a look at this example. This defines two custom package directories to deploy to the cluster.  To deploy these packages, run the following command:  $./idpbuilder create \\ -p https://github.com/cnoe-io/stacks//basic/package1 \\ -p https://github.com/cnoe-io/stacks//basic/package2  Alternatively, you can use the local directory format.  # clone the stacks repository $git clone https://github.com/cnoe-io/stacks.git $cd stacks # run idpbuilder against the local directory $./idpbuilder create \\ -p examples/basic/package1\\ -p examples/basic/package2  Running this command should create three additional ArgoCD applications in your cluster.  $kubectl get Applications -n argocd -l example=basic NAME SYNC STATUS HEALTH STATUS guestbook Synced Healthy guestbook2 Synced Healthy my-app Synced Healthy  Let's break this down. The first package directory defines an application. This corresponds to the my-app application above. In this application, we want to deploy manifests from local machine in GitOps way.  The directory contains an ArgoCD application file. This is a normal ArgoCD application file except for one field.  apiVersion: argoproj.io/v1alpha1 kind: Application spec: source: repoURL: cnoe://manifests   The cnoe:// prefix in the repoURL field indicates that we want to sync from a local directory. Values after cnoe:// is treated as a relative path from this file. In this example, we are instructing idpbuilder to make ArgoCD sync from files in the manifests directory.  As a result the following actions were taken by idpbuilder:  Create a Gitea repository.Fill the repository with contents from the manifests directory.Update the Application spec to use the newly created repository.  You can verify this by going to this address in your browser: https://gitea.cnoe.localtest.me:8443/giteaAdmin/idpbuilder-localdev-my-app-manifests    This is the repository that corresponds to the manifests folder. It contains a file called alpine.yaml, synced from the manifests directory above.  You can also view the updated Application spec by going to this address: https://argocd.cnoe.localtest.me:8443/applications/argocd/my-app    The second package directory defines two normal ArgoCD applications referencing a remote repository. They are applied as-is. ","version":"Next","tagName":"h3"},{"title":"Generate CNOE Backstage template","type":0,"sectionRef":"#","url":"/docs/tutorials/backstage-template","content":"","keywords":"","version":"Next"},{"title":"Install CNOE CLI​","type":1,"pageTitle":"Generate CNOE Backstage template","url":"/docs/tutorials/backstage-template#install-cnoe-cli","content":" The CNOE CLI is a powerful tool designed to enhance Internal Developer Platform (IDP) experiences by streamlining developer workflows through Kubernetes integration. It offers advanced templating capabilities that can automatically convert Kubernetes CRDs and Crossplane XRDs into Backstage templates, making it particularly valuable for organizations with custom Kubernetes controllers. The tool excels at transforming complex resources into user-friendly templates and supports bulk conversion with customizable parameters. By bridging the gap between developer workflows and underlying infrastructure, CNOE CLI helps organizations build cohesion in their development processes and simplify the migration of workflows to their developer portal, while adding necessary verifications and extensions.  Follow cnoe-io/cnoe-cli documentation to install.  ","version":"Next","tagName":"h2"},{"title":"Generate CNOE Backstage Template​","type":1,"pageTitle":"Generate CNOE Backstage template","url":"/docs/tutorials/backstage-template#generate-cnoe-backstage-template","content":" You pick the option you want to use to generate the templates. Here we are demonstrating with two examples one using CRD and other with Terraform.  ","version":"Next","tagName":"h2"},{"title":"Using CRD/XRDs​","type":1,"pageTitle":"Generate CNOE Backstage template","url":"/docs/tutorials/backstage-template#using-crdxrds","content":" As shown below, the ./cnoe template crd command allows you to specify an input directory for stored CRD specifications, the template that needs to be populated with the list of converted CRDs, and configuration knobs to set the name, title, and description of the generated template.  The generated templates are stored in the defined output directory.  Generate backstage templates from supplied CRD and XRD definitions Usage: cnoe template crd [flags] Flags: -h, --help help for crd --templateDescription string sets the description of the template --templateName string sets the name of the template --templateTitle string sets the title of the template -v, --verifier stringArray list of verifiers to test the resource against Global Flags: -c, --collapse if set to true, items are rendered and collapsed as drop down items in a single specified template --depth uint32 depth from given directory to search for TF modules or CRDs (default 2) -i, --inputDir string input directory for CRDs and XRDs to be templatized -p, --insertAt string jq path within the template to insert backstage info (default &quot;.spec.parameters[0]&quot;) -o, --outputDir string output directory for backstage templates to be stored in --raw templatePath prints the raw open API output without putting it into a template (ignoring templatePath and `insertAt`) -t, --templatePath string path to the template to be augmented with backstage info   In this example we will show how to generate Backstage template for ACK Controllers. You require the list of CRDs that you want to convert, and a Backstage template. For this example, let us look at the CRDs available in the CNOE CLI repository in particular, the CRDs for Amazon Controllers for Kubernetes (ACK). There is approximately 120 sample ACK CRDs in the example repo.  Step-1​  First create the Backstage Scaffolding Template. You can choose a scaffolding template of your choice to pass to the tool for it to augment it with the list of converted CRD elements. For this example we choose the k8s-apply-template available in the CNOE CLI repository.  apiVersion: scaffolder.backstage.io/v1beta3 kind: Template metadata: name: deploy-resources title: Deploy Resources description: Deploy Resource to Kubernetes spec: owner: guest type: service # these are the steps which are rendered in the frontend with the form input parameters: - title: Choose AWS Resources description: Select a AWS resource to add to your repository. properties: path: type: string description: path to place this file into default: kustomize/base name: type: string description: name of this resource. This will be the name of K8s object. required: - awsResources - name steps: - id: serialize name: serialize action: roadiehq:utils:serialize:yaml input: data: apiVersion: ${{ parameters.apiVersion }} kind: ${{ parameters.kind }} metadata: name: ${{ parameters.name }} namespace: ${{ parameters.namespace }} spec: ${{ parameters.config }} - id: sanitize name: sanitize action: cnoe:utils:sanitize input: document: ${{ steps['serialize'].output.serialized }} - id: apply name: apply-manifest action: cnoe:kubernetes:apply input: namespaced: true manifest: ${{ steps['sanitize'].output.sanitized }}   metadata and spec.parameters elements are placeholders that will be overwritten by the tool when doing the conversion. However, the steps remain as the primary set of actions later on to be taken by Backstage to deploy the generated templates.  The set of steps for the scaffolder are pretty self explanatory but stating the obvious, the first two steps serialize and sanitize the yaml document corresponding to the converted CRD, and the last step deploys the CRD to a target Kubernetes cluster.  Step-2​  Run the command below to generate the template for ACK crds  $cd ~/cnoe-cli $./cnoe template crd \\ --inputDir examples/ack-crds \\ --outputDir /tmp/templates-ack-deploy \\ --templatePath config/templates/k8s-apply-template.yaml \\ --templateName deploy-ack-resource \\ --templateTitle &quot;Deploy ACK Resource&quot; \\ --templateDescription &quot;Deploy ACK Resource to Kubernetes&quot; \\ -c  The output in the /tmp/templates-ack-deploy should look like below:  drwxr-xr-x 119 user wheel 3.7K Aug 7 23:26 resources drwxr-xr-x 4 user wheel 128B Aug 7 23:26 . -rw-r--r-- 1 user wheel 15K Aug 8 19:25 template.yaml drwxrwxrwt 68 root wheel 2.1K Aug 8 19:34 ..  With the template augmented to have all the resources:  redepiVersion: scaffolder.backstage.io/v1beta3 kind: Template metadata: name: deploy-ack-resource title: Deploy ACK Resource description: Deploy Resource to Kubernetes spec: owner: guest type: service parameters: - properties: name: description: name of this resource. This will be the name of K8s object. type: string path: default: kustomize/base description: path to place this file into type: string resources: type: string enum: - acm.services.k8s.aws.Certificate - apigatewayv2.services.k8s.aws.API - apigatewayv2.services.k8s.aws.Authorizer - apigatewayv2.services.k8s.aws.Deployment - apigatewayv2.services.k8s.aws.Integration - apigatewayv2.services.k8s.aws.Route - apigatewayv2.services.k8s.aws.Stage - apigatewayv2.services.k8s.aws.VPCLink - applicationautoscaling.services.k8s.aws.ScalableTarget - applicationautoscaling.services.k8s.aws.ScalingPolicy - cloudfront.services.k8s.aws.CachePolicy - cloudtrail.services.k8s.aws.EventDataStore - cloudtrail.services.k8s.aws.Trail ... dependencies: resources: oneOf: - $yaml: resources/acm.services.k8s.aws.certificate.yaml - $yaml: resources/apigatewayv2.services.k8s.aws.api.yaml - $yaml: resources/apigatewayv2.services.k8s.aws.authorizer.yaml - $yaml: resources/apigatewayv2.services.k8s.aws.deployment.yaml - $yaml: resources/apigatewayv2.services.k8s.aws.integration.yaml - $yaml: resources/apigatewayv2.services.k8s.aws.route.yaml - $yaml: resources/apigatewayv2.services.k8s.aws.stage.yaml - $yaml: resources/apigatewayv2.services.k8s.aws.vpclink.yaml - $yaml: resources/applicationautoscaling.services.k8s.aws.scalabletarget.yaml - $yaml: resources/applicationautoscaling.services.k8s.aws.scalingpolicy.yaml - $yaml: resources/cloudfront.services.k8s.aws.cachepolicy.yaml - $yaml: resources/cloudtrail.services.k8s.aws.eventdatastore.yaml - $yaml: resources/cloudtrail.services.k8s.aws.trail.yaml ... steps: - id: serialize name: serialize action: roadiehq:utils:serialize:yaml input: data: apiVersion: ${{ parameters.apiVersion }} kind: ${{ parameters.kind }} metadata: name: ${{ parameters.name }} namespace: ${{ parameters.namespace }} spec: ${{ parameters.config }} - id: sanitize name: sanitize action: cnoe:utils:sanitize input: document: ${{ steps['serialize'].output.serialized }} - id: apply name: apply-manifest action: cnoe:kubernetes:apply input: manifest: ${{ steps['sanitize'].output.sanitized }} namespaced: true   Step-3​  In this step we will import the generated template to Backstage. The generated template is registered with Backstage by pushing it to a repository and analyzing the generated content. With a valid template, the analysis would be successfully validated and you can import the template into Backstage.    It would show up in the list of available templates (in this case the service template to &quot;Deploy ACK Resources&quot;):    Choosing the template would load all the resources dynamically generated for the template. In case of Amazon Controller for Kubernetes (ACK), it will be the list of over 180 resources that we created from the available CRDs.    Once the desired resource is selected, the Backstage UI will be populated with the list of all properties that can be configured for this CRD, with the Backstage template validating the presence of required properties before you can proceed:    Once the properties are defined, the resource is hydrated for deployment to Kubernetes:    Where deploying the resource will result in running the Backstage scaffolder and getting the resource deployed to a target cluster as configured in your template:    ","version":"Next","tagName":"h3"},{"title":"Using Terraform​","type":1,"pageTitle":"Generate CNOE Backstage template","url":"/docs/tutorials/backstage-template#using-terraform","content":" The CNOE CLI supports integration of Terraform modules into the developer portal.  Template Generation​  To generate Backstage template input fields from Terraform modules, you can use the tf subcommand. Usage is shown below.  Generate backstage templates by walking the given input directory, find TF modules,then create output file per module. If the templatePath and insertionPoint flags are set, generated objects are merged into the given template at given insertion point. Otherwise a yaml file with two keys are generated. The properties key contains the generated form input. The required key contains the TF variable names that do not have defaults. Usage: cnoe template tf [flags] Flags: -h, --help help for tf Global Flags: -c, --colllapse if set to true, items are rendered and collapsed as drop down items in a single specified template --depth uint32 depth from given directory to search for TF modules or CRDs (default 2) -i, --inputDir string input directory for CRDs and XRDs to be templatized -p, --insertAt string jq path within the template to insert backstage info (default &quot;.spec.parameters[0]&quot;) -o, --outputDir string output directory for backstage templates to be stored in --raww templatePath prints the raw open API output without putting it into a template (ignoring templatePath and `insertAt`) -t, --templatePath string path to the template to be augmented with backstage info  Example​  We can run the command against one of modules within the Data on EKS repository.  $git clone https://github.com/awslabs/data-on-eks.git /tmp/data-on-eks $git clone https://github.com/cnoe-io/reference-implementation-aws.git /tmp/ref-impl $cnoe template tf \\ -i /tmp/data-on-eks/analytics/terraform/spark-k8s-operator \\ -t /tmp/ref-impl/examples/template-generation/data-on-eks.yaml \\ -p '.spec.parameters[0].properties.tfVars' \\ -o .  The -i flag specifies input Terraform module directory. In this example, the content looks like this:  $ls /tmp/data-on-eks/analytics/terraform/spark-k8s-operator README.md data.tf karpenter-provisioners spark-team.tf addons.tf examples main.tf variables.tf amp.tf helm-values outputs.tf versions.tf cleanup.sh install.sh providers.tf vpc.tf  The -t flag specifies the location of the partially configured template file. It may look something like this:  apiVersion: scaffolder.backstage.io/v1beta3 kind: Template spec: parameters: - title: Terraform config options properties: tfVars: # this field is to be generated. title: Terraform variables type: object - title: Configuration Options properties: name: title: name of this entry type: string namespace: title: namespace within the kubernetes cluster to deploy this type: string default: data-on-eks adminRoleName: title: Admin Role Name description: Name of the role to give the administrative rights on the EKS cluster. default: Admin type: string clusterName: title: Cluster to run description: The cluster to run this workflow in. type: string ui:field: KubernetesClusterPicker repoUrl: # need a place to store this entity information. title: Repository Location type: string ui:field: RepoUrlPicker ui:options: allowedHosts: - github.com ...   This template contains input fields (.spec.parameters[1]) that are common to all Data on EKS blueprints. For example, the name of the admin IAM role that will have Cluster Admin access is common to all EKS clusters. The only difference between templates are the terraform configuration options field. We will populate this field with variables from a terraform module.  The -p flag specifies where you want to insert input field within the given template. In this case, we want to insert it at .spec.parameters[0].properties.tfVars.  The -o flag specifies the output directory. In this case, we want it to output it to the current directory.  Once the fields are generated and inserted, the template is ready to use. When rendered in Backstage, it should look something like this.    The diff between the original template and generated template should look something like this:  spec.parameters - one list entry removed: - title: &quot;Terraform config options&quot; │ properties: │ │ tfVars: │ │ │ type: object │ │ │ title: &quot;Terraform variables&quot; + one list entry added: - properties: │ │ tfVars: │ │ │ type: object │ │ │ title: &quot;Terraform variables&quot; │ │ │ properties: │ │ │ │ name: │ │ │ │ │ type: string │ │ │ │ │ default: spark-operator-doeks │ │ │ │ │ description: &quot;Name of the VPC and EKS Cluster&quot; │ │ │ │ eks_cluster_version: │ │ │ │ │ type: string │ │ │ │ │ default: 1.26 │ │ │ │ │ description: &quot;EKS Cluster version&quot; │ │ │ │ enable_amazon_prometheus: │ │ │ │ │ type: boolean │ │ │ │ │ default: true │ │ │ │ │ description: &quot;Enable AWS Managed Prometheus service&quot; │ │ │ │ enable_vpc_endpoints: │ │ │ │ │ type: boolean │ │ │ │ │ default: false │ │ │ │ │ description: &quot;Enable VPC Endpoints&quot; │ │ │ │ enable_yunikorn: │ │ │ │ │ type: boolean │ │ │ │ │ default: true │ │ │ │ │ description: &quot;Enable Apache YuniKorn Scheduler&quot; │ │ │ │ region: │ │ │ │ │ type: string │ │ │ │ │ default: us-west-2 │ │ │ │ │ description: Region │ │ │ │ vpc_cidr: │ │ │ │ │ type: string │ │ │ │ │ default: 10.1.0.0/16 │ │ │ │ │ description: &quot;VPC CIDR. This should be a valid private (RFC 1918) CIDR range&quot; │ │ │ │ eks_data_plane_subnet_secondary_cidr: │ │ │ │ │ type: array │ │ │ │ │ description: &quot;Secondary CIDR blocks. 32766 IPs per Subnet per Subnet/AZ for EKS Node and Pods&quot; │ │ │ │ │ default: │ │ │ │ │ - 100.64.0.0/17 │ │ │ │ │ - 100.64.128.0/17 │ │ │ │ │ items: │ │ │ │ │ │ type: string │ │ │ │ private_subnets: │ │ │ │ │ type: array │ │ │ │ │ description: &quot;Private Subnets CIDRs. 254 IPs per Subnet/AZ for Private NAT + NLB + Airflow + EC2 Jumphost etc.&quot; │ │ │ │ │ default: │ │ │ │ │ - 10.1.1.0/24 │ │ │ │ │ - 10.1.2.0/24 │ │ │ │ │ items: │ │ │ │ │ │ type: string │ │ │ │ public_subnets: │ │ │ │ │ type: array │ │ │ │ │ description: &quot;Public Subnets CIDRs. 62 IPs per Subnet/AZ&quot; │ │ │ │ │ default: │ │ │ │ │ - 10.1.0.0/26 │ │ │ │ │ - 10.1.0.64/26 │ │ │ │ │ items: │ │ │ │ │ │ type: string │ │ │ │ secondary_cidr_blocks: │ │ │ │ │ type: array │ │ │ │ │ description: &quot;Secondary CIDR blocks to be attached to VPC&quot; │ │ │ │ │ default: │ │ │ │ │ - 100.64.0.0/16 │ │ │ │ │ items: │ │ │ │ │ │ type: string │ title: &quot;Terraform config options&quot;  ","version":"Next","tagName":"h3"},{"title":"Verification​","type":1,"pageTitle":"Generate CNOE Backstage template","url":"/docs/tutorials/backstage-template#verification","content":" Verifications play a key role in ensuring successful rollouts in an IDP. Verifications are done external to the target Kubernetes cluster and perform readiness and dependency checks against the target cluster.  CNOE supports running verifications either by using the CNOE cli, or by embedding them into the Backstage workflow as a verify step in theScaffolder Backend Plugin.  CNOE supports the following (growing) list of verifications:  availability of required CRDs in a target Kubernetes clusterreadiness of operators in a target Kubernetes cluster  info full specification for the verification templates is available in the CNOE CLI repo.  ","version":"Next","tagName":"h2"},{"title":"Writing a Verification Template​","type":1,"pageTitle":"Generate CNOE Backstage template","url":"/docs/tutorials/backstage-template#writing-a-verification-template","content":" Below is a sample spec for a prerequisite ensuring that the Amazon Controllers for KubernetesS3 controller is installed and running in a target cluster:  apiVersion: cnoe.io/v1alpha1 kind: Prerequisite metadata: name: ack-s3 annotations: - test: something - another: something spec: pods: - name: ack-release-s3 namespace: ack-system state: Running crds: - group: s3.services.k8s.aws version: v1alpha1 kind: Buckets - group: acme.cert-manager.io kind: Challenges version: v1 - group: services.k8s.aws kind: AdoptedResources version: v1alpha1 - group: services.k8s.aws kind: FieldExports version: v1alpha1 - group: vpcresources.k8s.aws kind: SecurityGroupPolicies version: v1beta1   ","version":"Next","tagName":"h3"},{"title":"Running Verifications​","type":1,"pageTitle":"Generate CNOE Backstage template","url":"/docs/tutorials/backstage-template#running-verifications","content":" via the CNOE CLI​  The CLI support running verifications against a target cluster by running the command ./cnoe k8s verify:  $./cnoe k8s verify -h Verify if the required resources and controllers are working as expected Usage: cnoe k8s verify [flags] Flags: -c, --config stringArray list of prerequisite configurations (samples under config/prereq) -h, --help help for verify Global Flags: -k, --kubeconfig string path to the kubeconfig file (default &quot;~/.kube/config&quot;)  Below is an example successful output of running verify against a target cluster:  $./cnoe k8s verify --config config/prereq/ack-s3-prerequisites.yaml ✓ ack-s3 - s3.services.k8s.aws/v1alpha1, Kind=Buckets ✓ ack-s3 - acme.cert-manager.io/v1, Kind=Challenges ✓ ack-s3 - services.k8s.aws/v1alpha1, Kind=AdoptedResources ✓ ack-s3 - services.k8s.aws/v1alpha1, Kind=FieldExports ✓ ack-s3 - vpcresources.k8s.aws/v1beta1, Kind=SecurityGroupPolicies ✓ ack-s3 - ack-system, Pod=ack-release-s3-chart-8f76bf8bb-nm9wv - Running  And when things fail:  $./cnoe k8s verify --config config/prereq/bad-spark-prerequisites.yaml X bad-spark - sparkoperator.k8s.io/v2beta2, Kind=SparkApplication X bad-spark - Pod=sprk-operator 2 errors occurred: * sparkoperator.k8s.io/v2beta2, Kind=SparkApplication not found * Pod=sprk-operator not found  via the Backend Scaffolder​  caution Running the verification phase from within CNOE is still experimental and requires the presence of the CNOE CLI binary on the container image for Backstage, where it is configured to target the desired cluster.  The backend scaffolder plugin implements a step where the CNOE CLI can be called with reference to the respective Prerequisite check that needs to be run against the target cluster prior to installing resources.  In case of a S3 resource that is enabled via the Amazon Controllers for Kubernetes (ACK), this would be a check that verifies the existence of the relevant CRDs as well as ensuring that the ACK S3 Controller is present and running.  In case of a failure, the Backstage scaffolder halts the execution flow and shows the exact error reporting that the CNOE CLI reports upon execution from within the terminal (see below):    In case of a successful verification, the verify step would finish execution with an exit code 0 and allow for the rest of the steps to proceed:   ","version":"Next","tagName":"h3"}],"options":{"id":"default"}}